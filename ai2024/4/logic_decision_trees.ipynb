{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21862bbbaa99224c75be3bff0948ee68",
     "grade": false,
     "grade_id": "cell-b9a81d7a93ecd505",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Artificial Intelligence UE\n",
    "## Assignment 4 - Propositional Logic & Decision Trees\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <strong>Deadline:</strong> 09.12.2024, 12:00 (noon) \n",
    "</div>\n",
    "\n",
    "In this assignment you are going to implement two rules from Propositional Logic and implement the ID3 algorithm.\n",
    "\n",
    "The algorithm has been explained in the lecture (VO) and we gave you some additional information in the exercise (UE). Please refer to the lecture slides (VO) for the pseudo algorithms and the exercise slides (UE) for additional hints. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<p><strong>Automatic Grading:</strong></p>\n",
    "<ul>\n",
    "<li>Replace the placeholders <code># YOUR CODE HERE</code>, <code>raise NotImplementedError()</code> with your code.</li>\n",
    "<li>Do not rename any of the already existing variables (this might lead to hidden tests failing / not working).</li>\n",
    "<li>Do not delete or add cells.</li>\n",
    "<li>We added a few cells that you can use for debugging your implementation (marked by <code># you can use this cell to test / debug your implementations - please empty it before submission (you can leave or remove the comment)</code>)</li>\n",
    "<li>Hint: Once you've completed your implementation, if you're unsure whether any unintended changes were made to the original notebook, create a fresh copy of the provided notebook. Then, transfer your implementations to the new notebook before submitting.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Submission:</strong> Upload the notebook containing your implementation and answers, and change its name s.t. it contains \"a4\" and your student ID: </p>\n",
    "\n",
    "    a4_<k/vk + 8 digits>.ipynb ; e.g., a4_k01234567.ipynb\n",
    "\n",
    "\n",
    "<p><strong>Practical hints:</strong></p>\n",
    "<ul>\n",
    "<li>if you want a number smaller than all others, you may use <code>float('-Inf')</code></li>\n",
    "<li>if you want a number larger than all others, you may use <code>float('Inf')</code></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "For the implementation of the information gain, we are going to use the `entropy` function provided by `scipy`. To install `scipy`:\n",
    "<ul>\n",
    "    <li>First, activate your environment: <code>conda activate ai2024</code></li>\n",
    "    <li><code>pip install scipy==1.14.1</code></li>\n",
    "</ul>\n",
    "\n",
    "Note: The notebook has been tested with the original environment, and the environment after installing the additional libraries for A3 (i.e. it works with numpy=1.26.4 and numpy=2.1.0).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5f478ad78a1ab6f1ce0cd264aa4935b",
     "grade": false,
     "grade_id": "cell-a2f2bf0477eabc31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pig_lite.decision_tree.dt_node import DecisionTreeNodeBase\n",
    "from pig_lite.decision_tree.dt_base import DecisionTree, DecisionTreeNode # dummy classes so that pickle works\n",
    "from pig_lite.decision_tree.dt_base import entropy\n",
    "from pig_lite.decision_tree.training_set import TrainingSet\n",
    "from pig_lite.instance_generation.problem_factory import ProblemFactory\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df20327dad63f60cbef1d10daa6ccb08",
     "grade": false,
     "grade_id": "cell-a2ff996ae7d868be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Propositional Logic (2 points)\n",
    "\n",
    "Let us start by having a brief look at propositional logic. In the next cell, we provide you with an implementation of three functions for the logical operators $\\land$ (AND), $\\lor$ (OR), and $\\neg$ (NOT). Feel free to experiment with these functions and understand what they are doing. If you need to refresh your memory on these operators and the next ones that you need to implement, you might want to check the Standard Inference Rules in the lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb9947ca3e9ce4b7b9ac06a7adcf6e84",
     "grade": false,
     "grade_id": "cell-85bb8825b9824680",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def conjunction(alpha: bool, beta: bool) -> bool: # AND\n",
    "    return alpha & beta\n",
    "\n",
    "def disjunction(alpha: bool, beta: bool) -> bool: # OR\n",
    "    return alpha | beta\n",
    "\n",
    "def negation(alpha: bool) -> bool: # NOT\n",
    "    return not alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6035953aecd40b5b9876656572993273",
     "grade": false,
     "grade_id": "cell-d4c51c1414ff4271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell contains some assertions to make sure that the functions defined above have not been changed and work as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "851fd162933c2176e46320568e77275a",
     "grade": false,
     "grade_id": "cell-e560f0a19b863561",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(conjunction(True, True) == True)\n",
    "\n",
    "assert(negation(True) == False)\n",
    "assert(negation(False) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this cell to test / debug your implementations - please empty it before submission (you can leave or remove the comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31d40064ddb5563631bd54bc40f2172b",
     "grade": false,
     "grade_id": "cell-e940de5fac2f1eec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now you need to implement the next two operators, `implies(alpha, beta)` and `biconditional(alpha, beta)`. Where:\n",
    "\n",
    "* `implies(alpha, beta)`: Represents the logical implication, $\\alpha \\implies \\beta$\n",
    "* `biconditional(alpha, beta)`: Represents the logical implication, $\\alpha \\Longleftrightarrow \\beta$\n",
    "\n",
    "Both functions take two boolean values (`alpha` and `beta`) as input and return the resulting boolean value. \n",
    "\n",
    "In your implementations, you can either use the functions defined above (`conjunction`, `disjunction`, `negation`) or the operators `&`, `|`, and `not`, whichever you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54a9f04124e2ccd2de7c3f574d9cccd6",
     "grade": false,
     "grade_id": "cell-a192ca2fbccc0050",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def implies(alpha: bool, beta: bool) -> bool:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16a6e7950941d6d4ee75d4b4dd3775e1",
     "grade": true,
     "grade_id": "cell-ac89d086e794dbd6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c74163a278c2a0f3da15579b6293246",
     "grade": false,
     "grade_id": "cell-6a8201c85817daad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def biconditional(alpha: bool, beta: bool) -> bool:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b487efa0e94304cfa4756033a88a333",
     "grade": true,
     "grade_id": "cell-07b411dd96d6fbb0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3e56b76a75960ccf87e00e367ba701c",
     "grade": false,
     "grade_id": "cell-809c6901b6fbba23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "In this section you are going to play around with the information gain of a dataset that you will create for this purpose, implement the ID3 algorithm for datasets with numeric features, and implement a method to predict values for new examples using your trained decision tree.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<p><strong>Tree Visualization</strong></p>\n",
    "We provide you with different ways of visualizing the learned decision trees, which will be helpful for debugging your implementations.\n",
    "\n",
    "You can visualize an instance of class `TrainingSet`: `training_set.visualize()`, which in this assignment will give you a 2D representation of the points in your dataset.  \n",
    "\n",
    "You can also visualize the decision boundaries of a trained tree on top: `training_set.visualize(tree)`\n",
    "\n",
    "Furthermore, you can print a trained decision tree: `tree.print()` (this might get messy for larger trees)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a894ddcbae7642410919d0bd885d9b4",
     "grade": false,
     "grade_id": "cell-586cdb55f00a2670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following we are loading a previously trained tree and the corresponding training set. This is the same example as shown in the exercise slides.\n",
    "\n",
    "If you want to (it is not necessary for this exercise), you can also store trees:\n",
    "\n",
    "```\n",
    "with open(\"./demo/tree..pt\", 'wb') as fh:\n",
    "    pickle.dump(tree, fh)\n",
    "```\n",
    "\n",
    "and training sets:\n",
    "\n",
    "```\n",
    "json_str = training_set.to_json()\n",
    "with open(\"./demo/data.json\", 'w') as fh:\n",
    "    fh.write(json_str)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bcbe95bc8311e26094241d9776353ce",
     "grade": false,
     "grade_id": "cell-00c5b7a143b24959",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./demo/tree.pt\", 'rb') as fh:\n",
    "    demo_tree = pickle.load(fh)\n",
    "\n",
    "training_set = ProblemFactory().create_problem_from_json(\"./demo/data.json\")\n",
    "training_set.visualize(demo_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc87f81ebd96a25b965deb7af230c523",
     "grade": false,
     "grade_id": "cell-47903034e198af6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following we show `tree.print()` for the example tree that was also used in the exercise slides.\n",
    "- internal (non-leaf) nodes are represented as `(x0:-1.75)` (we split feature x0 at -1.75)\n",
    "- leaf nodes are represented as `(    1   )` where the number represents the class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdc389f555c792a124b836428c6db7cd",
     "grade": false,
     "grade_id": "cell-c0ddf83516ae1664",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "demo_tree.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfc54b3955d3d539bf256f2e3b5ffd83",
     "grade": false,
     "grade_id": "cell-3f4582e577bae8bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Information Gain (3 points)\n",
    "\n",
    "To build a decision tree using the ID3 algorithm, you need to calculate the information gain. In the cell below, we provide you with a function that does this computation, using the entropy() function. entropy() is a wrapper for [the scipy.stats.entropy function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html) for the case of binary classification. Feel free to check the documentation and see if you understand how these functions work. Note that in our data, we have two classes: 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19c2277f49ab903e439f2bd462d78c8e",
     "grade": false,
     "grade_id": "cell-c38fa9d270938c01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_information_gain(labels: np.array, x: np.array, split_point: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the information gain for a given feature and split point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : np.array\n",
    "        Binary class labels for the dataset.\n",
    "    x : np.array\n",
    "        Feature values corresponding to the labels.\n",
    "    split_point : float\n",
    "        The value at which to split the feature.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The information gain resulting from the split.\n",
    "    \"\"\"\n",
    "\n",
    "    # split labels according to split_point\n",
    "    labels_left_branch = labels[x <= split_point]\n",
    "    labels_right_branch = labels[x > split_point]\n",
    "\n",
    "    # compute weight (what proportion of samples is going into the left and right branch)\n",
    "    weight_left = len(labels_left_branch) / len(x)\n",
    "    weight_right = len(labels_right_branch) / len(x)\n",
    "\n",
    "    # compute entropy for all data, and the two created subsets\n",
    "    e_data = entropy(labels)\n",
    "    e_right = entropy(labels_right_branch)\n",
    "    e_left = entropy(labels_left_branch)\n",
    "\n",
    "    # compute and return information gain\n",
    "    return e_data - (weight_left * e_left + weight_right * e_right)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a34a8c0b658c6b193d6f3e8b233c1449",
     "grade": false,
     "grade_id": "cell-c6991d417521866e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's create a small dataset and see what the information gain for this data looks like. The labels for our dataset will be stored in a numpy array of shape `(n_samples,)` and the features will be stored in a numpy array of shape `(n_samples, n_features)`. The cell below shows how these arrays can be initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26cb754b9bcbc9288e7d09c6a628dce5",
     "grade": false,
     "grade_id": "cell-a106c48d1253a46d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "labels = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "X0 = np.array([ # samples (rows) x features (columns)\n",
    "    [0.2, 1.5, 8.3, 4.0],\n",
    "    [3.5, 2.3, 7.1, 2.4],\n",
    "    [1.8, 6.4, 4.6, 4.5],\n",
    "    [2.1, 3.9, 2.4, 3.0],\n",
    "    [8.3, 4.0, 5.3, 3.0],\n",
    "    [7.2, 2.1, 5.2, 2.0]\n",
    "])\n",
    "\n",
    "print(X0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2226459d6f2038b0a9657564dd82962f",
     "grade": false,
     "grade_id": "cell-dce80d68bc39aed9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can split the data along different features, and calculate the information gain for that split. The following code sets a threshold (`split_point=3.5` for each feature, also in the hidden tests for the information gain example) and computes the information gain.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79d07c3a6e40515576e697327811d434",
     "grade": false,
     "grade_id": "cell-a3c9cf2482dead73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(X0.shape[1]):\n",
    "    print(X0[:, i], compute_information_gain(labels, X0[:, i], split_point=3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c07588b2f8de83a88b4a568f1eeb2b49",
     "grade": false,
     "grade_id": "cell-e2fff6f1eabde257",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now your task is to **create** `X0` in a way such that, \n",
    "* $\\text{IG}(X0[:, 0]) = 0.0$\n",
    "* $\\text{IG}(X0[:, 0]) < \\text{IG}(X0[:, 1]) < \\text{IG}(X0[:, 2]) < \\text{IG}(X0[:, 3])$\n",
    "* $\\text{IG}(X0[:, 3]) = 1.0$\n",
    "\n",
    "Where $\\text{IG}(X0[:, i])$ is the information gain for the ith column when split on the point `split_point=3.5`. First, think about what the data must look like to result in a low / high information gain with respect to the labels of the dataset and this particular split point.\n",
    "\n",
    "All three conditions must hold for a single array `X0`. The datatype used, similar to the given example has to be a numpy array with the same dimensions. \n",
    "\n",
    "Do not modify `labels`, this will cause the hidden tests to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5887d934897b16a5b1fdc06e049a368e",
     "grade": false,
     "grade_id": "cell-28c5dbe7ea31f13d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X0 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# feel free to use this cell to also print / look at your created dataset and the resulting information gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02afcb9491a54a23c26c44f7597bcbc5",
     "grade": true,
     "grade_id": "cell-5483d3419af7deed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your modifications to X0 should have happened somewhere above this cell\n",
    "# make sure that 'labels' and 'X0' still have the expected shapes\n",
    "assert(labels.shape==(6,))\n",
    "assert(X0.shape==(6, 4))\n",
    "\n",
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa9d09c8dd1af2f689cd814a791fe38b",
     "grade": true,
     "grade_id": "cell-244b4f82f009b4dd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91ed199bb5378bff8c1979e2f646f2ef",
     "grade": true,
     "grade_id": "cell-8b2bf26b4562ab64",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4f3cd0eeb2e9dfe592f3ab62eafe431",
     "grade": false,
     "grade_id": "cell-f99f3dfe977f5ddf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### ID3 Algorithm\n",
    "\n",
    "In the next cell, you need to complete the implementation of several functions for a DecisionTreeNode following the instructions of the ID3 algorithm. Similar to the dataset you worked with above, the features of the data will be numeric and the labels will be binary. You need to complete three functions here:  \n",
    "\n",
    "* `get_all_possible_split_points` returns a list of tuples, containing all the possible split points for each of the features in the data of the current node,  \n",
    "* `get_optimal_split_point` can then use this function to find all the possible split points, and find the best split point based on information gain,  \n",
    "* `split` performs the splitting of the ID3 algorithm recursivly, based on the optimal split point and split value. \n",
    "\n",
    "**Hints:**\n",
    "* Each dataset, contains at least 2 samples and at least 2 features, i.e. `X` or `features` have a shape of at least (2, 2).\n",
    "* We are considering a binary classification problem where labels are either `0` or `1`. However, not every dataset is guaranteed to contain samples from both classes.\n",
    "* You can use `set(labels)` to get unique labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08c7246850ec9717173e2e3e58ebeff5",
     "grade": false,
     "grade_id": "cell-244ab622da0231f5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTreeNode(DecisionTreeNodeBase):\n",
    "    def __init__(self, features: np.ndarray, labels: np.ndarray):\n",
    "        \"\"\"\n",
    "        Initialize a decision tree node with features and labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features : np.ndarray\n",
    "            A 2D NumPy array where each row represents an instance and each column represents a feature.\n",
    "            This array contains the feature values for the data points at the current node.\n",
    "            Example:\n",
    "                np.array([\n",
    "                    [1.2, 3.4, 5.6],  # Instance 1 with 3 features\n",
    "                    [7.8, 9.0, 2.1],  # Instance 2 with 3 features\n",
    "                    [4.5, 6.7, 8.9]   # Instance 3 with 3 features\n",
    "                ])\n",
    "        labels : np.ndarray\n",
    "            A 1D NumPy array of integers, where each element corresponds to the class label of an instance.\n",
    "            This array contains the labels of the data points at the current node.\n",
    "            Example:\n",
    "                np.array([0, 1, 0])  # Instance 1 belongs to class 0, Instance 2 belongs to class 1, and so on.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "\n",
    "    def get_all_possible_split_points(self) -> list[tuple]:\n",
    "        \"\"\"\n",
    "        Identify all possible split points for features in the dataset.\n",
    "\n",
    "        This method generates potential split points for each feature in the dataset based on changes in the labels. \n",
    "        A split point is defined as the midpoint between two successive feature values where the labels and features differ.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[tuple]\n",
    "            A list of tuples `(f_idx, split_at)`, where `f_idx` is the feature index and `split_at` is the value \n",
    "            at which the split occurs.\n",
    "        Notes for Students\n",
    "        ------------------\n",
    "        - The input dataset is stored in `self.features` (a 2D NumPy array) and `self.labels` (a 1D NumPy array).\n",
    "        - Make sure to use features and labels that has already been sorted for you\n",
    "        - You should:\n",
    "            1. Iterate over all samples\n",
    "            2. Check whether it makes sense to split at this point, if yes: store the split point\n",
    "        \"\"\"\n",
    "\n",
    "        nr_samples, nr_features = self.features.shape\n",
    "        split_points = []\n",
    "\n",
    "        for f_idx in range(nr_features):\n",
    "            # we use argsort so we can used the indeces to sort the labels accordingly\n",
    "            idx_sort = self.features[:, f_idx].argsort()\n",
    "            features = self.features[idx_sort, :] # <- use this instead of self.features\n",
    "            labels = self.labels[idx_sort] # <- use this instead of self.labels\n",
    "                    \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        return split_points\n",
    "\n",
    "    def get_optimal_split_point(self) -> tuple[int, float]:\n",
    "        \"\"\"\n",
    "        Find the optimal split point for the dataset.\n",
    "\n",
    "        This method identifies the feature and value that provide the highest information gain when splitting the data. \n",
    "        It uses the method `self.get_all_possible_split_points()` to generate potential splits and evaluates each split \n",
    "        using `compute_information_gain`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple `(split_feature, split_point)`, where:\n",
    "            - `split_feature` is the index of the feature to split on.\n",
    "            - `split_point` is the value of the feature at which to split.\n",
    "\n",
    "        Notes for Students\n",
    "        ------------------\n",
    "        - Step 1: Use `self.get_all_possible_split_points()` to retrieve a list of potential split points. \n",
    "                Each split point is a tuple `(f_idx, split_at)`.\n",
    "        - Step 2: Iterate over the list of possible split points:\n",
    "            - For each split point, calculate the information gain using the `compute_information_gain` function.\n",
    "            - Keep track of the split point that gives the highest information gain.\n",
    "        - Step 3: Return the feature index and value of the split with the best information gain.\n",
    "        \"\"\"\n",
    "\n",
    "        split_feature, split_point = None, None\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return split_feature, split_point\n",
    "\n",
    "    def split(self) -> DecisionTreeNode:\n",
    "        \"\"\"\n",
    "            Split the current node using the ID3 algorithm based on the lecture slides \"The ID3 Algorithm\"\n",
    "\n",
    "            Notes for Students\n",
    "            --------\n",
    "            The following steps correspond to the steps on the lecture (VO) slide \"ID3: The Full Algorithm\"\n",
    "            1. If all examples X in the current node belong to the same class, make current node a leaf (i.e. label with class (integer value), and EXIT)\n",
    "            2. Our implementation differs here, each feature can be split several times (see exercise slides)\n",
    "            3. + 4. Use get_optimal_split_point() to determine the best feature to split on.\n",
    "            5. + 6. Create a branch + successor node N_i for each value of the selected feature containing a subset of X \n",
    "                - Instances where the feature value is less than or equal (<=) to the split point go to the left child (assign to self.left_child).\n",
    "                - Instances where the feature value is greater (>) than the split point go to the right child (assign to self.right_child).\n",
    "            7. For each subnode (self.left_child, self.right_child) call split\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            self : DecisionTreeNode\n",
    "                The current node after the split, which may have new left and right child nodes.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this cell to test / debug your implementations - please empty it before submission (you can leave or remove the comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "987bd3e39a308ec76198ce846224478f",
     "grade": false,
     "grade_id": "cell-b84b2a54eff97d27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Basic Tests\n",
    "\n",
    "These tests check some basic functionality and should help you debug your algorithm. They are not graded this time but should give you an idea what the hidden tests could look like for (possibly) more complicated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4605cd97ce3036c5a9a84ecefd17e8bf",
     "grade": false,
     "grade_id": "cell-f1429a73a981a395",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_basic_test = np.array([[1, 1],\n",
    "                         [-1, -1],\n",
    "                         [-1, 1],\n",
    "                         [1, -1]])\n",
    "y_basic_test = np.array([0, 0, 1, 1])\n",
    "\n",
    "# this is only a test node and not a tree (this means you can not visualize it on top of the dataset)\n",
    "dt_basic_test_node = DecisionTreeNode(features=X_basic_test, labels=y_basic_test)\n",
    "\n",
    "TrainingSet(X_basic_test, y_basic_test).visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44c106963e009de4128bc65af0268db0",
     "grade": false,
     "grade_id": "cell-04080834af3854cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_apsp = len(dt_basic_test_node.get_all_possible_split_points())\n",
    "assert(n_apsp == 2), f'Expected 2 possible splitting points, but found {n_apsp}. Check your logic for determining split points.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97bf0cca93599b84bded598ccffc7b2f",
     "grade": false,
     "grade_id": "cell-dff9fa41c2c394a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# optimal split points\n",
    "assert(dt_basic_test_node.get_optimal_split_point()[0] == 0), 'something is wrong with your implementation of the method get_optimal_split_point()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09af3c2d99b799c75f6d6bd5723d6e21",
     "grade": false,
     "grade_id": "cell-8d6c6a0029c80574",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# the split method\n",
    "assert(isinstance(dt_basic_test_node.split(), DecisionTreeNode)), 'your implemenation of split() should return a DecisionTreeNode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d61ed9a6927fb5c850f1b48f1afb3327",
     "grade": false,
     "grade_id": "cell-e050004b7f1d07db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### DecisionTree - predict()\n",
    "\n",
    "This section now contains the class `DecisionTree` which contains the function to fit a tree (already implemented) and the function to predict labels for a new dataset (to be implemented by you).\n",
    "\n",
    "The predict(X) function should take in numpy.array `X` containing feature values for which we want to compute predictions. The predictions should be returned as a Python list.\n",
    "\n",
    "Hints:\n",
    "* You can use `for x in X` to loop over the data. You can also do it differently as long as the output is correct.\n",
    "* Ensure that you properly handle cases where a node is a leaf (i.e., `split_point` is `None`).\n",
    "* The predicted label can be converted to a standard Python type using `.item()` (not required, but makes the output look cleaner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "387b5975808011218fa93a9d0f03327f",
     "grade": false,
     "grade_id": "cell-63a846ebec044d59",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self) -> None:\n",
    "        self.root = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.root)\n",
    "\n",
    "    def fit(self, training_set):\n",
    "        self.root = DecisionTreeNode(training_set.X, training_set.y)\n",
    "        self.root.split()\n",
    "        return self\n",
    "    \n",
    "    def get_height(self, node):\n",
    "        if node is None:\n",
    "            return 0\n",
    "        return max(self.get_height(node.left_child), self.get_height(node.right_child)) + 1\n",
    "    \n",
    "    def print(self):\n",
    "        if self.root is not None:\n",
    "            height = self.get_height(self.root)\n",
    "            self.root.print_tree(height)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> list:\n",
    "        \"\"\"\n",
    "        Predict the labels for a set of input samples using the decision tree.\n",
    "\n",
    "        This method traverses the decision tree for each input sample in `X`, starting from the root node. \n",
    "        It follows the splits based on the features and split points until it reaches a leaf node, where the \n",
    "        predicted label is stored.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            A 2D NumPy array where each row represents a sample and each column represents a feature.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of predicted labels for each sample in `X`.\n",
    "\n",
    "        Notes for Students\n",
    "        ------------------\n",
    "        - The prediction starts at the root of the decision tree (`self.root`) and proceeds down the tree until \n",
    "        a leaf node is reached.\n",
    "        - At each node:\n",
    "            - Compare the sample's feature value at `split_feature` to the `split_point`.\n",
    "            - Traverse to the `left_child` if the feature value is less than or equal to the `split_point`.\n",
    "            - Traverse to the `right_child` if the feature value is greater than the `split_point`.\n",
    "        - Once a leaf node is reached, the `label` of that node is appended to the predictions list.\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this cell to test / debug your implementations - please empty it before submission (you can leave or remove the comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54dc643b4a822225c3777197699a70e5",
     "grade": false,
     "grade_id": "cell-33b2479d19ad77cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell contains a very basic test that should help you debug your implementations, and is also not graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15dd3b9dae2c509250d882d6de38557f",
     "grade": false,
     "grade_id": "cell-f03a6e867a3a1490",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "id3_tree = DecisionTree()\n",
    "\n",
    "# a new tree is trained on the previously defined training set and used to predict two new examples\n",
    "id3_tree.fit(training_set)\n",
    "\n",
    "# feel free to play around with the samples\n",
    "X1 = np.array([[-3, 0],\n",
    "               [-1, -2]])\n",
    "\n",
    "y1 = id3_tree.predict(X=X1)\n",
    "\n",
    "assert(y1[0] == 1), 'predict(X1[0]) expected to be 1.0'\n",
    "assert(y1[1] == 0), 'predict(X1[1]) expected to be 0.0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed3e165ecc1025c8cf79cb6f161df8aa",
     "grade": false,
     "grade_id": "cell-35a43faa22364f3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Additional tests\n",
    "\n",
    "The following contains additional tests for the functions you implemented. These will be graded.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <strong>Attention!</strong> Do not change anything below this point!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f9107fed1e0f7e9dd6a07104675a96c",
     "grade": false,
     "grade_id": "cell-c3db16c94766d380",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### get_all_possible_split_points() (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e63bd8a6546e676eb01949d32f5b4a0f",
     "grade": true,
     "grade_id": "cell-d460a014b43a7a01",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae103f85079780be65371b7237cceaea",
     "grade": true,
     "grade_id": "cell-48c11e27ccb0b326",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc8e1800beae72bf89c04b7759ad191d",
     "grade": false,
     "grade_id": "cell-71963abcf23420b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### get_optimal_split_point() (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4be0b45b16972756416fab41ae30d1c",
     "grade": true,
     "grade_id": "cell-197e372e8e51846a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e1926e03e6304fe51a9eb9e94afbfa9",
     "grade": false,
     "grade_id": "cell-395cb178faca21b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### split() (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "374392075141a89cd059ad85f56d12e9",
     "grade": true,
     "grade_id": "cell-6ba666314b9395b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d420b24bb387b2a3d331d068b0e47a06",
     "grade": true,
     "grade_id": "cell-9aadd98cd48b90f8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3036dbcc4a265aade90b76bce1317f77",
     "grade": true,
     "grade_id": "cell-b5ab1e8b03ed2c26",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3634d0d398ba37dadb8e2cc6edcdbcc3",
     "grade": true,
     "grade_id": "cell-b14c2dfebae4a25f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c460798a9c6f0971ccdb2ee5c4de7b8",
     "grade": false,
     "grade_id": "cell-f5dd72df6dd598bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### predict() (3 points)\n",
    "\n",
    "For these tests we are going to use a previously trained tree using our reference implementation. This means even if your ID3 implementation does not work correctly, you can get all the points for these tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6af5504e4a5fab0d61f0d236fb751cd5",
     "grade": true,
     "grade_id": "cell-3e71f43df8dd8247",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49a8cdc7e7f73f0455ab90f76e8bf33f",
     "grade": true,
     "grade_id": "cell-1b606750a67e3401",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df7d82e96719f477850ff12e5ba2caa0",
     "grade": true,
     "grade_id": "cell-937b957365c6ed99",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains hidden tests, please do not edit or delete it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
