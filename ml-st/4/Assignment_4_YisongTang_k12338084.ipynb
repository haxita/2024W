{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7abf8494e9df749ad0e2f3913d42dfb",
     "grade": false,
     "grade_id": "cell-c73df07b01d6030e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 4: Decision Trees and other classifiers on real dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b593156a007302bd5077cffcdd654774",
     "grade": false,
     "grade_id": "cell-9da6e313cde530c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This material, no matter whether in printed or electronic form,\n",
    "may be used for personal and non-commercial educational use\n",
    "only. Any reproduction of this material, no matter whether as a\n",
    "whole or in parts, no matter whether in printed or in electronic\n",
    "form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5a700ec5cff11cd1a82284595bdeaff",
     "grade": false,
     "grade_id": "cell-2a9e4aa49371b9fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Automatic Testing Guidelines</h2>\n",
    "\n",
    "Automatic unittesting requires you to submit a notebook which contains strictly defined objects.\n",
    "Strictness of definition consists of unified shapes, dtypes, variable names and more.\n",
    "\n",
    "Within the notebook, we provide detailed instruction which you should follow in order to maximise your final grade.\n",
    "\n",
    "**Name your notebook properly**, follow the pattern in the template name:\n",
    "\n",
    "**Assignment_N_NameSurname_matrnumber**\n",
    "<ol>\n",
    "    <li>N - number of assignment</li>\n",
    "    <li>NameSurname - your full name where every part of the name starts with a capital letter, no spaces</li>\n",
    "    <li>matrnumber - you student number on ID card (with k, potentially with a leading zero)</li>\n",
    "</ol>\n",
    "\n",
    "Don't add any cells but use the ones provided by us. All cells have a unique ID so that the unit test can find it, so please do not add or remove any cell!\n",
    "\n",
    "Always make sure that implemented functions have the correct output and given variables contain the correct data type. In the descriptions for every function you can find information on what datatype an output should have and you should stick to that in order to minimize conflicts with the unittest. Don't import any other packages than listed in the cell with the \"imports\" tag.\n",
    "\n",
    "Questions are usually multiple choice (except the task description says otherwise) and can be answered by changing the given variables to either \"True\" or \"False\". \"None\" is counted as a wrong answer in any case!\n",
    "\n",
    "**Note:** Never use variables you defined in another cell in your functions directly; always pass them to the function as a parameter. In the unitest, they won't be available either. If you want to make sure that everything is executable for the unittest, try executing cells/functions individually (instead of running the whole notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56b85dda993eb88bfea01821dbbcf652",
     "grade": false,
     "grade_id": "cell-0bf8c61143eb8403",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Dataset</h2>\n",
    "\n",
    "For this notebook to compile without problems, make sure that the required dataset files are stored in a folder called `dataset`! Also make sure that this folder and the additional Python file, provided via Moodle, are in the same folder as the notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b47ee10e9d72d949ae0abdcb3bf1a74",
     "grade": false,
     "grade_id": "cell-d15c64b62594f0b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 1: Gini Impurity</h2>\n",
    "\n",
    "In this task, we will recall the most important concepts of decision trees by walking you through a simple example. On the way you have to solve some exercises to gain basic insights. Let's start with a simple toy dataset for one tree and give a defintion of the concepts needed for the following tasks.\n",
    "\n",
    "* **Code 1.1**:\n",
    "Implement the necessary calculations in the function `calc_gini` and return the 4 solutions (**Note:** Your implementation should work for any dataset similar to the toy dataset (i.e. binary labels, two dimensional)):\n",
    "    1. Calculate the Gini impurity for our toy dataset.\n",
    "    2. Calculate the Gini impurity for the top/right leaf in a given $x_2$- or $x_1$-split.\n",
    "    3. Calculate the Gini impurity for the bottom/left leaf in a given $x_2$- or $x_1$-split.\n",
    "    4. Calculate the Gini impurity gain for a given split in the toy dataset.\n",
    "* **Question 1.1**:\n",
    "    * Answer some questions about the results of **Code 1.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51df4a6f5d5ee2b357cc98046e7d7d1a",
     "grade": false,
     "grade_id": "cell-3fdd327e36b94adc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from mnist_loader import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "# Set random seed to ensure reproducible runs\n",
    "RSEED = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cf91836cc24f1bd899adea27bbaea17",
     "grade": false,
     "grade_id": "cell-167b45ae1a20da85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "X_toy = np.array(\n",
    "    [[2, 2],\n",
    "     [2, 1],\n",
    "     [2, 3],\n",
    "     [1, 2],\n",
    "     [1, 1],\n",
    "     [3, 3],\n",
    "     [3, 2]]\n",
    ")\n",
    "\n",
    "y_toy = np.array([0, 1, 1, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c438bb02eb33a8ae9a1305b8967ad25",
     "grade": false,
     "grade_id": "cell-b47006415ce9f384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "# Plot each point as the label.\n",
    "for x1, x2, label in zip(X_toy[:, 0], X_toy[:, 1], y_toy):\n",
    "    plt.text(x1, x2, str(label), fontsize = 40, color = 'b',\n",
    "             ha='center', va='center')\n",
    "    \n",
    "plt.grid()\n",
    "plt.xlim((0, 3.5))\n",
    "plt.ylim((0, 3.5))\n",
    "plt.xlabel('$x_1$', size = 20); plt.ylabel('$x_2$', size = 20)\n",
    "plt.title('Toy dataset', size = 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "285d56f6ec86035537549a729d4b3b7c",
     "grade": false,
     "grade_id": "cell-082d8408378af610",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "A **Decision Tree Classifier (DTC)** builds a decision tree based on the features of the data. This is equivalent to subdividing the feature space. Let's consider the example above and apply a simple heuristics. In the first step we try to subdivide the space such that we obtain the _largest possible leaf (subdivision)_ that contains only **one class**.\n",
    "<br><br>\n",
    "We first look at the feature $x_2$, i.e. a horizontal division of the space. For example, we could divide the space at the specific threshold $x_2 = 2.5$. Then we end up having a group of samples with features $x_2 > 2.5$ and homogenous class label 1, i.e. the two points with coordinates $\\{ (2,3), (3,3) \\}$ . If we instead look at the feature $x_1$, corresponding to a vertical division of the space, we cannot find an equally large or larger group of samples with the same label. Therefore, our first node in the tree is: $x_2 \\leq 2.5$, i.e. we split the space and repeat the same procedure on each of the two leafs. In our case we are done with the top leaf (since both samples have the same class) and only need to repeat the procedure on the bottom leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ecaaf05dd18c9d7429d18d2f58944dd",
     "grade": false,
     "grade_id": "cell-1aaff0f444e11c82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Our simple heuristics from above fails on the bottom node. We need a better criterion to decide which splits to make. <br> Nowadays the most frequently used one is called the **Gini Impurity**. \n",
    "\n",
    "The Gini Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled, if it was randomly labeled according to the distribution of labels in the subset.\n",
    "<br>\n",
    "\n",
    "What does that mean? \n",
    "1. Let us suppose we have $2$ labels and let $p_1, p_2$ be the fractions of points labeled with labels $1$ and $2$ (note: $p_1 + p_2 = 1$) . \n",
    "2. The probabilty to choose a point with label $1$ is $p_1$. \n",
    "3. The probability to choose label $2$ is $p_2 = 1-p_1$. \n",
    "4. Therefore, the probability to label a point of label $1$ with label $2$ is $p_1 \\cdot p_2 = p_1 \\cdot (1-p_1) = p_1 - p_1^2$. \n",
    "5. Analogously, the probability for points with label $2$ to be labeled with $1$ is $p_2 \\cdot (1-p_2) = p_2 - p_2^2$. <br> \n",
    "6. The Gini Impurity is the sum over both: $p_1 - p_1^2 + p_2 - p_2^2 = p_1 + p_2 - p_1^2 - p_2^2 = 1 - p_1^2 -p_2^2$\n",
    "\n",
    "The above reasoning is easy to generalize to the case where the number of labels $M$ is larger than two: $M>2$. <br>\n",
    "The formula for the given dataset $Z$ is simply $I_G(Z)=1-\\sum_{k = 1}^M p_k(Z)^2$, where $p_k(Z)$ is the frequency of points with labels $k$ in the dataset $Z$. <br> \n",
    "\n",
    "The Gini Impurity Gain is the amount of \"impurity\" we get rid of for a specific split $s$.\n",
    "\n",
    "Let's assume that we get the partition $Z_{s,1}, \\ldots, Z_{s,K_s}$ of $Z$ after applying $s$. \n",
    "\n",
    "Then the impurity gain is $g_G(Z,s) = I_G(Z) - \\sum_{t=1}^{K_s} \\frac{|Z_{s,t}|}{|Z|} \\cdot I_G(Z_{s,t})$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d87fd877fcd7596f722863d2bd34e0d",
     "grade": false,
     "grade_id": "cell-993736f446481c7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 1.1 (15 Points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2cee669ad10c8bb4bb576bbaabe00a3",
     "grade": false,
     "grade_id": "calc_gini",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_gini(X: np.ndarray, y: np.ndarray, split: float, axis: int) -> tuple[float, float, float, float]:\n",
    "    \"\"\"Function that calculates the Gini Impurity of the whole dataset and of the two subsets after a given split is performed.\n",
    "    Also returns the impurity gain from this specific split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : (N, 2) np.ndarray\n",
    "        Data matrix.\n",
    "    y : (N,) np.ndarray\n",
    "        Binary labels.\n",
    "    split : float\n",
    "        Value at which the split is performed\n",
    "    axis : int\n",
    "        Axis on which the split is performed, 0 for the first feature (=x1), 1 for the second feature (=x2).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of float\n",
    "        - gini_impurtiy : float\n",
    "            The gini impurity of the whole dataset.\n",
    "        - gini_impurity_top / gini_impurity_right : float\n",
    "            The gini impurity for the top or right split depending on the axis.\n",
    "        - gini_impurity_bottom / gini_impurity_left : float\n",
    "            The gini impurity for the bottom or left split depending on the axis.\n",
    "        - impurity_gain : float\n",
    "            The impurity gain of the performed split.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5f35df4eef1c4a35ffb8aa2128eb473",
     "grade": true,
     "grade_id": "gini_impurity_test",
     "locked": true,
     "points": 3.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "x1_split_point= 1.5\n",
    "gini_impurity, gini_right, gini_left, impurity_gain_0 = calc_gini(X_toy, y_toy, x1_split_point, 0)\n",
    "\n",
    "x2_split_point= 2.5\n",
    "_, gini_top, gini_bottom, impurity_gain_1 = calc_gini(X_toy, y_toy, x2_split_point, 1)\n",
    "\n",
    "assert isinstance(gini_impurity, float), \"The gini impurity is not a float!\"\n",
    "assert np.isclose(gini_impurity, 0.4898, atol=1e-4), \"The gini impurity is not correct!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e055006eed51aa51af91f3d5fcaf285d",
     "grade": true,
     "grade_id": "gini_impurity_right_top",
     "locked": true,
     "points": 3.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert isinstance(gini_right, float), \"The gini impurity for the right split is not a float!\"\n",
    "assert np.isclose(gini_right, 0.4800, atol=1e-4), \"The gini impurity for the right split is not correct!\"\n",
    "assert np.isclose(gini_top, 0, atol=1e-4), \"The gini impurity for the top split is not correct!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49adfc7885cd7d75f3879804e32f141b",
     "grade": true,
     "grade_id": "gini_impurity_left_bottom",
     "locked": true,
     "points": 3.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert isinstance(gini_left, float), \"The gini impurity for the left split is not a float!\"\n",
    "assert np.isclose(gini_left, 0.5, atol=1e-4), \"The gini impurity for the left split is not correct!\"\n",
    "assert np.isclose(gini_bottom, 0.48, atol=1e-4), \"The gini impurity for the bottom split is not correct!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eda46d5f0020726e66471cc7867c78d",
     "grade": true,
     "grade_id": "impurity_gain",
     "locked": true,
     "points": 3.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert isinstance(impurity_gain_0, float), \"The gini impurity gain is not a float!\"\n",
    "assert np.isclose(impurity_gain_0, 0.0041, atol=1e-4), \"The gini impurity gain for the vertical split is not correct!\"\n",
    "assert np.isclose(impurity_gain_1, 0.1469, atol=1e-4), \"The gini impurity gain for the horizontal split is not correct!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fec9f625d6ae5c40fbac58642cfe6c73",
     "grade": false,
     "grade_id": "cell-75f6a849c66cda60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "print(f\"Results for x1 = {x1_split_point}:\\n\")\n",
    "print(\n",
    "    f\"Gini impurity for the entire dataset: {gini_impurity:0.4f}\\n\"\n",
    "    f\"Gini impurity right leaf: {gini_right:0.4f}\\n\"\n",
    "    f\"Gini impurity left leaf: {gini_left:0.4f}\\n\"\n",
    "    f\"Gini impurity gain: {impurity_gain_0:0.4f}\\n\\n\"\n",
    ")\n",
    "\n",
    "print(f\"Results for x2 = {x2_split_point}:\\n\")\n",
    "print(\n",
    "    f\"Gini impurity for the entire dataset: {gini_impurity:0.4f}\\n\"\n",
    "    f\"Gini impurity top leaf: {gini_top:0.4f}\\n\"\n",
    "    f\"Gini impurity bottom leaf: {gini_bottom:0.4f}\\n\"\n",
    "    f\"Gini impurity gain: {impurity_gain_1:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ec7a7281cd80e69440dccc413aa169b",
     "grade": false,
     "grade_id": "cell-d46ac666472dac74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Question 1.1 (3 Points):</h3>\n",
    "\n",
    "***Based on the results of Gini impurity for the two different split locations of $x_2$, which of the following statements are correct?***\n",
    "\n",
    "a1_) The right leaf of the split at $x_1=1.5$ has smaller Gini impurity than the top leaf of the split at $x_2=2.5$ <br>\n",
    "b1_) The Gini impurity of the entire dataset does not depend on the split location. <br>\n",
    "c1_) The Gini impurity gain of the split at $x_1=1.5$ is smaller than at $x_2=2.5$, indicating that $x_1=1.5$ is a worse splitting point.\n",
    "\n",
    "To answer the question, assign `True` or `False` boolean values to variables in the next cell. For example, if you think that **a1_)** is correct, define a variable `a1_` and set it to `True`, the same applies to **b1_)** and the other options. A non-correctly answered question as well as no answer (i.e. answer “None”) yields 0 points for a specific question.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35c5490e129bc50282b39d3d07d6ff37",
     "grade": false,
     "grade_id": "question_1_2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a043f7228963c2b067623be4c018aa0",
     "grade": true,
     "grade_id": "a1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert a1_ is not None, \"Store True/False!\"\n",
    "assert a1_ in [True, False], \"Invalid Answer!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03b4cc2fb8f81a1a8fcf79ba6f7dbe36",
     "grade": true,
     "grade_id": "b1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert b1_ is not None, \"Store True/False!\"\n",
    "assert b1_ in [True, False], \"Invalid Answer!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f967ad69ee9e2ff208d8de7d18aaeee",
     "grade": true,
     "grade_id": "c1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert c1_ is not None, \"Store True/False!\"\n",
    "assert c1_ in [True, False], \"Invalid Answer!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8644e9b2ffc6760e694754731f041483",
     "grade": false,
     "grade_id": "cell-69a4ded70ace8c05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 2: Train a simple decision tree </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "657fcd4eaf7cca85bd04746215eae431",
     "grade": false,
     "grade_id": "cell-0747e019e9acb228",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, you should provide a Python routine for the previous example.\n",
    "* **Code 2.1**: In the cells below is the function `dec_tree` where you have to implement the following:\n",
    "    * Train a decision tree (have a look at [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)) on the given dataset $X_{train}, y_{train}$ and remember to pass the random seed `seed` defined as function parameter.\n",
    "    * Return the fitted DecisionTreeClassifier, the number of tree nodes, the maximum depth of the tree, and the accuracy of the tree on the given $X_{test}, y_{test}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1426bb2c7f6ff26eb13de14a8594787",
     "grade": false,
     "grade_id": "cell-9201aa4323ae5f7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 2.1 (12 Points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93f9210c010001e1cfc5ef862c62d65f",
     "grade": false,
     "grade_id": "dec_tree",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dec_tree(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray, seed: int) -> tuple[DecisionTreeClassifier, int, int, float]:\n",
    "    \"\"\"Trains a decision tree and returns certain attributes of the received model.\n",
    "    \n",
    "    Important: Use sklearn's DecisionTreeClassifier for this task, don't forget to feed it the given seed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : (N, K) np.ndarray\n",
    "        Data matrix used for fitting the tree.\n",
    "    y_train : (N,) np.ndarray\n",
    "        Binary labels of the train data.\n",
    "    X_test : (N, K) np.ndarray\n",
    "        Data matrix used for computing the accuracy of the tree.\n",
    "    y_test : (N,) np.ndarray\n",
    "        Binary labels of the test data.\n",
    "    seed : int\n",
    "        Seed for reproducibility.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of DecisionTreeClassifier, int, float\n",
    "        - tree : DecisionTreeClassifier\n",
    "            The fitted tree.\n",
    "        - nr_nodes : int\n",
    "            The number of nodes in the fitted decision tree.\n",
    "        - max_depth : int\n",
    "            The max depth of the tree.\n",
    "        - accuracy : float\n",
    "            The achieved accuracy on the given dataset.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccb7bc9ac57d4d3bf6245a363656674e",
     "grade": true,
     "grade_id": "nr_nodes_test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "fitted_tree, nr_nodes, max_depth, acc = dec_tree(X_toy, y_toy, X_toy, y_toy, RSEED)\n",
    "assert isinstance(fitted_tree, DecisionTreeClassifier), \"The returned tree is not of type DecisionTreeClassifier!\"\n",
    "assert isinstance(nr_nodes, int), \"The number of nodes is not an integer!\"\n",
    "assert nr_nodes == 11, \"The number of nodes is wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3529d4db8498260d655f56319cd1c3d2",
     "grade": true,
     "grade_id": "max_depth_test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert isinstance(max_depth, int), \"The max depth is not an integer!\"\n",
    "assert max_depth == 4, \"The max depth is wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ba6bdc4edc7889a8231182eb17205e2",
     "grade": true,
     "grade_id": "accuracy_test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert isinstance(acc, float), \"The accuracy is not a float!\"\n",
    "assert acc == 1, \"The accuracy is wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53329b63ff27ed65797263cc07b8b116",
     "grade": false,
     "grade_id": "cell-9bbcea5ee4eb8d4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "print(f'Decision tree has {nr_nodes} nodes with maximum depth {max_depth}.')\n",
    "print(f'Model accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15d40874ea9307455e0e6880a89455b0",
     "grade": false,
     "grade_id": "cell-9c7afb0612b896c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 3: Decision tree on a real data set</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b90ca56fa4734833f122c731c750fb22",
     "grade": false,
     "grade_id": "cell-f22b6920d3b8bec1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will apply the classifier to a well known real-world benchmark data set, namely the \"Fashion MNIST\" dataset. It consists of images of clothing, like sneakers and shirts. It was created to be an alternative to the famous MNIST benchmark dataset, which is nowadays considered as too easy for the most recent algorithms. Let us first load the train and test set, using the files provided on Moodle. The train and test datasets are represented as flattened pixel arrays ($28\\times28=784\\,\\text{pixels}$), and the label vector indicates the different classes (0 to 9). The following cells train and evaluate a simple DecisionTreeClassifier on a small subset of the Fashion MNIST dataset, to give you a baseline.\n",
    "\n",
    "* **Code 3.1**:\n",
    "    In order to obtain a better performance, we apply a hyperparameter search. \n",
    "    * To this end implement a factory function called `create_param_grid` that simply creates a parameter grid (dictionary) which contains the following quantities:\n",
    "        - `criterion`: 'gini' and 'entropy'\n",
    "        - `max_depth`: 10, 50 and 100\n",
    "        - `splitter`: 'random' and 'best'\n",
    "        - **Hint:** Have a look at the documentation of [RandomizedSearchCV](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) to get an idea on how this parameter grid should look like.\n",
    "    * Implement the function `train_dec_tree` that applies [RandomizedSearchCV](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) to train a DecisionTreeClassifier using Cross-Validation and returns the best fitted model on the train data and its `best_params_` dictionary (have a look at the documentation).\n",
    "    * Again, don't forget to pass the seed in **(both!)** the **DecisionTreeClassifier** and **RandomizedSearchCV**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4acaf5ce636fa83867bb3f33f02c7138",
     "grade": false,
     "grade_id": "cell-cac4859a12f8a4e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "data = MNIST('./dataset/')\n",
    "img_train, labels_train = data.load_training()\n",
    "n_train = 12000\n",
    "n_test = 2000\n",
    "X_train = np.array(img_train)[:n_train]\n",
    "y_train = np.array(labels_train)[:n_train]\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "img_test, labels_test = data.load_testing()\n",
    "X_test = np.array(img_test)[:n_test]\n",
    "y_test = np.array(labels_test)[:n_test]\n",
    "print(X_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af38f50bcae6766cb0d65167a96eebea",
     "grade": false,
     "grade_id": "cell-1b31bcef0cbecb42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To know what we are dealing with, let us plot some of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23d51d3957fdb9efd7f560f1a5903d6c",
     "grade": false,
     "grade_id": "cell-dd2951b9b91dc176",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "labels = ['T-Shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
    "plt.figure(figsize=(25, 9))\n",
    "for i in range(30):\n",
    "    plt.subplot(3, 10, i + 1)\n",
    "    two_d = (np.reshape(X_train[i], (28, 28))).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest', cmap='gray')\n",
    "    plt.title('Label: {0}'.format(labels[y_train[i]]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "952da9bab990a0e4509efefff02f9d5d",
     "grade": false,
     "grade_id": "cell-e36eb7506e1e4f0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The function `get_evaluation` should additionally help you to compute accuracies and provide confusion matrices and appropriate heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a41ce91a878343e2f600c4f313b6627e",
     "grade": false,
     "grade_id": "cell-b2f09d40be401311",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "def get_evaluation(model: sklearn.base.BaseEstimator, X_test: np.ndarray, y_test: np.ndarray) -> tuple[float, float]:\n",
    "    \"\"\"Evaluates the given model and plots a confusion matrix. Also measures the time taken for prediction and the achieved accuracy and returns both.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn.base.BaseEstimator\n",
    "        Trained model that implements the `predict` method.\n",
    "    X_test : (N, K) np.ndarray\n",
    "        Data matrix for testing.\n",
    "    y_test : (N,) np.ndarray\n",
    "        True labels for the test data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of float\n",
    "        - accuracy : float\n",
    "            The accuracy of the fitted classifier on the given test set.\n",
    "        - inference_time : float\n",
    "            The time it took to compute the predictions.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    inference_time = time.time()-start\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print('\\nAccuracy of classifier on test image data: ', accuracy)\n",
    "    print('\\nConfusion matrix: \\n', conf_mat)\n",
    "    print('\\nTime: ', inference_time)\n",
    "    print()\n",
    "\n",
    "    plt.matshow(conf_mat)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbc999ccec1ba8228907abb4101b382a",
     "grade": false,
     "grade_id": "cell-08ed864b64cc88cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "model, _, _, _ = dec_tree(X_train, y_train, X_test, y_test, RSEED)\n",
    "acc_fixed, time_fixed = get_evaluation(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6bdb4f445e96899bf05424d0869281c7",
     "grade": false,
     "grade_id": "cell-93fe67d57b1dabfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 3.1 (25 Points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "355a7d43d39349e2ec00b04ff8e2cd40",
     "grade": false,
     "grade_id": "create_param_grid",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_param_grid() -> dict:\n",
    "    \"\"\"Creates a parameter grid for hyperparameter tuning of a decision tree classifier.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing parameter names (`criterion`, `max_depth`, `splitter`) \n",
    "        and their respective values to be used in grid search.\n",
    "        - 'criterion': list of str\n",
    "            Specifies the function to measure the quality of a split. Options are 'entropy' and 'gini'.\n",
    "        - 'max_depth': list of int\n",
    "            Specifies the maximum depth of the tree. Options are 10, 50, and 100.\n",
    "        - 'splitter': list of str\n",
    "            Specifies the strategy used to split at each node. Options are 'random' and 'best'.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "303ea0be1e12595d639211fd1211eafe",
     "grade": true,
     "grade_id": "create_param_grid_test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "param_grid = create_param_grid()\n",
    "assert isinstance(param_grid, dict), \"The parameter grid is not a dictionary!\"\n",
    "assert len(param_grid.keys()) == 3, \"The number of keys is not correct!\"\n",
    "assert set(param_grid[\"criterion\"]) == {\"entropy\", \"gini\"}, \"The criterion does not have the correct options!\"\n",
    "assert set(param_grid[\"max_depth\"]) == {10, 50, 100}, \"The max_depth does not have the correct options!\"\n",
    "assert set(param_grid[\"splitter\"]) == {\"random\", \"best\"}, \"The splitter does not have the correct options!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4152abe028c6f5436ab6352e5be1eec",
     "grade": false,
     "grade_id": "train_dec_tree",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_dec_tree(X_train: np.ndarray, y_train: np.ndarray, param_grid: dict, n_iter: int, cv: int, seed: int) -> tuple[RandomizedSearchCV, dict]:\n",
    "    \"\"\"Trains a decision tree using cross-validation and returns the best model as well as the best parameter combination. \n",
    "    \n",
    "    Important: Again use (only!) the implementations from sklearn already imported for this assignment and don't forget the seed in (both!) the DecisionTreeClassifier and the RandomizedSearchCV.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : (N, K) np.ndarray\n",
    "        Data matrix used for fitting the tree.\n",
    "    y_train : (N,) np.ndarray\n",
    "        Labels of the train data.\n",
    "    param_grid : dict\n",
    "        Dictionary of parameters for the grid search (RandomizedSearchCV).\n",
    "    n_iter : int\n",
    "        Number of iterations (RandomizedSearchCV)\n",
    "    cv : int\n",
    "        Number of folds in CV (RandomizedSearchCV)\n",
    "    seed : int\n",
    "        Seed for reproducibility, feed to both RandomizedSearchCV and the DecisionTreeClassifier!\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of RandomizedSearchCV, dict, float\n",
    "        - model : RandomizedSearchCV\n",
    "            Fitted best model.\n",
    "        - best_params : dict\n",
    "            Best model parameters as dict.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3413e6e187b65683c28861b56613a6a",
     "grade": true,
     "grade_id": "train_dec_tree_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "model_dec_tree, params_dec_tree = train_dec_tree(X_train, y_train, param_grid, 5, 3, RSEED)\n",
    "assert isinstance(model_dec_tree, RandomizedSearchCV), \"The best decision tree should be of type RandomizedSearchCV!\"\n",
    "assert isinstance(params_dec_tree, dict), \"The best params should be a dictionary!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8486922fe1c7eb93209d46ec2c63a679",
     "grade": false,
     "grade_id": "cell-84742e48700ca7ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "print(\"The best parameters are: {}\".format(params_dec_tree))\n",
    "acc_best, time_best = get_evaluation(model_dec_tree, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "beb98322c6b70025ae10759232e82bde",
     "grade": false,
     "grade_id": "cell-8076dcede6919b0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you did the task correctly, you should obtain a slightly better accuracy than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9da6a2ce9a64b46ec360a8157d2eb73",
     "grade": false,
     "grade_id": "cell-af0930230db0e253",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 4: Comparison of different classifiers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c25f31c2aa8bc578fb7faf169474906a",
     "grade": false,
     "grade_id": "cell-3e3de72dcbfb40e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this task we compare the performace of the Decision Tree Classifier to two other classifiers, namely KNN and SVM, also evaluated on the Fashion MNIST dataset:\n",
    "\n",
    "* **Code 4.1**:\n",
    "    * Implement a function `train_kNN` that creates and fits a KNN classifier with the given `n_neighbors`, `weights`, and `p` parameters (have a look at [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)). This function should return the fitted model.\n",
    "* **Code 4.2**:\n",
    "    * Implement a function `train_SVM` that creates and fits a SVM classifier with `C`, `kernel`, and `gamma` parameters (have a look at [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)). Similar to `train_kNN`, this function should again return the fitted model.\n",
    "* **Plot 4.3**: \n",
    "    * Now, plot the accuracies of the four classifiers (decision tree with fixed parameters, decision tree with the best parameters, KNN, and SVM) in a **bar plot** with y-axis in the range of $[0,1]$ to compare them. To this end, implement the function `plot_accuracies`.\n",
    "    * Make another **bar plot** with the four inference times (in seconds) of the four classifiers. Make sure to use the log-scale on the y-axis. Similar to the previous plot, implement the function `plot_times`.\n",
    "    * Make sure to label all axis and give you plots a fitting title! \n",
    "* **Question 4.3**:\n",
    "    *  Afterwards, answer some questions that correspond to your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f590e12aa6d6f14a29b33f90d6b812d1",
     "grade": false,
     "grade_id": "cell-fd20ea25a0481d62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 4.1 (10 Points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9909364d94a21955965ab6c92f5d21fc",
     "grade": false,
     "grade_id": "train_kNN",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_KNN(X_train: np.ndarray, y_train: np.ndarray, n_neighbors: int, weights: str, p: float) -> KNeighborsClassifier: \n",
    "    \"\"\"Trains a KNN classifier on the given dataset and computes the accuracy on the given test set.\n",
    "    \n",
    "    Again use the sklearn implementation, but no need to set a seed for this classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : (N, K) np.ndarray\n",
    "        Data matrix used for fitting the classifier.\n",
    "    y_train : (N,) np.ndarray\n",
    "        Labels of the train data.\n",
    "    n_neighbors : int\n",
    "        KNN parameter, number of neighbors.\n",
    "    weights : str\n",
    "        Knn parameter, mode for weights.\n",
    "    p : float\n",
    "        Power parameter for the Minkowski metric (see documentation: KNeighborsClassifier)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : KNeighborsClassifier\n",
    "            The fitted classifier.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42b52828e2d030e0901a7938e7d38a41",
     "grade": true,
     "grade_id": "train_kNN_test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "knn_model = train_KNN(X_train, y_train, 5, 'distance', 1)\n",
    "assert isinstance(knn_model, KNeighborsClassifier), \"The returned model is not a KNeighborsClassifier!\"\n",
    "assert knn_model.n_neighbors == 5, \"The number of neighbors is wrong!\"\n",
    "assert knn_model.weights == \"distance\", \"The 'weights' parameter is wrong!\"\n",
    "assert knn_model.p == 1, \"The 'P' parameter is wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cad7118f1a1212058014dc19c6e9754",
     "grade": false,
     "grade_id": "cell-075602c52b8a77fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "knn_acc, knn_time = get_evaluation(knn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "faaaaf55d9332d184f78a5f8cc544f67",
     "grade": false,
     "grade_id": "cell-e9a944121fd22e24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">4.2 Code (10 Points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6874c86d60b3583de787dbebea9b593a",
     "grade": false,
     "grade_id": "train_SVM",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_SVM(X_train: np.ndarray, y_train: np.ndarray, C: float, kernel: str, gamma: str, seed: int) -> SVC:\n",
    "    \"\"\" Trains an SVM classifier on the given dataset.\n",
    "    \n",
    "    Important: Again use the sklearn implementation provided, and don't forget to set the seed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : (N, K) np.ndarray\n",
    "        Data matrix used for fitting the classifier.\n",
    "    y_train : (N,) np.ndarray\n",
    "        Labels of the train data.\n",
    "    C : float\n",
    "        SVM parameter for regularization.\n",
    "    kernel : str\n",
    "        SVM parameter for the type of kernel being.\n",
    "    gamma : str\n",
    "        SVM parameter for kernel coefficient.\n",
    "    seed : int\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : SVC\n",
    "        The fitted classifier.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4f0169869e0d7015a24a227de1146be",
     "grade": true,
     "grade_id": "train_SVM_test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "svm_model = train_SVM(X_train, y_train, 10, 'poly', 'auto', RSEED)\n",
    "assert isinstance(svm_model, SVC), \"The returned model is not a SVC!\"\n",
    "assert svm_model.C == 10, \"The regularization parameter 'C' is wrong!\"\n",
    "assert svm_model.kernel == \"poly\", \"The 'kernel' parameter is wrong!\"\n",
    "assert svm_model.gamma == \"auto\", \"The 'gamma' parameter is wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f08acd0a21885279970bef7b8a415aa",
     "grade": false,
     "grade_id": "cell-48d9a1fda00d123a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "svm_acc, svm_time = get_evaluation(svm_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c4d7979cdcd84ed2486a5e93399f0f3",
     "grade": false,
     "grade_id": "cell-71e07a0430469d37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Plot 4.3 (7 Points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0461bfc8fd6fef7abaf522652c44bafe",
     "grade": true,
     "grade_id": "plot_accuracies",
     "locked": false,
     "points": 3.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracies(accuracies: list[float]):\n",
    "    \"\"\"Creates a bar-plot from the classifier accuracies with a range of [0, 1] on the y-axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    accuracies : list\n",
    "        List of 4 accuracies from the previous exercises.\n",
    "            - dec_tree_fixed : float\n",
    "                Accuracy of the decision tree with fixed parameters.\n",
    "            - dec_tree_bets : float\n",
    "                Accuracy of the decision tree with best parameters.\n",
    "            - kNN : float\n",
    "                Accuracy of the kNN classifier.\n",
    "            - SVM : float\n",
    "                Accuracy of the SVM classifier.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac0986b53185c5a1e0978c92e2bc8b88",
     "grade": true,
     "grade_id": "plot_times",
     "locked": false,
     "points": 3.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_times(times: list[float]):\n",
    "    \"\"\"Creates a bar-plot from the classifier inference times using the log-scale on the y-axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    times : list\n",
    "        List of 4 inference times from the previous exercises.\n",
    "            - dec_tree_fixed : float\n",
    "                Inference time of the decision tree with fixed parameters.\n",
    "            - dec_tree_bets : float\n",
    "                Inference time of the decision tree with best parameters.\n",
    "            - kNN : float\n",
    "                Inference time of the kNN classifier.\n",
    "            - SVM : float\n",
    "                Inference time of the SVM classifier.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a11380d52b40f47c47852915971d5bc",
     "grade": false,
     "grade_id": "cell-6d0700ea6531fd21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nothing to do here, just run the cell.\n",
    "accuracies = [acc_fixed, acc_best, knn_acc, svm_acc]\n",
    "times = [time_fixed, time_best, knn_time, svm_time]\n",
    "\n",
    "plot_accuracies(accuracies)\n",
    "plot_times(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7ba702d40a2a0c35f87aa1840ed134c",
     "grade": false,
     "grade_id": "cell-d0543fdd421470d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Question 4.3 (3 Points):</h3>\n",
    "\n",
    "***Are the following observations correct?***\n",
    "\n",
    "According to the plots above:\n",
    "\n",
    "a4_) The decision tree model is faster in terms of inference time and yields a better accuracy than kNN and SVM. <br>\n",
    "b4_) SVM performs significantly better than kNN.<br>\n",
    "c4_) On such a large dataset, the SVM with kernel has higher inference time than the decision tree, as expected.\n",
    "\n",
    "To answer the question, assign `True` or `False` boolean values to variables in the next cell. For example, if you think that **a4_)** is correct, define a variable `a4_` and set it to `True`, the same applies to **b4_)** and the other options. A non-correctly answered question as well as no answer (i.e. answer “None”) yields 0 points for a specific question.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee45adb4a23f3a7530b769d052a5864f",
     "grade": false,
     "grade_id": "question_4_3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7ed2bc2676ec18cdab1a2a6233b5769",
     "grade": true,
     "grade_id": "a4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert a4_ is not None, \"Store True/False!\"\n",
    "assert a4_ in [True, False], \"Invalid Answer!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "733b97cff192949cb94403509f0e780f",
     "grade": true,
     "grade_id": "b4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert b4_ is not None, \"Store True/False!\"\n",
    "assert b4_ in [True, False], \"Invalid Answer!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1eeac874ac90348dcdbe4fbd8b52cf7b",
     "grade": true,
     "grade_id": "c4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!\n",
    "assert c4_ is not None, \"Store True/False!\"\n",
    "assert c4_ in [True, False], \"Invalid Answer!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e751ac783b1ecc7e1dfd23d8ee652bb",
     "grade": false,
     "grade_id": "cell-98655ea6b33041c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 5: Preparation towards ensembles of trees</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7021ddef311acf7199aadd66ae8dee02",
     "grade": false,
     "grade_id": "cell-a02f983fc1257ed2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In the upcoming lectures, you will discuss ensemble methods for trees that aggregate and/or average single tree models to achieve better performances and/or faster runtimes compared to the ones we used here. Random Forest is a famous example where we average over trees such that the overall variance (of the average) is reduced. We will now formalize the situation:\n",
    "\n",
    "Let's say you have $X_1,...,X_B$ identically distributed random variables which are NOT necessarily independent. Let us denote the variance of a single variable $X_i$ by $\\sigma^2$ and the correlation coefficient between two $X_i$ and $X_j$ for $j \\ne i$ by $\\rho=\\frac{E(X_i X_j)-E(X_i)E(X_j)}{\\sigma^2}$ (keep in mind that all $X_i$'s are identically distributed!). \n",
    "\n",
    "In **Calculation 5.1**, show that $$\\text{Var}\\left(\\frac{1}{B} \\sum_{i=1}^B X_i \\right)=\\rho \\sigma^2 +\\frac{1-\\rho}{B} \\sigma^2. \\quad (1)$$\n",
    "This gives some intuition about how to control the overall variance of averages. One can reduce it e.g. by a small correlation coefficient $\\rho$ and a large number of models $B$.\n",
    "\n",
    "1. Apply the definition of the variance to the given average. \n",
    "2. Split up the resulting double sum in parts with equal and unequal indices. \n",
    "3. Apply the definition for $\\rho$ and replace the sums with the number of occurences of the respective term (how often the indices appear).\n",
    "4. Rewrite this to get the desired solution.\n",
    "\n",
    "**Note:** Denote in your calculation where you tackle each of this points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b55add35917e8fed8ab268e50bc6b13",
     "grade": false,
     "grade_id": "cell-c03f5dfefcbed2ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Calculation 5.1 (15 Points):</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a17cc0ee0e631d09c32682d5a6f93b70",
     "grade": true,
     "grade_id": "calculation_5_1",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "356734b0b4e05b3af569ed06eb258f6ef66038e7268c6bdbb97ecd1a1c609e88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
