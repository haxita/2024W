<html>
<head>
<title>Assignment_2_YisongTang_k12338084.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #6aab73;}
.s5 { color: #2aacb8;}
.s6 { color: #5f826b; font-style: italic;}
.ln { color: #4b5059; font-weight: normal; font-style: normal; }
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Assignment_2_YisongTang_k12338084.ipynb</font>
</center></td></tr></table>
<pre><a name="l1"><span class="ln">1    </span></a><span class="s0">#%% md 
<a name="l2"><span class="ln">2    </span></a></span><span class="s1">&lt;h1 style=&quot;color:rgb(0,120,170)&quot;&gt;Assignment 2: Gaussian Classifier, Bias-Variance Decomposition, Evaluation Measures &lt;/h1&gt; 
<a name="l3"><span class="ln">3    </span></a></span><span class="s0">#%% md 
<a name="l4"><span class="ln">4    </span></a></span><span class="s1">This material, no matter whether in printed or electronic form, 
<a name="l5"><span class="ln">5    </span></a>may be used for personal and non-commercial educational use 
<a name="l6"><span class="ln">6    </span></a>only. Any reproduction of this material, no matter whether as a 
<a name="l7"><span class="ln">7    </span></a>whole or in parts, no matter whether in printed or in electronic 
<a name="l8"><span class="ln">8    </span></a>form, requires explicit prior acceptance of the authors. 
<a name="l9"><span class="ln">9    </span></a></span><span class="s0">#%% md 
<a name="l10"><span class="ln">10   </span></a></span><span class="s1">&lt;h2 style=&quot;color:rgb(0,120,170)&quot;&gt;Automatic Testing Guidelines&lt;/h2&gt; 
<a name="l11"><span class="ln">11   </span></a> 
<a name="l12"><span class="ln">12   </span></a>Automatic unittesting requires you to submit a notebook which contains strictly defined objects. 
<a name="l13"><span class="ln">13   </span></a>Strictness of definition consists of unified shapes, dtypes, variable names and more. 
<a name="l14"><span class="ln">14   </span></a> 
<a name="l15"><span class="ln">15   </span></a>Within the notebook, we provide detailed instruction which you should follow in order to maximise your final grade. 
<a name="l16"><span class="ln">16   </span></a> 
<a name="l17"><span class="ln">17   </span></a>**Name your notebook properly**, follow the pattern in the template name: 
<a name="l18"><span class="ln">18   </span></a> 
<a name="l19"><span class="ln">19   </span></a>**Assignment_N_NameSurname_matrnumber** 
<a name="l20"><span class="ln">20   </span></a>&lt;ol&gt; 
<a name="l21"><span class="ln">21   </span></a>    &lt;li&gt;N - number of assignment&lt;/li&gt; 
<a name="l22"><span class="ln">22   </span></a>    &lt;li&gt;NameSurname - your full name where every part of the name starts with a capital letter, no spaces&lt;/li&gt; 
<a name="l23"><span class="ln">23   </span></a>    &lt;li&gt;matrnumber - you student number on ID card (with k, potenitially with a leading zero)&lt;/li&gt; 
<a name="l24"><span class="ln">24   </span></a>&lt;/ol&gt; 
<a name="l25"><span class="ln">25   </span></a> 
<a name="l26"><span class="ln">26   </span></a>Don't add any cells but use the ones provided by us. All cells have a unique ID so that the unit test can find it, so please do not add or remove any cell! 
<a name="l27"><span class="ln">27   </span></a> 
<a name="l28"><span class="ln">28   </span></a>Always make sure that implemented functions have the correct output and given variables contain the correct data type. In the descriptions for every function you can find information on what datatype an output should have and you should stick to that in order to minimize conflicts with the unittest. Don't import any other packages than listed in the cell with the &quot;imports&quot; tag. 
<a name="l29"><span class="ln">29   </span></a> 
<a name="l30"><span class="ln">30   </span></a>Questions are usually multiple choice (except the task description says otherwise) and can be answered by changing the given variables to either &quot;True&quot; or &quot;False&quot;. &quot;None&quot; is counted as a wrong answer in any case! 
<a name="l31"><span class="ln">31   </span></a> 
<a name="l32"><span class="ln">32   </span></a>**Note:** Never use variables you defined in another cell in your functions directly; always pass them to the function as a parameter. In the unitest, they won't be available either. If you want to make sure that everything is executable for the unittest, try executing cells/functions individually (instead of running the whole notebook). 
<a name="l33"><span class="ln">33   </span></a></span><span class="s0">#%% md 
<a name="l34"><span class="ln">34   </span></a></span><span class="s1">&lt;h2 style=&quot;color:rgb(0,120,170)&quot;&gt;Task 1: Gaussian classifier: visualization &amp; parameter estimation&lt;/h2&gt; 
<a name="l35"><span class="ln">35   </span></a> 
<a name="l36"><span class="ln">36   </span></a>The goal of this task is to explore the given (artificial) data before diving into the classification function. To do this, we will use `matplotlib` to plot the data set and `numpy` to estimate the means &amp; covariance matrices of the classes as well as the probability of encountering a positive/negative example. 
<a name="l37"><span class="ln">37   </span></a> 
<a name="l38"><span class="ln">38   </span></a>* **Plot 1.1**: Visualize the data stored in `normal.csv` with two different colors using a scatter plot and store it in the given variable. Always label the axes of all your plots. We also suggest to make a plot legend indicating which color belongs to 
<a name="l39"><span class="ln">39   </span></a>which label. 
<a name="l40"><span class="ln">40   </span></a>* **Question 1.1**: Answer 2 questions regarding the data depicted in the plot. 
<a name="l41"><span class="ln">41   </span></a>* **Code 1.2**: We assume that the data is distributed according to a two-dimensional (bivariate) normal distribution: 
<a name="l42"><span class="ln">42   </span></a>    - Write a function that estimates the mean and covariance matrix for the entire dataset, the means and covariance matrices for each class, and the probabilities $p(y=+1)$ and $p(y=-1)$. 
<a name="l43"><span class="ln">43   </span></a>    - Return a tuple containing the results (the resulting list should be of length 8). The datatype for `meanX`, `covX`, `meanXpos`, `covXpos`, `meanXneg`, and `covXneg` should be a numpy array, for $p(y=+1)$ and $p(y=-1)$ it should be float. 
<a name="l44"><span class="ln">44   </span></a></span><span class="s0">#%% md 
<a name="l45"><span class="ln">45   </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Plot 1.1 (2 Points):&lt;/h3&gt; 
<a name="l46"><span class="ln">46   </span></a></span><span class="s0">#%% 
<a name="l47"><span class="ln">47   </span></a># Nothing to do here, just run the cell.</span>
<a name="l48"><span class="ln">48   </span></a><span class="s2">import </span><span class="s1">sklearn</span>
<a name="l49"><span class="ln">49   </span></a><span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<a name="l50"><span class="ln">50   </span></a><span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<a name="l51"><span class="ln">51   </span></a><span class="s2">import </span><span class="s1">matplotlib</span><span class="s3">.</span><span class="s1">pyplot </span><span class="s2">as </span><span class="s1">plt</span>
<a name="l52"><span class="ln">52   </span></a><span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model </span><span class="s2">import </span><span class="s1">LinearRegression</span>
<a name="l53"><span class="ln">53   </span></a><span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">preprocessing </span><span class="s2">import </span><span class="s1">PolynomialFeatures</span>
<a name="l54"><span class="ln">54   </span></a><span class="s0">#%% 
<a name="l55"><span class="ln">55   </span></a># Nothing to do here, just run the cell.</span>
<a name="l56"><span class="ln">56   </span></a><span class="s1">Z </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">genfromtxt</span><span class="s3">(</span><span class="s4">'normal.csv'</span><span class="s3">, </span><span class="s1">delimiter</span><span class="s3">=</span><span class="s4">','</span><span class="s3">)</span>
<a name="l57"><span class="ln">57   </span></a><span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">Z</span><span class="s3">[:,:-</span><span class="s5">1</span><span class="s3">].</span><span class="s1">astype</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s1">Z</span><span class="s3">[:,-</span><span class="s5">1</span><span class="s3">].</span><span class="s1">astype</span><span class="s3">(</span><span class="s1">int</span><span class="s3">)</span>
<a name="l58"><span class="ln">58   </span></a><span class="s0">#%% 
<a name="l59"><span class="ln">59   </span></a></span><span class="s2">def </span><span class="s1">scatter_plot</span><span class="s3">(</span><span class="s1">X</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">y</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">):</span>
<a name="l60"><span class="ln">60   </span></a>    <span class="s6">&quot;&quot;&quot;Creates a scatter-plot for the dataset X with labels y. 
<a name="l61"><span class="ln">61   </span></a> 
<a name="l62"><span class="ln">62   </span></a>    Parameters 
<a name="l63"><span class="ln">63   </span></a>    ---------- 
<a name="l64"><span class="ln">64   </span></a>    X : (N, K) np.ndarray 
<a name="l65"><span class="ln">65   </span></a>        Data to plot. 
<a name="l66"><span class="ln">66   </span></a>    y : (N,) np.ndarray 
<a name="l67"><span class="ln">67   </span></a>        labels of the data. 
<a name="l68"><span class="ln">68   </span></a>    &quot;&quot;&quot;</span>
<a name="l69"><span class="ln">69   </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l70"><span class="ln">70   </span></a>    <span class="s1">pos </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">y </span><span class="s3">== </span><span class="s5">1</span><span class="s3">]</span>
<a name="l71"><span class="ln">71   </span></a>    <span class="s1">neg </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">y </span><span class="s3">== -</span><span class="s5">1</span><span class="s3">]</span>
<a name="l72"><span class="ln">72   </span></a>    
<a name="l73"><span class="ln">73   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">figure</span><span class="s3">(</span><span class="s1">figsize</span><span class="s3">=(</span><span class="s5">8</span><span class="s3">,</span><span class="s5">6</span><span class="s3">))</span>
<a name="l74"><span class="ln">74   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">scatter</span><span class="s3">(</span><span class="s1">pos</span><span class="s3">[:,</span><span class="s5">0</span><span class="s3">], </span><span class="s1">pos</span><span class="s3">[:,</span><span class="s5">1</span><span class="s3">], </span><span class="s1">c</span><span class="s3">=</span><span class="s4">'blue'</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Positive (+1)'</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s5">0.6</span><span class="s3">)</span>
<a name="l75"><span class="ln">75   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">scatter</span><span class="s3">(</span><span class="s1">neg</span><span class="s3">[:,</span><span class="s5">0</span><span class="s3">], </span><span class="s1">neg</span><span class="s3">[:,</span><span class="s5">1</span><span class="s3">], </span><span class="s1">c</span><span class="s3">=</span><span class="s4">'red'</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Negative (-1)'</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s5">0.6</span><span class="s3">)</span>
<a name="l76"><span class="ln">76   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">xlabel</span><span class="s3">(</span><span class="s4">'x1'</span><span class="s3">)</span>
<a name="l77"><span class="ln">77   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">ylabel</span><span class="s3">(</span><span class="s4">'x2'</span><span class="s3">)</span>
<a name="l78"><span class="ln">78   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">legend</span><span class="s3">()</span>
<a name="l79"><span class="ln">79   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">title</span><span class="s3">(</span><span class="s4">'Scatter Plot of Normal Dataset'</span><span class="s3">)</span>
<a name="l80"><span class="ln">80   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">grid</span><span class="s3">(</span><span class="s2">True</span><span class="s3">)</span>
<a name="l81"><span class="ln">81   </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">show</span><span class="s3">()</span>
<a name="l82"><span class="ln">82   </span></a><span class="s0">#%% 
<a name="l83"><span class="ln">83   </span></a># Nothing to do here, just run the cell.</span>
<a name="l84"><span class="ln">84   </span></a><span class="s1">scatter_plot</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
<a name="l85"><span class="ln">85   </span></a><span class="s0">#%% md 
<a name="l86"><span class="ln">86   </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Question 1.1 (2 Points):&lt;/h3&gt; 
<a name="l87"><span class="ln">87   </span></a></span><span class="s0">#%% md 
<a name="l88"><span class="ln">88   </span></a></span><span class="s1">***Answer the following yes/no questions concerning the distribution of the data:*** 
<a name="l89"><span class="ln">89   </span></a> 
<a name="l90"><span class="ln">90   </span></a>a1_) Would a linear regression method be an optimal choice for this task?&lt;br&gt; 
<a name="l91"><span class="ln">91   </span></a>b1_) Would a linear classifier achieve a better performance than 25% misclassification?&lt;br&gt; 
<a name="l92"><span class="ln">92   </span></a> 
<a name="l93"><span class="ln">93   </span></a>To answer the question, assign &quot;True&quot; or &quot;False&quot; boolean values to variables in the next cell. For example, if you think that **a1_)** is correct, define a variable `a1_` and set it to `True`, the same applies to **b1_)**. A non-correctly answered question as well as no answer (i.e. answer “None”) yields 0 points for a specific question.&lt;br&gt; 
<a name="l94"><span class="ln">94   </span></a>&lt;b&gt;Note:&lt;/b&gt; Do not reuse these variable names. They are used for testing. 
<a name="l95"><span class="ln">95   </span></a></span><span class="s0">#%% 
<a name="l96"><span class="ln">96   </span></a># YOUR CODE HERE</span>
<a name="l97"><span class="ln">97   </span></a><span class="s1">a1_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l98"><span class="ln">98   </span></a><span class="s1">b1_ </span><span class="s3">= </span><span class="s2">True</span>
<a name="l99"><span class="ln">99   </span></a><span class="s0">#%% 
<a name="l100"><span class="ln">100  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l101"><span class="ln">101  </span></a><span class="s2">assert </span><span class="s1">a1_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l102"><span class="ln">102  </span></a><span class="s2">assert </span><span class="s1">a1_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l103"><span class="ln">103  </span></a><span class="s0">#%% 
<a name="l104"><span class="ln">104  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l105"><span class="ln">105  </span></a><span class="s2">assert </span><span class="s1">b1_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l106"><span class="ln">106  </span></a><span class="s2">assert </span><span class="s1">b1_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l107"><span class="ln">107  </span></a><span class="s0">#%% md 
<a name="l108"><span class="ln">108  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Code 1.2 (6 Points):&lt;/h3&gt; 
<a name="l109"><span class="ln">109  </span></a></span><span class="s0">#%% 
<a name="l110"><span class="ln">110  </span></a></span><span class="s2">def </span><span class="s1">est_mean_cov</span><span class="s3">(</span><span class="s1">X</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">y</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">) </span><span class="s1">-&gt; tuple</span><span class="s3">[</span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">]:</span>
<a name="l111"><span class="ln">111  </span></a>    <span class="s6">&quot;&quot;&quot;Estimate means and covariance matrices from the given data, as well as the probability of encountering a positive or negative example. 
<a name="l112"><span class="ln">112  </span></a>    Utilize numpy functions for calculating the results. 
<a name="l113"><span class="ln">113  </span></a> 
<a name="l114"><span class="ln">114  </span></a>    Parameters 
<a name="l115"><span class="ln">115  </span></a>    ---------- 
<a name="l116"><span class="ln">116  </span></a>    X : (N, K) np.ndarray 
<a name="l117"><span class="ln">117  </span></a>        Data matrix of shape (n_samples, n_features). 
<a name="l118"><span class="ln">118  </span></a>    y : (N,) np.ndarray 
<a name="l119"><span class="ln">119  </span></a>        Data vector of shape (n_samples,), with binary labels (e.g., +1 or -1). 
<a name="l120"><span class="ln">120  </span></a> 
<a name="l121"><span class="ln">121  </span></a>    Returns 
<a name="l122"><span class="ln">122  </span></a>    ------- 
<a name="l123"><span class="ln">123  </span></a>    meanX : (K,) np.ndarray 
<a name="l124"><span class="ln">124  </span></a>        Mean vector (one entry per feature) for the entire dataset.  
<a name="l125"><span class="ln">125  </span></a>    covX : (K, K) np.ndarray 
<a name="l126"><span class="ln">126  </span></a>        Covariance matrix for the entire dataset. 
<a name="l127"><span class="ln">127  </span></a>    meanXpos : (K,) np.ndarray 
<a name="l128"><span class="ln">128  </span></a>        Mean vector (one entry per feature) for positive samples. 
<a name="l129"><span class="ln">129  </span></a>    covXpos : (K, K) np.ndarray 
<a name="l130"><span class="ln">130  </span></a>        Covariance matrix for positive samples. 
<a name="l131"><span class="ln">131  </span></a>    meanXneg : (K,) np.ndarray 
<a name="l132"><span class="ln">132  </span></a>        Mean vector (one entry per feature) for negative samples. 
<a name="l133"><span class="ln">133  </span></a>    covXneg : (K, K) np.ndarray 
<a name="l134"><span class="ln">134  </span></a>        Covariance matrix for negative samples. 
<a name="l135"><span class="ln">135  </span></a>    p_ypos : float 
<a name="l136"><span class="ln">136  </span></a>        Probability of a positive example, p(y = +1). 
<a name="l137"><span class="ln">137  </span></a>    p_yneg : float 
<a name="l138"><span class="ln">138  </span></a>        Probability of a negative example, p(y = -1). 
<a name="l139"><span class="ln">139  </span></a>    &quot;&quot;&quot;</span>
<a name="l140"><span class="ln">140  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l141"><span class="ln">141  </span></a>    
<a name="l142"><span class="ln">142  </span></a>    <span class="s1">meanX </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
<a name="l143"><span class="ln">143  </span></a>    <span class="s1">covX </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">cov</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">rowvar</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>
<a name="l144"><span class="ln">144  </span></a>    
<a name="l145"><span class="ln">145  </span></a>    <span class="s1">Xpos </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">y </span><span class="s3">== </span><span class="s5">1</span><span class="s3">]</span>
<a name="l146"><span class="ln">146  </span></a>    <span class="s1">meanXpos </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">Xpos</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
<a name="l147"><span class="ln">147  </span></a>    <span class="s1">covXpos </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">cov</span><span class="s3">(</span><span class="s1">Xpos</span><span class="s3">, </span><span class="s1">rowvar</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>
<a name="l148"><span class="ln">148  </span></a>    
<a name="l149"><span class="ln">149  </span></a>    <span class="s1">Xneg </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">y </span><span class="s3">== -</span><span class="s5">1</span><span class="s3">]</span>
<a name="l150"><span class="ln">150  </span></a>    <span class="s1">meanXneg </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">Xneg</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
<a name="l151"><span class="ln">151  </span></a>    <span class="s1">covXneg </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">cov</span><span class="s3">(</span><span class="s1">Xneg</span><span class="s3">, </span><span class="s1">rowvar</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>
<a name="l152"><span class="ln">152  </span></a>    
<a name="l153"><span class="ln">153  </span></a>    <span class="s1">N </span><span class="s3">= </span><span class="s1">len</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
<a name="l154"><span class="ln">154  </span></a>    <span class="s1">p_ypos </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">y </span><span class="s3">== </span><span class="s5">1</span><span class="s3">) / </span><span class="s1">N</span>
<a name="l155"><span class="ln">155  </span></a>    <span class="s1">p_yneg </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">y </span><span class="s3">== -</span><span class="s5">1</span><span class="s3">) / </span><span class="s1">N</span>
<a name="l156"><span class="ln">156  </span></a>    
<a name="l157"><span class="ln">157  </span></a>    <span class="s2">return </span><span class="s1">meanX</span><span class="s3">, </span><span class="s1">covX</span><span class="s3">, </span><span class="s1">meanXpos</span><span class="s3">, </span><span class="s1">covXpos</span><span class="s3">, </span><span class="s1">meanXneg</span><span class="s3">, </span><span class="s1">covXneg</span><span class="s3">, </span><span class="s1">p_ypos</span><span class="s3">, </span><span class="s1">p_yneg</span>
<a name="l158"><span class="ln">158  </span></a><span class="s0">#%% 
<a name="l159"><span class="ln">159  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l160"><span class="ln">160  </span></a><span class="s1">res </span><span class="s3">= </span><span class="s1">est_mean_cov</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
<a name="l161"><span class="ln">161  </span></a><span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">res</span><span class="s3">) == </span><span class="s5">8</span><span class="s3">, </span><span class="s4">&quot;The number of outputs is wrong!&quot;</span>
<a name="l162"><span class="ln">162  </span></a><span class="s1">meanX</span><span class="s3">, </span><span class="s1">covX</span><span class="s3">, </span><span class="s1">meanXpos</span><span class="s3">, </span><span class="s1">covXpos</span><span class="s3">, </span><span class="s1">meanXneg</span><span class="s3">, </span><span class="s1">covXneg</span><span class="s3">, </span><span class="s1">p_ypos</span><span class="s3">, </span><span class="s1">p_yneg </span><span class="s3">= </span><span class="s1">res</span>
<a name="l163"><span class="ln">163  </span></a><span class="s0">#%% 
<a name="l164"><span class="ln">164  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l165"><span class="ln">165  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">meanX</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The mean of the whole data is not a np.ndarray!&quot;</span>
<a name="l166"><span class="ln">166  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">meanX</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s5">0.057087306</span><span class="s3">,  </span><span class="s5">0.064688794</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l167"><span class="ln">167  </span></a><span class="s0">#%% 
<a name="l168"><span class="ln">168  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l169"><span class="ln">169  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">covX</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The covariance of the whole data is not a np.ndarray!&quot;</span>
<a name="l170"><span class="ln">170  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">covX</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s5">4.321541110644044</span><span class="s3">, </span><span class="s5">0.9361894568083656</span><span class="s3">], [</span><span class="s5">0.9361894568083656</span><span class="s3">, </span><span class="s5">6.752613915214139</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l171"><span class="ln">171  </span></a><span class="s0">#%% 
<a name="l172"><span class="ln">172  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l173"><span class="ln">173  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">meanXpos</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The mean of the positive samples is not a np.ndarray!&quot;</span>
<a name="l174"><span class="ln">174  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">meanXpos</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s5">0.14820707</span><span class="s3">, -</span><span class="s5">0.037901126</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l175"><span class="ln">175  </span></a><span class="s0">#%% 
<a name="l176"><span class="ln">176  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l177"><span class="ln">177  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The covariance of the positive sample is not a np.ndarray!&quot;</span>
<a name="l178"><span class="ln">178  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s5">8.44226725</span><span class="s3">, </span><span class="s5">2.01781502</span><span class="s3">], [</span><span class="s5">2.01781502</span><span class="s3">, </span><span class="s5">0.95332618</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l179"><span class="ln">179  </span></a><span class="s0">#%% 
<a name="l180"><span class="ln">180  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l181"><span class="ln">181  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">meanXneg</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The mean of the negative samples is not a np.ndarray!&quot;</span>
<a name="l182"><span class="ln">182  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">meanXneg</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">0.03403238</span><span class="s3">, </span><span class="s5">0.16727877</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l183"><span class="ln">183  </span></a><span class="s0">#%% 
<a name="l184"><span class="ln">184  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l185"><span class="ln">185  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">covXneg</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The covariance of the negative sample is not a np.ndarray!&quot;</span>
<a name="l186"><span class="ln">186  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">covXneg</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[ </span><span class="s5">0.19860714</span><span class="s3">, -</span><span class="s5">0.16106351</span><span class="s3">], [-</span><span class="s5">0.16106351</span><span class="s3">, </span><span class="s5">12.55336585</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l187"><span class="ln">187  </span></a><span class="s0">#%% 
<a name="l188"><span class="ln">188  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l189"><span class="ln">189  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">p_ypos</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The probably of a positive sample is not a float!&quot;</span>
<a name="l190"><span class="ln">190  </span></a><span class="s2">assert </span><span class="s1">p_ypos </span><span class="s3">== </span><span class="s5">0.5</span><span class="s3">, </span><span class="s4">&quot;The probability of a positive sample is not correct!&quot;</span>
<a name="l191"><span class="ln">191  </span></a><span class="s0">#%% 
<a name="l192"><span class="ln">192  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l193"><span class="ln">193  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">p_yneg</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The probability of a negative sample is not a float!&quot;</span>
<a name="l194"><span class="ln">194  </span></a><span class="s2">assert </span><span class="s1">p_yneg </span><span class="s3">== </span><span class="s5">0.5</span><span class="s3">, </span><span class="s4">&quot;The probability of a negative sample is not correct!&quot;</span>
<a name="l195"><span class="ln">195  </span></a><span class="s0">#%% 
<a name="l196"><span class="ln">196  </span></a># Nothing to do here, just run the cell.</span>
<a name="l197"><span class="ln">197  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Entire dataset:</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l198"><span class="ln">198  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Mean = &quot;</span><span class="s3">, </span><span class="s1">meanX</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l199"><span class="ln">199  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Covariance:&quot;</span><span class="s3">)</span>
<a name="l200"><span class="ln">200  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">covX</span><span class="s3">,</span><span class="s1">columns</span><span class="s3">=[</span><span class="s4">&quot;x1&quot;</span><span class="s3">,</span><span class="s4">&quot;x2&quot;</span><span class="s3">],</span><span class="s1">index</span><span class="s3">=[</span><span class="s4">&quot;x1&quot;</span><span class="s3">,</span><span class="s4">&quot;x2&quot;</span><span class="s3">]),</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l201"><span class="ln">201  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s5">30 </span><span class="s3">* </span><span class="s4">&quot;=&quot;</span><span class="s3">)</span>
<a name="l202"><span class="ln">202  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Positive class:</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l203"><span class="ln">203  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Mean = &quot;</span><span class="s3">, </span><span class="s1">meanXpos</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l204"><span class="ln">204  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Covariance:&quot;</span><span class="s3">)</span>
<a name="l205"><span class="ln">205  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">,</span><span class="s1">columns</span><span class="s3">=[</span><span class="s4">&quot;x1&quot;</span><span class="s3">,</span><span class="s4">&quot;x2&quot;</span><span class="s3">],</span><span class="s1">index</span><span class="s3">=[</span><span class="s4">&quot;x1&quot;</span><span class="s3">,</span><span class="s4">&quot;x2&quot;</span><span class="s3">]),</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l206"><span class="ln">206  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;p(y=+1) =&quot;</span><span class="s3">, </span><span class="s1">p_ypos</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l207"><span class="ln">207  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s5">30 </span><span class="s3">* </span><span class="s4">&quot;=&quot;</span><span class="s3">)</span>
<a name="l208"><span class="ln">208  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Negative class:</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l209"><span class="ln">209  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Mean =&quot;</span><span class="s3">, </span><span class="s1">meanXneg</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l210"><span class="ln">210  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Covariance:&quot;</span><span class="s3">)</span>
<a name="l211"><span class="ln">211  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">covXneg</span><span class="s3">,</span><span class="s1">columns</span><span class="s3">=[</span><span class="s4">&quot;x1&quot;</span><span class="s3">,</span><span class="s4">&quot;x2&quot;</span><span class="s3">],</span><span class="s1">index</span><span class="s3">=[</span><span class="s4">&quot;x1&quot;</span><span class="s3">,</span><span class="s4">&quot;x2&quot;</span><span class="s3">]),</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l212"><span class="ln">212  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;p(y=-1) =&quot;</span><span class="s3">, </span><span class="s1">p_yneg</span><span class="s3">)</span>
<a name="l213"><span class="ln">213  </span></a><span class="s0">#%% md 
<a name="l214"><span class="ln">214  </span></a></span><span class="s1">&lt;h2 style=&quot;color:rgb(0,120,170)&quot;&gt;Task 2: Gaussian classifier: compute classifier &amp; visualization&lt;/h2&gt; 
<a name="l215"><span class="ln">215  </span></a> 
<a name="l216"><span class="ln">216  </span></a>Now that we got a good idea of the data, we want to implement a classifier and visualize it. 
<a name="l217"><span class="ln">217  </span></a> 
<a name="l218"><span class="ln">218  </span></a>- **Code 2.1**: Compute an optimal classification function $g_opt$ in `calc_g_opt()`. To do this, you should: 
<a name="l219"><span class="ln">219  </span></a>    - Calculate the values of the corresponding parameters $\mathbf{A}$, $\mathbf{b}$ and $c$ in the provided functions (have a look at the lecture slides). 
<a name="l220"><span class="ln">220  </span></a>    - Store the results in the given parameters `A` (np.ndarray), `b` (np.ndarray), `c` (float), and `g_opt` (np.ndarray). 
<a name="l221"><span class="ln">221  </span></a>    - Print the values of $\mathbf{A}$, $\mathbf{b}$ and $c$ that you have calculated with their respective shapes. 
<a name="l222"><span class="ln">222  </span></a>    - Note: You can reuse items from the previous task. 
<a name="l223"><span class="ln">223  </span></a>* **Plot 2.2**: Visualize the classification function and the original data samples from Task 1.1. in **one** two-dimensional plot. I.e., the plot should show the data samples -- blue for positive and orange for negative -- and also show the classification function (500x500 grid points) in the corresponding (or similar) colors. For the grid points: use alpha=0.05 for opaquness and s=1 for the marker size. The decision boundary will become visible as the line separating the two classification territories. Again: Label the axes and plot a legend. 
<a name="l224"><span class="ln">224  </span></a>* **Question 2.2**: Answer 2 questions about the result. 
<a name="l225"><span class="ln">225  </span></a></span><span class="s0">#%% md 
<a name="l226"><span class="ln">226  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Code 2.1 (10 Points):&lt;/h3&gt; 
<a name="l227"><span class="ln">227  </span></a></span><span class="s0">#%% 
<a name="l228"><span class="ln">228  </span></a></span><span class="s2">def </span><span class="s1">calc_A</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">covXneg</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">) </span><span class="s1">-&gt; np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">:</span>
<a name="l229"><span class="ln">229  </span></a>    <span class="s6">&quot;&quot;&quot;Calculate the desired parameter A based on covariance matrices and return the result. 
<a name="l230"><span class="ln">230  </span></a> 
<a name="l231"><span class="ln">231  </span></a>    Parameters 
<a name="l232"><span class="ln">232  </span></a>    ---------- 
<a name="l233"><span class="ln">233  </span></a>    covXpos : (K, K) np.ndarray 
<a name="l234"><span class="ln">234  </span></a>        Covariance matrix of positive samples. 
<a name="l235"><span class="ln">235  </span></a>    covXneg : (K, K) np.ndarray 
<a name="l236"><span class="ln">236  </span></a>        Covariance matrix of negative samples. 
<a name="l237"><span class="ln">237  </span></a>         
<a name="l238"><span class="ln">238  </span></a>    Returns 
<a name="l239"><span class="ln">239  </span></a>    ------- 
<a name="l240"><span class="ln">240  </span></a>    A : (K, K) np.ndarray 
<a name="l241"><span class="ln">241  </span></a>        Result of the parameter calculation. 
<a name="l242"><span class="ln">242  </span></a>    &quot;&quot;&quot;</span>
<a name="l243"><span class="ln">243  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l244"><span class="ln">244  </span></a>    <span class="s0"># A = covXneg^{-1} - covXpos^{-1}</span>
<a name="l245"><span class="ln">245  </span></a>    <span class="s1">inv_covXpos </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">inv</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">)</span>
<a name="l246"><span class="ln">246  </span></a>    <span class="s1">inv_covXneg </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">inv</span><span class="s3">(</span><span class="s1">covXneg</span><span class="s3">)</span>
<a name="l247"><span class="ln">247  </span></a>    <span class="s1">A </span><span class="s3">= </span><span class="s1">inv_covXpos </span><span class="s3">- </span><span class="s1">inv_covXneg </span>
<a name="l248"><span class="ln">248  </span></a>    <span class="s2">return </span><span class="s1">A</span>
<a name="l249"><span class="ln">249  </span></a><span class="s0">#%% 
<a name="l250"><span class="ln">250  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l251"><span class="ln">251  </span></a><span class="s1">A </span><span class="s3">= </span><span class="s1">calc_A</span><span class="s3">(</span>
<a name="l252"><span class="ln">252  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s5">8.44226725</span><span class="s3">, </span><span class="s5">2.01781502</span><span class="s3">], [</span><span class="s5">2.01781502</span><span class="s3">, </span><span class="s5">0.95332618</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l253"><span class="ln">253  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[ </span><span class="s5">0.19860714</span><span class="s3">, -</span><span class="s5">0.16106351</span><span class="s3">], [-</span><span class="s5">0.16106351</span><span class="s3">, </span><span class="s5">12.55336585</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">)</span>
<a name="l254"><span class="ln">254  </span></a><span class="s3">)</span>
<a name="l255"><span class="ln">255  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">A</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;Parameter A is not a np.ndarray!&quot;</span>
<a name="l256"><span class="ln">256  </span></a><span class="s2">assert </span><span class="s1">A</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s5">2</span><span class="s3">, </span><span class="s5">2</span><span class="s3">), </span><span class="s4">&quot;Parameter A does not have the correct shape!&quot;</span>
<a name="l257"><span class="ln">257  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">A</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[-</span><span class="s5">4.8482757</span><span class="s3">, -</span><span class="s5">0.5726957</span><span class="s3">], [-</span><span class="s5">0.5726957</span><span class="s3">,  </span><span class="s5">2.0424585</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l258"><span class="ln">258  </span></a><span class="s0">#%% 
<a name="l259"><span class="ln">259  </span></a></span><span class="s2">def </span><span class="s1">calc_b</span><span class="s3">(</span><span class="s1">meanXpos</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">covXpos</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">meanXneg</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">covXneg</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">) </span><span class="s1">-&gt; np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">:</span>
<a name="l260"><span class="ln">260  </span></a>    <span class="s6">&quot;&quot;&quot;This function should contain the calculations for the respective b parameter and return the result. 
<a name="l261"><span class="ln">261  </span></a>     
<a name="l262"><span class="ln">262  </span></a>    Parameters 
<a name="l263"><span class="ln">263  </span></a>    ---------- 
<a name="l264"><span class="ln">264  </span></a>    meanXpos : (K,) np.ndarray 
<a name="l265"><span class="ln">265  </span></a>        Mean vector of positive samples. 
<a name="l266"><span class="ln">266  </span></a>    covXpos : (K, K) np.ndarray 
<a name="l267"><span class="ln">267  </span></a>        Covariance matrix of positive samples. 
<a name="l268"><span class="ln">268  </span></a>    meanXneg : (K,) np.ndarray 
<a name="l269"><span class="ln">269  </span></a>        Mean vector of negative samples. 
<a name="l270"><span class="ln">270  </span></a>    covXneg : (K, K) np.ndarray 
<a name="l271"><span class="ln">271  </span></a>        Covariance matrix of negative samples. 
<a name="l272"><span class="ln">272  </span></a> 
<a name="l273"><span class="ln">273  </span></a>    Returns 
<a name="l274"><span class="ln">274  </span></a>    ------- 
<a name="l275"><span class="ln">275  </span></a>    b : (K,) np.ndarray 
<a name="l276"><span class="ln">276  </span></a>        Result of the parameter calculation. 
<a name="l277"><span class="ln">277  </span></a>    &quot;&quot;&quot;</span>
<a name="l278"><span class="ln">278  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l279"><span class="ln">279  </span></a>    <span class="s0"># b = (covXneg^{-1} * meanXneg) - (covXpos^{-1} * meanXpos)</span>
<a name="l280"><span class="ln">280  </span></a>    <span class="s1">inv_covXpos </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">inv</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">)</span>
<a name="l281"><span class="ln">281  </span></a>    <span class="s1">inv_covXneg </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">inv</span><span class="s3">(</span><span class="s1">covXneg</span><span class="s3">)</span>
<a name="l282"><span class="ln">282  </span></a>    <span class="s1">b </span><span class="s3">= </span><span class="s1">inv_covXpos </span><span class="s3">@ </span><span class="s1">meanXpos </span><span class="s3">- </span><span class="s1">inv_covXneg </span><span class="s3">@ </span><span class="s1">meanXneg </span>
<a name="l283"><span class="ln">283  </span></a>    <span class="s2">return </span><span class="s1">b</span>
<a name="l284"><span class="ln">284  </span></a><span class="s0">#%% 
<a name="l285"><span class="ln">285  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l286"><span class="ln">286  </span></a><span class="s1">b </span><span class="s3">= </span><span class="s1">calc_b</span><span class="s3">(</span>
<a name="l287"><span class="ln">287  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s5">0.14820707</span><span class="s3">, -</span><span class="s5">0.037901126</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l288"><span class="ln">288  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s5">8.44226725</span><span class="s3">, </span><span class="s5">2.01781502</span><span class="s3">], [</span><span class="s5">2.01781502</span><span class="s3">, </span><span class="s5">0.95332618</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l289"><span class="ln">289  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">0.03403238</span><span class="s3">, </span><span class="s5">0.16727877</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l290"><span class="ln">290  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[ </span><span class="s5">0.19860714</span><span class="s3">, -</span><span class="s5">0.16106351</span><span class="s3">], [-</span><span class="s5">0.16106351</span><span class="s3">, </span><span class="s5">12.55336585</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">)</span>
<a name="l291"><span class="ln">291  </span></a><span class="s3">)</span>
<a name="l292"><span class="ln">292  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">b</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;Parameter b is not a np.ndarray!&quot;</span>
<a name="l293"><span class="ln">293  </span></a><span class="s2">assert </span><span class="s1">b</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s5">2</span><span class="s3">,), </span><span class="s4">&quot;Parameter b does not have the correct shape!&quot;</span>
<a name="l294"><span class="ln">294  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">b</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s5">0.2003752 </span><span class="s3">, -</span><span class="s5">0.02094711</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l295"><span class="ln">295  </span></a><span class="s0">#%% 
<a name="l296"><span class="ln">296  </span></a></span><span class="s2">def </span><span class="s1">calc_c</span><span class="s3">(</span><span class="s1">meanXpos</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">covXpos</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">meanXneg</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">covXneg</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">p_ypos</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">p_yneg</span><span class="s3">: </span><span class="s1">float</span><span class="s3">) </span><span class="s1">-&gt; float</span><span class="s3">:</span>
<a name="l297"><span class="ln">297  </span></a>    <span class="s6">&quot;&quot;&quot;This function should contain the calculations for the respective c parameter and return the result. 
<a name="l298"><span class="ln">298  </span></a>     
<a name="l299"><span class="ln">299  </span></a>    Parameters 
<a name="l300"><span class="ln">300  </span></a>    ---------- 
<a name="l301"><span class="ln">301  </span></a>    meanXpos : (K,) np.ndarray 
<a name="l302"><span class="ln">302  </span></a>        Mean vector of positive samples. 
<a name="l303"><span class="ln">303  </span></a>    covXpos : (K, K) np.ndarray 
<a name="l304"><span class="ln">304  </span></a>        Covariance matrix of positive samples. 
<a name="l305"><span class="ln">305  </span></a>    meanXneg : (K,) np.ndarray 
<a name="l306"><span class="ln">306  </span></a>        Mean vector of negative samples. 
<a name="l307"><span class="ln">307  </span></a>    covXneg : (K, K) np.ndarray 
<a name="l308"><span class="ln">308  </span></a>        Covariance matrix of negative samples. 
<a name="l309"><span class="ln">309  </span></a>    p_ypos : float 
<a name="l310"><span class="ln">310  </span></a>        Probability of encountering a positive sample. 
<a name="l311"><span class="ln">311  </span></a>    p_yneg : float 
<a name="l312"><span class="ln">312  </span></a>        Probability of encountering a negative sample. 
<a name="l313"><span class="ln">313  </span></a> 
<a name="l314"><span class="ln">314  </span></a>    Returns 
<a name="l315"><span class="ln">315  </span></a>    ------- 
<a name="l316"><span class="ln">316  </span></a>    c : float 
<a name="l317"><span class="ln">317  </span></a>        Result of the parameter calculation. 
<a name="l318"><span class="ln">318  </span></a>    &quot;&quot;&quot; </span>
<a name="l319"><span class="ln">319  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l320"><span class="ln">320  </span></a>    <span class="s0"># c = -0.5 * (meanXneg.T @ inv_covXneg @ meanXneg - meanXpos.T @ inv_covXpos @ meanXpos) + np.log(p_ypos / p_yneg)</span>
<a name="l321"><span class="ln">321  </span></a>    <span class="s1">inv_covXpos </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">inv</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">)</span>
<a name="l322"><span class="ln">322  </span></a>    <span class="s1">inv_covXneg </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">inv</span><span class="s3">(</span><span class="s1">covXneg</span><span class="s3">)</span>
<a name="l323"><span class="ln">323  </span></a>    
<a name="l324"><span class="ln">324  </span></a>    <span class="s1">term1 </span><span class="s3">= -</span><span class="s5">0.5 </span><span class="s3">* </span><span class="s1">meanXpos</span><span class="s3">.</span><span class="s1">T </span><span class="s3">@ </span><span class="s1">inv_covXpos </span><span class="s3">@ </span><span class="s1">meanXpos</span>
<a name="l325"><span class="ln">325  </span></a>    <span class="s1">term2 </span><span class="s3">= </span><span class="s5">0.5 </span><span class="s3">* </span><span class="s1">meanXneg</span><span class="s3">.</span><span class="s1">T </span><span class="s3">@ </span><span class="s1">inv_covXneg </span><span class="s3">@ </span><span class="s1">meanXneg</span>
<a name="l326"><span class="ln">326  </span></a>    <span class="s1">term3 </span><span class="s3">= -</span><span class="s5">0.5 </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">log</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">det</span><span class="s3">(</span><span class="s1">covXpos</span><span class="s3">))</span>
<a name="l327"><span class="ln">327  </span></a>    <span class="s1">term4 </span><span class="s3">= </span><span class="s5">0.5 </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">log</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">det</span><span class="s3">(</span><span class="s1">covXneg</span><span class="s3">))</span>
<a name="l328"><span class="ln">328  </span></a>    <span class="s1">term5 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">log</span><span class="s3">(</span><span class="s1">p_ypos </span><span class="s3">/ </span><span class="s1">p_yneg</span><span class="s3">)</span>
<a name="l329"><span class="ln">329  </span></a>    
<a name="l330"><span class="ln">330  </span></a>    <span class="s1">c </span><span class="s3">= </span><span class="s1">term1 </span><span class="s3">+ </span><span class="s1">term2 </span><span class="s3">+ </span><span class="s1">term3 </span><span class="s3">+ </span><span class="s1">term4 </span><span class="s3">+ </span><span class="s1">term5</span>
<a name="l331"><span class="ln">331  </span></a>    
<a name="l332"><span class="ln">332  </span></a>    <span class="s2">return </span><span class="s1">c</span>
<a name="l333"><span class="ln">333  </span></a><span class="s0">#%% 
<a name="l334"><span class="ln">334  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l335"><span class="ln">335  </span></a><span class="s1">c </span><span class="s3">= </span><span class="s1">calc_c</span><span class="s3">(</span>
<a name="l336"><span class="ln">336  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s5">0.14820707</span><span class="s3">, -</span><span class="s5">0.037901126</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l337"><span class="ln">337  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s5">8.44226725</span><span class="s3">, </span><span class="s5">2.01781502</span><span class="s3">], [</span><span class="s5">2.01781502</span><span class="s3">, </span><span class="s5">0.95332618</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l338"><span class="ln">338  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">0.03403238</span><span class="s3">, </span><span class="s5">0.16727877</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l339"><span class="ln">339  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[ </span><span class="s5">0.19860714</span><span class="s3">, -</span><span class="s5">0.16106351</span><span class="s3">], [-</span><span class="s5">0.16106351</span><span class="s3">, </span><span class="s5">12.55336585</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">),</span>
<a name="l340"><span class="ln">340  </span></a>    <span class="s5">0.5</span><span class="s3">,</span>
<a name="l341"><span class="ln">341  </span></a>    <span class="s5">0.5</span>
<a name="l342"><span class="ln">342  </span></a><span class="s3">)</span>
<a name="l343"><span class="ln">343  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">c</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;Parameter c is not a float!&quot;</span>
<a name="l344"><span class="ln">344  </span></a><span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">isclose</span><span class="s3">(</span><span class="s1">c</span><span class="s3">, -</span><span class="s5">0.2355323516530916</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s5">1e-4</span><span class="s3">), </span><span class="s4">&quot;Parameter c is not correct!&quot;</span>
<a name="l345"><span class="ln">345  </span></a><span class="s0">#%% 
<a name="l346"><span class="ln">346  </span></a></span><span class="s2">def </span><span class="s1">calc_g_opt</span><span class="s3">(</span><span class="s1">A</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">b</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">c</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">gridpoints</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">) </span><span class="s1">-&gt; np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">:</span>
<a name="l347"><span class="ln">347  </span></a>    <span class="s6">&quot;&quot;&quot;Compute the optimal classification function `g_opt` using the parameters A, b, and c. 
<a name="l348"><span class="ln">348  </span></a> 
<a name="l349"><span class="ln">349  </span></a>    This function applies the classification function `g_hat` to each point in `gridpoints`, using the provided parameters. 
<a name="l350"><span class="ln">350  </span></a>    Afterwards the sign function is applied using `np.sign` resulting in `g_opt`. 
<a name="l351"><span class="ln">351  </span></a>     
<a name="l352"><span class="ln">352  </span></a>    Parameters 
<a name="l353"><span class="ln">353  </span></a>    ---------- 
<a name="l354"><span class="ln">354  </span></a>    A : (K, K) np.ndarray 
<a name="l355"><span class="ln">355  </span></a>        A matrix representing quadratic terms in the classification function `g_hat`. 
<a name="l356"><span class="ln">356  </span></a>    b : (K,) np.ndarray 
<a name="l357"><span class="ln">357  </span></a>        A vector representing linear terms in the classification function `g_hat`. 
<a name="l358"><span class="ln">358  </span></a>    c : float 
<a name="l359"><span class="ln">359  </span></a>        A scalar bias term in the classification function `g_hat`. 
<a name="l360"><span class="ln">360  </span></a>    gridpoints : (N, K) np.ndarray 
<a name="l361"><span class="ln">361  </span></a>        Array containing the points to which `g_hat` should be applied. 
<a name="l362"><span class="ln">362  </span></a> 
<a name="l363"><span class="ln">363  </span></a>    Returns 
<a name="l364"><span class="ln">364  </span></a>    ------- 
<a name="l365"><span class="ln">365  </span></a>    classification : (N,) np.ndarray 
<a name="l366"><span class="ln">366  </span></a>        A 1D array containing the +1 and -1 values of the classification function `g_opt` applied to each sample in `gridpoints`. 
<a name="l367"><span class="ln">367  </span></a>    &quot;&quot;&quot;</span>
<a name="l368"><span class="ln">368  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l369"><span class="ln">369  </span></a>    <span class="s0"># g_hat = x.T A x + b.T x + c</span>
<a name="l370"><span class="ln">370  </span></a>    <span class="s1">g_hat </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">einsum</span><span class="s3">(</span><span class="s4">'ij,ij-&gt;i'</span><span class="s3">, </span><span class="s1">gridpoints </span><span class="s3">@ </span><span class="s1">A</span><span class="s3">, </span><span class="s1">gridpoints</span><span class="s3">) + </span><span class="s1">gridpoints </span><span class="s3">@ </span><span class="s1">b </span><span class="s3">+ </span><span class="s1">c</span>
<a name="l371"><span class="ln">371  </span></a>    
<a name="l372"><span class="ln">372  </span></a>    <span class="s1">classification </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sign</span><span class="s3">(</span><span class="s1">g_hat</span><span class="s3">)</span>
<a name="l373"><span class="ln">373  </span></a>    
<a name="l374"><span class="ln">374  </span></a>    <span class="s1">classification</span><span class="s3">[</span><span class="s1">classification </span><span class="s3">== </span><span class="s5">0</span><span class="s3">] = -</span><span class="s5">1</span>
<a name="l375"><span class="ln">375  </span></a>    
<a name="l376"><span class="ln">376  </span></a>    <span class="s2">return </span><span class="s1">classification</span>
<a name="l377"><span class="ln">377  </span></a><span class="s0">#%% 
<a name="l378"><span class="ln">378  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l379"><span class="ln">379  </span></a><span class="s1">X1</span><span class="s3">, </span><span class="s1">X2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mgrid</span><span class="s3">[-</span><span class="s5">11</span><span class="s3">:</span><span class="s5">11</span><span class="s3">:</span><span class="s5">500j</span><span class="s3">, -</span><span class="s5">11</span><span class="s3">:</span><span class="s5">11</span><span class="s3">:</span><span class="s5">500j</span><span class="s3">]</span>
<a name="l380"><span class="ln">380  </span></a><span class="s1">X1</span><span class="s3">, </span><span class="s1">X2 </span><span class="s3">= </span><span class="s1">X1</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">X2</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">()</span>
<a name="l381"><span class="ln">381  </span></a><span class="s1">gridpoints </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">c_</span><span class="s3">[</span><span class="s1">X1</span><span class="s3">, </span><span class="s1">X2</span><span class="s3">]</span>
<a name="l382"><span class="ln">382  </span></a><span class="s1">A </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[-</span><span class="s5">4.8482757</span><span class="s3">, -</span><span class="s5">0.5726957</span><span class="s3">], [-</span><span class="s5">0.5726957</span><span class="s3">,  </span><span class="s5">2.0424585</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">)</span>
<a name="l383"><span class="ln">383  </span></a><span class="s1">b </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s5">0.2003752 </span><span class="s3">, -</span><span class="s5">0.02094711</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">)</span>
<a name="l384"><span class="ln">384  </span></a><span class="s1">c </span><span class="s3">= -</span><span class="s5">0.2355323516530916</span>
<a name="l385"><span class="ln">385  </span></a>
<a name="l386"><span class="ln">386  </span></a><span class="s1">g_opt </span><span class="s3">= </span><span class="s1">calc_g_opt</span><span class="s3">(</span><span class="s1">A</span><span class="s3">, </span><span class="s1">b</span><span class="s3">, </span><span class="s1">c</span><span class="s3">, </span><span class="s1">gridpoints</span><span class="s3">)</span>
<a name="l387"><span class="ln">387  </span></a><span class="s2">assert </span><span class="s1">g_opt</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">X1</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s4">&quot;The output has a wrong shape!&quot;</span>
<a name="l388"><span class="ln">388  </span></a><span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">isin</span><span class="s3">(</span><span class="s1">g_opt</span><span class="s3">, [</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">]).</span><span class="s1">all</span><span class="s3">(), </span><span class="s4">&quot;Some values in g_opt are unequal to 1 or -1!&quot;</span>
<a name="l389"><span class="ln">389  </span></a><span class="s0">#%% 
<a name="l390"><span class="ln">390  </span></a># Nothing to do here, just run the cell.</span>
<a name="l391"><span class="ln">391  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;gridponts.shape =&quot;</span><span class="s3">, </span><span class="s1">gridpoints</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l392"><span class="ln">392  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s5">30</span><span class="s3">*</span><span class="s4">&quot;=&quot;</span><span class="s3">)</span>
<a name="l393"><span class="ln">393  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;g_opt.shape =&quot;</span><span class="s3">, </span><span class="s1">g_opt</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l394"><span class="ln">394  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s5">30</span><span class="s3">*</span><span class="s4">&quot;=&quot;</span><span class="s3">)</span>
<a name="l395"><span class="ln">395  </span></a><span class="s0"># Print the values of A, b and c that you have calculated with their respective shapes.</span>
<a name="l396"><span class="ln">396  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;A = &quot;</span><span class="s3">, </span><span class="s1">A</span><span class="s3">)</span>
<a name="l397"><span class="ln">397  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;A.shape = &quot;</span><span class="s3">, </span><span class="s1">A</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l398"><span class="ln">398  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s5">30</span><span class="s3">*</span><span class="s4">&quot;=&quot;</span><span class="s3">)</span>
<a name="l399"><span class="ln">399  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;b = &quot;</span><span class="s3">, </span><span class="s1">b</span><span class="s3">)</span>
<a name="l400"><span class="ln">400  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;b.shape = &quot;</span><span class="s3">, </span><span class="s1">b</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l401"><span class="ln">401  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s5">30</span><span class="s3">*</span><span class="s4">&quot;=&quot;</span><span class="s3">)</span>
<a name="l402"><span class="ln">402  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;c = &quot;</span><span class="s3">, </span><span class="s1">c</span><span class="s3">)</span>
<a name="l403"><span class="ln">403  </span></a><span class="s0">#%% md 
<a name="l404"><span class="ln">404  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Plot 2.2 (8 Points):&lt;/h3&gt; 
<a name="l405"><span class="ln">405  </span></a></span><span class="s0">#%% 
<a name="l406"><span class="ln">406  </span></a></span><span class="s2">def </span><span class="s1">scatter_plot_g_opt</span><span class="s3">(</span><span class="s1">X</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">y</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">X1</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">X2</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">g_opt</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">):</span>
<a name="l407"><span class="ln">407  </span></a>    <span class="s6">&quot;&quot;&quot;Creates a scatter-plot for the dataset X with labels y and the classification function g_opt applied to X1 and X2. 
<a name="l408"><span class="ln">408  </span></a>     
<a name="l409"><span class="ln">409  </span></a>    Parameters 
<a name="l410"><span class="ln">410  </span></a>    ---------- 
<a name="l411"><span class="ln">411  </span></a>    X : (N_data, K) np.ndarray 
<a name="l412"><span class="ln">412  </span></a>        The original data. 
<a name="l413"><span class="ln">413  </span></a>    y : (N_data,) np.ndarray 
<a name="l414"><span class="ln">414  </span></a>        The labels of the data. 
<a name="l415"><span class="ln">415  </span></a>    X1: (N_grid,) np.ndarray 
<a name="l416"><span class="ln">416  </span></a>        The grid values for the x-axis. 
<a name="l417"><span class="ln">417  </span></a>    X2: (N_grid,) np.ndarray 
<a name="l418"><span class="ln">418  </span></a>        The grid values for the y-axis. 
<a name="l419"><span class="ln">419  </span></a>    g_opt : (N_grid,) np.ndarray 
<a name="l420"><span class="ln">420  </span></a>        The result of applying the optimal classifier on the grid features X1 and X2. 
<a name="l421"><span class="ln">421  </span></a>    &quot;&quot;&quot;</span>
<a name="l422"><span class="ln">422  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l423"><span class="ln">423  </span></a>    
<a name="l424"><span class="ln">424  </span></a>    <span class="s1">g_opt_reshaped </span><span class="s3">= </span><span class="s1">g_opt</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">500</span><span class="s3">, </span><span class="s5">500</span><span class="s3">)</span>
<a name="l425"><span class="ln">425  </span></a>    
<a name="l426"><span class="ln">426  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">figure</span><span class="s3">(</span><span class="s1">figsize</span><span class="s3">=(</span><span class="s5">8</span><span class="s3">,</span><span class="s5">6</span><span class="s3">))</span>
<a name="l427"><span class="ln">427  </span></a>    
<a name="l428"><span class="ln">428  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">contourf</span><span class="s3">(</span><span class="s1">X1</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">500</span><span class="s3">,</span><span class="s5">500</span><span class="s3">), </span><span class="s1">X2</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">500</span><span class="s3">,</span><span class="s5">500</span><span class="s3">), </span><span class="s1">g_opt_reshaped</span><span class="s3">, </span><span class="s1">levels</span><span class="s3">=[-</span><span class="s1">np</span><span class="s3">.</span><span class="s1">inf</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">inf</span><span class="s3">], </span><span class="s1">colors</span><span class="s3">=[</span><span class="s4">'orange'</span><span class="s3">, </span><span class="s4">'blue'</span><span class="s3">], </span><span class="s1">alpha</span><span class="s3">=</span><span class="s5">0.2</span><span class="s3">)</span>
<a name="l429"><span class="ln">429  </span></a>    
<a name="l430"><span class="ln">430  </span></a>    <span class="s1">pos </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">y </span><span class="s3">== </span><span class="s5">1</span><span class="s3">]</span>
<a name="l431"><span class="ln">431  </span></a>    <span class="s1">neg </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">y </span><span class="s3">== -</span><span class="s5">1</span><span class="s3">]</span>
<a name="l432"><span class="ln">432  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">scatter</span><span class="s3">(</span><span class="s1">pos</span><span class="s3">[:,</span><span class="s5">0</span><span class="s3">], </span><span class="s1">pos</span><span class="s3">[:,</span><span class="s5">1</span><span class="s3">], </span><span class="s1">c</span><span class="s3">=</span><span class="s4">'blue'</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Positive (+1)'</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s5">0.6</span><span class="s3">)</span>
<a name="l433"><span class="ln">433  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">scatter</span><span class="s3">(</span><span class="s1">neg</span><span class="s3">[:,</span><span class="s5">0</span><span class="s3">], </span><span class="s1">neg</span><span class="s3">[:,</span><span class="s5">1</span><span class="s3">], </span><span class="s1">c</span><span class="s3">=</span><span class="s4">'orange'</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Negative (-1)'</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s5">0.6</span><span class="s3">)</span>
<a name="l434"><span class="ln">434  </span></a>    
<a name="l435"><span class="ln">435  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">contour</span><span class="s3">(</span><span class="s1">X1</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">500</span><span class="s3">,</span><span class="s5">500</span><span class="s3">), </span><span class="s1">X2</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">500</span><span class="s3">,</span><span class="s5">500</span><span class="s3">), </span><span class="s1">g_opt_reshaped</span><span class="s3">, </span><span class="s1">levels</span><span class="s3">=[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">colors</span><span class="s3">=</span><span class="s4">'k'</span><span class="s3">, </span><span class="s1">linewidths</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
<a name="l436"><span class="ln">436  </span></a>    
<a name="l437"><span class="ln">437  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">xlabel</span><span class="s3">(</span><span class="s4">'x1'</span><span class="s3">)</span>
<a name="l438"><span class="ln">438  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">ylabel</span><span class="s3">(</span><span class="s4">'x2'</span><span class="s3">)</span>
<a name="l439"><span class="ln">439  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">legend</span><span class="s3">()</span>
<a name="l440"><span class="ln">440  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">title</span><span class="s3">(</span><span class="s4">'Gaussian Classifier Decision Boundary'</span><span class="s3">)</span>
<a name="l441"><span class="ln">441  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">grid</span><span class="s3">(</span><span class="s2">True</span><span class="s3">)</span>
<a name="l442"><span class="ln">442  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">show</span><span class="s3">()</span>
<a name="l443"><span class="ln">443  </span></a><span class="s0">#%% 
<a name="l444"><span class="ln">444  </span></a># Nothing to do here, just run the cell.</span>
<a name="l445"><span class="ln">445  </span></a><span class="s1">scatter_plot_g_opt</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">X1</span><span class="s3">, </span><span class="s1">X2</span><span class="s3">, </span><span class="s1">g_opt</span><span class="s3">)</span>
<a name="l446"><span class="ln">446  </span></a><span class="s0">#%% md 
<a name="l447"><span class="ln">447  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Question 2.2 (2 Points):&lt;/h3&gt; 
<a name="l448"><span class="ln">448  </span></a></span><span class="s0">#%% md 
<a name="l449"><span class="ln">449  </span></a></span><span class="s1">***Answer the following questions about the plot you just created:*** 
<a name="l450"><span class="ln">450  </span></a> 
<a name="l451"><span class="ln">451  </span></a>a2_) Did the classifier perform well on the task i.e. do the decision boundaries seem to match the classes as plotted in Task 1.1?&lt;br&gt; 
<a name="l452"><span class="ln">452  </span></a>b2_) Are datapoints that lie in the middle (i.e. overlapping) region of the two classes less prone to being misclassified compared to data far away from the center?&lt;br&gt; 
<a name="l453"><span class="ln">453  </span></a> 
<a name="l454"><span class="ln">454  </span></a>To answer the question, assign &quot;True&quot; or &quot;False&quot; boolean values to variables in the next cell. For example, if you think that **a2_)** is correct, define a variable `a2_` and set it to `True`, the same applies to **b2_)**. A non-correctly answered question as well as no answer (i.e. answer “None”) yields 0 points for a specific question.&lt;br&gt; 
<a name="l455"><span class="ln">455  </span></a>&lt;b&gt;Note:&lt;/b&gt; Do not reuse these variable names. They are used for testing. 
<a name="l456"><span class="ln">456  </span></a></span><span class="s0">#%% 
<a name="l457"><span class="ln">457  </span></a># YOUR CODE HERE</span>
<a name="l458"><span class="ln">458  </span></a><span class="s1">a2_ </span><span class="s3">= </span><span class="s2">True</span>
<a name="l459"><span class="ln">459  </span></a><span class="s1">b2_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l460"><span class="ln">460  </span></a><span class="s0">#%% 
<a name="l461"><span class="ln">461  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l462"><span class="ln">462  </span></a><span class="s2">assert </span><span class="s1">a2_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l463"><span class="ln">463  </span></a><span class="s2">assert </span><span class="s1">a2_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l464"><span class="ln">464  </span></a><span class="s0">#%% 
<a name="l465"><span class="ln">465  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l466"><span class="ln">466  </span></a><span class="s2">assert </span><span class="s1">b2_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l467"><span class="ln">467  </span></a><span class="s2">assert </span><span class="s1">b2_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l468"><span class="ln">468  </span></a><span class="s0">#%% md 
<a name="l469"><span class="ln">469  </span></a></span><span class="s1">&lt;h2 style=&quot;color:rgb(0,120,170)&quot;&gt;Task 3: Details for bias-variance decomposition for quadratic loss&lt;/h2&gt; 
<a name="l470"><span class="ln">470  </span></a> 
<a name="l471"><span class="ln">471  </span></a>An explicit formula of the bias variance decomposition for the quadratic loss was mentioned in the lecture. In this task, you will prove this decomposition yourselves. To this end, let us introduce some notation: 
<a name="l472"><span class="ln">472  </span></a> 
<a name="l473"><span class="ln">473  </span></a>$Z_l = (X,\mathbf{y})$ denotes a data matrix of $l$ elements, with $X$ the ($d\times l$)-dimensional feature matrix and $\mathbf{y}$ the $l$-dimensional (column) label vector. $g(\mathbf{x}_0;\mathbf{w}(Z_l)))$ denotes the model, parametrized by the vector $\mathbf{w}(Z_l)$ trained on $Z_l$, and the variable $y$ is the label corresponding to a (new) feature vector $\mathbf{x}_0$.  
<a name="l474"><span class="ln">474  </span></a> 
<a name="l475"><span class="ln">475  </span></a>Our object of interest is the expected prediction error (EPE) for 
<a name="l476"><span class="ln">476  </span></a>$\mathbf{x}_0$ in case of the quadratic loss, i.e.: 
<a name="l477"><span class="ln">477  </span></a> 
<a name="l478"><span class="ln">478  </span></a>$$\mathrm{EPE}(\mathbf{x}_0) = \mathrm{E}_{y\mid 
<a name="l479"><span class="ln">479  </span></a>\mathbf{x}_0,Z_l}\big(L_{\mathbf{q}}(y,g(\mathbf{x}_0;\mathbf{w}(Z_l)))\big) 
<a name="l480"><span class="ln">480  </span></a>= \mathrm{E}_{y\mid 
<a name="l481"><span class="ln">481  </span></a>\mathbf{x}_0,Z_l}\big((y-g(\mathbf{x}_0;\mathbf{w}(Z_l)))^2\big)$$ 
<a name="l482"><span class="ln">482  </span></a> 
<a name="l483"><span class="ln">483  </span></a>We assume that $y\!\mid\!\mathbf{x}_0$ and the selection of training samples $Z_l$ are 
<a name="l484"><span class="ln">484  </span></a>independent which results in the following reformulation of the total expected prediction error: 
<a name="l485"><span class="ln">485  </span></a> 
<a name="l486"><span class="ln">486  </span></a>$$\mathrm{EPE}(\mathbf{x}_0) = \mathrm{E}_{y\mid 
<a name="l487"><span class="ln">487  </span></a>\mathbf{x}_0}\Big(\mathrm{E}_{Z_l}\big((y-g(\mathbf{x}_0;\mathbf{w}(Z_l)))^2\big)\Big) \qquad \text{(1)}$$ 
<a name="l488"><span class="ln">488  </span></a> 
<a name="l489"><span class="ln">489  </span></a>Show that we can obtain the following bias-variance decomposition: 
<a name="l490"><span class="ln">490  </span></a> 
<a name="l491"><span class="ln">491  </span></a>\begin{align} 
<a name="l492"><span class="ln">492  </span></a>\mathrm{EPE}(\mathbf{x}_0)=&amp;\,\operatorname{Var}(y\!\mid\!\mathbf{x}_0) \\ 
<a name="l493"><span class="ln">493  </span></a>&amp;+\Big(\mathrm{E}_{y\mid\mathbf{x}_0}(y)-E_{Z_l}\big(g(\mathbf{x}_0;\mathbf{w}(Z_l))\big)\Big)^2 &amp; \text{(2)}\\ 
<a name="l494"><span class="ln">494  </span></a>&amp;+\mathrm{E}_{Z_l}\Big(\big(g(\mathbf{x}_0;\mathbf{w}(Z_l))-E_{Z_l}(g(\mathbf{x}_0;\mathbf{w}(Z_l)))\big)^2\Big)  
<a name="l495"><span class="ln">495  </span></a>\end{align} 
<a name="l496"><span class="ln">496  </span></a> 
<a name="l497"><span class="ln">497  </span></a>For your calculation please use the given notation. Follow the steps indicated below. 
<a name="l498"><span class="ln">498  </span></a></span><span class="s0">#%% md 
<a name="l499"><span class="ln">499  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Calculation 3.1 (5 Points): Expand the Expected Prediction Error.&lt;/h3&gt; 
<a name="l500"><span class="ln">500  </span></a> 
<a name="l501"><span class="ln">501  </span></a>Expand $\mathrm{EPE}(\mathbf{x}_0)$, i.e. eq. (1) above, and write it as three separate terms. 
<a name="l502"><span class="ln">502  </span></a></span><span class="s0">#%% md 
<a name="l503"><span class="ln">503  </span></a></span><span class="s1">YOUR ANSWER HERE 
<a name="l504"><span class="ln">504  </span></a> 
<a name="l505"><span class="ln">505  </span></a>We start with the definition of the Expected Prediction Error (EPE): 
<a name="l506"><span class="ln">506  </span></a> 
<a name="l507"><span class="ln">507  </span></a>$\mathrm{EPE}(\mathbf{x}0) = \mathrm{E}{y\mid \mathbf{x}0} \left( \mathrm{E}{Z_l} \left( (y - g(\mathbf{x}_0; \mathbf{w}(Z_l)))^2 \right) \right)$ 
<a name="l508"><span class="ln">508  </span></a> 
<a name="l509"><span class="ln">509  </span></a>Expanding the square inside the expectation: 
<a name="l510"><span class="ln">510  </span></a> 
<a name="l511"><span class="ln">511  </span></a>$(y - g)^2 = y^2 - 2 y g + g^2$ 
<a name="l512"><span class="ln">512  </span></a> 
<a name="l513"><span class="ln">513  </span></a>Thus, the EPE becomes: 
<a name="l514"><span class="ln">514  </span></a> 
<a name="l515"><span class="ln">515  </span></a>$\mathrm{EPE}(\mathbf{x}0) = \mathrm{E}{y\mid \mathbf{x}0} \left( \mathrm{E}{Z_l} \left( y^2 - 2 y g + g^2 \right) \right)$\ 
<a name="l516"><span class="ln">516  </span></a>$\mathrm{EPE}(\mathbf{x}0) = \mathrm{E}{y\mid \mathbf{x}0} \left( y^2 \right) - 2 \mathrm{E}{y\mid \mathbf{x}0} \left( y \right) \mathrm{E}{Z_l} \left( g \right) + \mathrm{E}{Z_l} \left( g^2 \right)$ 
<a name="l517"><span class="ln">517  </span></a> 
<a name="l518"><span class="ln">518  </span></a>So, we have: 
<a name="l519"><span class="ln">519  </span></a> 
<a name="l520"><span class="ln">520  </span></a>$\mathrm{EPE}(\mathbf{x}0) = \underbrace{\mathrm{E}{y\mid \mathbf{x}0} \left( y^2 \right)}{\text{Term A}} - 2 \underbrace{\mathrm{E}{y\mid \mathbf{x}0} \left( y \right) \mathrm{E}{Z_l} \left( g \right)}{\text{Term B}} + \underbrace{\mathrm{E}{Z_l} \left( g^2 \right)}{\text{Term C}}$ 
<a name="l521"><span class="ln">521  </span></a> 
<a name="l522"><span class="ln">522  </span></a></span><span class="s0">#%% md 
<a name="l523"><span class="ln">523  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Calculation 3.2 (5 Points): Rewrite $\operatorname{Var}(y\!\mid\!\mathbf{x}_0)$ using expected values. &lt;/h3&gt; 
<a name="l524"><span class="ln">524  </span></a> 
<a name="l525"><span class="ln">525  </span></a>Write the label variance (unavoidable error), i.e. term 1 in (2), in terms of expectation values. 
<a name="l526"><span class="ln">526  </span></a></span><span class="s0">#%% md 
<a name="l527"><span class="ln">527  </span></a></span><span class="s1">YOUR ANSWER HERE 
<a name="l528"><span class="ln">528  </span></a> 
<a name="l529"><span class="ln">529  </span></a>The variance of $y$ given $\mathbf{x}_0$ is: 
<a name="l530"><span class="ln">530  </span></a> 
<a name="l531"><span class="ln">531  </span></a>$\operatorname{Var}(y\mid \mathbf{x}0) = \mathrm{E}{y\mid \mathbf{x}0}\left[ \left( y - \mathrm{E}{y\mid \mathbf{x}0}(y) \right)^2 \right] $\ 
<a name="l532"><span class="ln">532  </span></a>$= \mathrm{E}{y\mid \mathbf{x}0}(y^2) - \left( \mathrm{E}{y\mid \mathbf{x}0}(y) \right)^2 $\ 
<a name="l533"><span class="ln">533  </span></a>$= \mathrm{E}{y\mid \mathbf{x}_0}(y^2) - \mu^2$ 
<a name="l534"><span class="ln">534  </span></a> 
<a name="l535"><span class="ln">535  </span></a> 
<a name="l536"><span class="ln">536  </span></a>Thus, $\operatorname{Var}(y\mid \mathbf{x}_0)$ is expressed in terms of expected values. 
<a name="l537"><span class="ln">537  </span></a></span><span class="s0">#%% md 
<a name="l538"><span class="ln">538  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Calculation 3.3 (4 Points): Expand the squared bias.&lt;/h3&gt; 
<a name="l539"><span class="ln">539  </span></a> 
<a name="l540"><span class="ln">540  </span></a>Expand the squared bias, i.e. term 2 in (2), and write it in three separate terms. 
<a name="l541"><span class="ln">541  </span></a></span><span class="s0">#%% md 
<a name="l542"><span class="ln">542  </span></a></span><span class="s1">YOUR ANSWER HERE 
<a name="l543"><span class="ln">543  </span></a> 
<a name="l544"><span class="ln">544  </span></a>The squared bias term is: 
<a name="l545"><span class="ln">545  </span></a> 
<a name="l546"><span class="ln">546  </span></a>$\left( \mathrm{E}_{y\mid \mathbf{x}0}(y) - \mathrm{E}{Z_l}\big( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \big) \right)^2 = \left( \mu - \bar{g} \right)^2 $\ 
<a name="l547"><span class="ln">547  </span></a>$= \mu^2 - 2\, \mu\, \bar{g} + \bar{g}^2$ 
<a name="l548"><span class="ln">548  </span></a> 
<a name="l549"><span class="ln">549  </span></a> 
<a name="l550"><span class="ln">550  </span></a> 
<a name="l551"><span class="ln">551  </span></a>We have expanded the squared bias into three separate terms: 
<a name="l552"><span class="ln">552  </span></a>    1.  $\mu^2$ 
<a name="l553"><span class="ln">553  </span></a>    2.  $-2, \mu, \bar{g}$ 
<a name="l554"><span class="ln">554  </span></a>    3.  $\bar{g}^2$ 
<a name="l555"><span class="ln">555  </span></a> 
<a name="l556"><span class="ln">556  </span></a></span><span class="s0">#%% md 
<a name="l557"><span class="ln">557  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Calculation 3.4 (5 Points): Expand the variance of the model.&lt;/h3&gt; 
<a name="l558"><span class="ln">558  </span></a> 
<a name="l559"><span class="ln">559  </span></a>Expand model variance, i.e. term 3 in (2), into three terms, and then simplify it to only two terms. 
<a name="l560"><span class="ln">560  </span></a> 
<a name="l561"><span class="ln">561  </span></a>Eventually, show that adding up your results from 3.2., 3.3., and 3.4. leads to your results from 3.1. That concludes the proof. 
<a name="l562"><span class="ln">562  </span></a></span><span class="s0">#%% md 
<a name="l563"><span class="ln">563  </span></a></span><span class="s1">YOUR ANSWER HERE 
<a name="l564"><span class="ln">564  </span></a> 
<a name="l565"><span class="ln">565  </span></a>The model variance is: 
<a name="l566"><span class="ln">566  </span></a> 
<a name="l567"><span class="ln">567  </span></a>$\operatorname{Var}_{Z_l}\big( g(\mathbf{x}0;\mathbf{w}(Z_l)) \big) = \mathrm{E}{Z_l}\left[ \left( g(\mathbf{x}0;\mathbf{w}(Z_l)) - \bar{g} \right)^2 \right] $\ 
<a name="l568"><span class="ln">568  </span></a>$= \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \right)^2 - 2\, g(\mathbf{x}0;\mathbf{w}(Z_l))\, \bar{g} + \bar{g}^2 \right) $\ 
<a name="l569"><span class="ln">569  </span></a>$= \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}0;\mathbf{w}(Z_l)) \right)^2 \right) - 2\, \bar{g}^2 + \bar{g}^2 $\ 
<a name="l570"><span class="ln">570  </span></a>$= \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \right)^2 \right) - \bar{g}^2$ 
<a name="l571"><span class="ln">571  </span></a> 
<a name="l572"><span class="ln">572  </span></a> 
<a name="l573"><span class="ln">573  </span></a>We have expanded the variance into three terms: 
<a name="l574"><span class="ln">574  </span></a>    1.  $\mathrm{E}_{Z_l}\left( \left( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \right)^2 \right)$ 
<a name="l575"><span class="ln">575  </span></a>    2.  $-2, \bar{g}^2$ 
<a name="l576"><span class="ln">576  </span></a>    3.  $\bar{g}^2$ 
<a name="l577"><span class="ln">577  </span></a> 
<a name="l578"><span class="ln">578  </span></a>Simplifying, we get: 
<a name="l579"><span class="ln">579  </span></a> 
<a name="l580"><span class="ln">580  </span></a>$\operatorname{Var}_{Z_l}\big( g(\mathbf{x}0;\mathbf{w}(Z_l)) \big) = \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \right)^2 \right) - \bar{g}^2$ 
<a name="l581"><span class="ln">581  </span></a> 
<a name="l582"><span class="ln">582  </span></a> 
<a name="l583"><span class="ln">583  </span></a>Adding the results from Calculations 3.2, 3.3, and 3.4:\\ 
<a name="l584"><span class="ln">584  </span></a>    1.From Calculation $3.2:$\ 
<a name="l585"><span class="ln">585  </span></a>$\operatorname{Var}(y\mid \mathbf{x}0) = \mathrm{E}{y\mid \mathbf{x}_0}(y^2) - \mu^2$ 
<a name="l586"><span class="ln">586  </span></a>    2.From Calculation $3.3:$\ 
<a name="l587"><span class="ln">587  </span></a>$(\mu - \bar{g})^2 = \mu^2 - 2\, \mu\, \bar{g} + \bar{g}^2$ 
<a name="l588"><span class="ln">588  </span></a>    3.From Calculation $3.4:$\ 
<a name="l589"><span class="ln">589  </span></a>$\operatorname{Var}_{Z_l}\big( g(\mathbf{x}0;\mathbf{w}(Z_l)) \big) = \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \right)^2 \right) - \bar{g}^2$ 
<a name="l590"><span class="ln">590  </span></a> 
<a name="l591"><span class="ln">591  </span></a>Summing these up: 
<a name="l592"><span class="ln">592  </span></a> 
<a name="l593"><span class="ln">593  </span></a> 
<a name="l594"><span class="ln">594  </span></a>$\mathrm{EPE}(\mathbf{x}0) = \left( \mathrm{E}{y\mid \mathbf{x}0}(y^2) - \mu^2 \right) + \left( \mu^2 - 2\, \mu\, \bar{g} + \bar{g}^2 \right) + \left( \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}0;\mathbf{w}(Z_l)) \right)^2 \right) - \bar{g}^2 \right) $\ 
<a name="l595"><span class="ln">595  </span></a>$= \mathrm{E}{y\mid \mathbf{x}0}(y^2) - 2\, \mu\, \bar{g} + \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \right)^2 \right)$ 
<a name="l596"><span class="ln">596  </span></a> 
<a name="l597"><span class="ln">597  </span></a> 
<a name="l598"><span class="ln">598  </span></a>Notice that $\mu^2$ and $-\bar{g}^2$ cancel out. 
<a name="l599"><span class="ln">599  </span></a> 
<a name="l600"><span class="ln">600  </span></a>From Calculation 3.1, we have: 
<a name="l601"><span class="ln">601  </span></a> 
<a name="l602"><span class="ln">602  </span></a> 
<a name="l603"><span class="ln">603  </span></a>$\mathrm{EPE}(\mathbf{x}0) = \mathrm{E}{y\mid \mathbf{x}0}(y^2) - 2\, \mu\, \bar{g} + \mathrm{E}{Z_l}\left( \left( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \right)^2 \right)$ 
<a name="l604"><span class="ln">604  </span></a> 
<a name="l605"><span class="ln">605  </span></a> 
<a name="l606"><span class="ln">606  </span></a>Thus, summing the results from Calculations 3.2, 3.3, and 3.4 leads back to the expanded form of the EPE from Calculation 3.1, confirming the bias-variance decomposition: 
<a name="l607"><span class="ln">607  </span></a> 
<a name="l608"><span class="ln">608  </span></a>$\mathrm{EPE}(\mathbf{x}_0) = \operatorname{Var}(y\mid \mathbf{x}0) + \left( \mathrm{E}{y\mid \mathbf{x}0}(y) - \mathrm{E}{Z_l}\big( g(\mathbf{x}0;\mathbf{w}(Z_l)) \big) \right)^2 + \operatorname{Var}{Z_l}\big( g(\mathbf{x}_0;\mathbf{w}(Z_l)) \big)$ 
<a name="l609"><span class="ln">609  </span></a> 
<a name="l610"><span class="ln">610  </span></a> 
<a name="l611"><span class="ln">611  </span></a>This concludes the proof of the bias-variance decomposition for the quadratic loss. 
<a name="l612"><span class="ln">612  </span></a> 
<a name="l613"><span class="ln">613  </span></a> 
<a name="l614"><span class="ln">614  </span></a></span><span class="s0">#%% md 
<a name="l615"><span class="ln">615  </span></a></span><span class="s1">&lt;h2 style=&quot;color:rgb(0,120,170)&quot;&gt;Task 4: Bias-variance decomposition for regression&lt;/h2&gt; 
<a name="l616"><span class="ln">616  </span></a></span><span class="s0">#%% md 
<a name="l617"><span class="ln">617  </span></a></span><span class="s1">We intend to perform polynomial regression to illustrate the bias-variance decomposition for the regression task described before. To this end, perform the following steps: 
<a name="l618"><span class="ln">618  </span></a>* **Question 4.1**:&lt;br&gt; 
<a name="l619"><span class="ln">619  </span></a>  Consider the following one-dimensional regression task: inputs $x$ are 
<a name="l620"><span class="ln">620  </span></a>  sampled from the uniform distribution in $[−1, 3] \subset \mathbb{R}$ and targets $y$ are given as 
<a name="l621"><span class="ln">621  </span></a>  \begin{align*} 
<a name="l622"><span class="ln">622  </span></a>  f(x) &amp;= 0.5\,x^4 + 2\,x^3 - 8\,x^2 \\ 
<a name="l623"><span class="ln">623  </span></a>  y &amp;= f(x) + \varepsilon, 
<a name="l624"><span class="ln">624  </span></a>  \end{align*} 
<a name="l625"><span class="ln">625  </span></a>  where $\varepsilon$ is independent normally distributed noise with mean $\mu=0$ and variance $\sigma^2 = 4$. 
<a name="l626"><span class="ln">626  </span></a>   
<a name="l627"><span class="ln">627  </span></a>  Now, answer the given question. 
<a name="l628"><span class="ln">628  </span></a>* **Code 4.2**: 
<a name="l629"><span class="ln">629  </span></a>    * If a seed is given as function parameter, then set the seed using [np.random.seed](https://numpy.org/doc/2.0/reference/random/generated/numpy.random.seed.html). 
<a name="l630"><span class="ln">630  </span></a>    * Define the function `f(x)`, using the definition in **Question 4.1**. 
<a name="l631"><span class="ln">631  </span></a>    * Implement the function `create_X_train` which should return $S$ training sets with $N$ samples in the form of a `np.ndarray`. The x-values are uniformly sampled from `x_min` to `x_max`. Important: Use the function [np.random.uniform](https://numpy.org/doc/2.0/reference/random/generated/numpy.random.uniform.html) to complete this task! 
<a name="l632"><span class="ln">632  </span></a>    * Implement the function `create_y_train` which generates the training y-values according to **Question 4.1**, i.e. with Gaussian noise. Define the function for general mean `mu` and standard deviation `std`. Important: Use the function [np.random.normal](https://numpy.org/doc/2.0/reference/random/generated/numpy.random.normal.html) to complete this task! 
<a name="l633"><span class="ln">633  </span></a>    * Below, we provide the code for a function `pol_reg_pred` that trains a polynomial regression model with degree $m$ on a given training set and returns the prediction for a given test set (uniformly sampled $x$ values without labels). Use this to implement the function `bias_var` that estimates for each degree $m=1, ..., M$ the squared bias and the variance from the predictions for each of the $S$ training sets at $x_{test}$ and returns them in the `np.ndarrays` sqbias and variance. Each of these two arrays should then only contain $M$ elements. 
<a name="l634"><span class="ln">634  </span></a>* **Plot 4.3**:&lt;br&gt;  
<a name="l635"><span class="ln">635  </span></a>  Utilize the function `pol_reg_pred` to produce a &lt;em&gt;single&lt;/em&gt; plot that simultaneously visualizes the training data as dots (plot only the &lt;em&gt;first&lt;/em&gt; instance of the $S$ training sets, i.e. `X_train[0]`) and the corresponding models for $m=1,4,11$. Don't forget to label the axes and give your plot a fitting title. 
<a name="l636"><span class="ln">636  </span></a>* **Plot 4.4**:&lt;br&gt; 
<a name="l637"><span class="ln">637  </span></a>Finally, visualize your results in another &lt;em&gt;single&lt;/em&gt; plot where the dependence of **(i) the unavoidable error**, **(ii) the squared bias**, **(iii) the model variance**, and **(iv) the total EPE** is shown versus $m$. Again, don't forget to label the axes and give your plot a fitting title as well as plot a legend. Feel free to plot lines to guide the eye, although the horizontal axis is discrete. 
<a name="l638"><span class="ln">638  </span></a>* **Question 4.4**:&lt;br&gt; 
<a name="l639"><span class="ln">639  </span></a>Answer some questions about **Plot 4.4**. 
<a name="l640"><span class="ln">640  </span></a></span><span class="s0">#%% md 
<a name="l641"><span class="ln">641  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Question 4.1 (6 Points):&lt;/h3&gt; 
<a name="l642"><span class="ln">642  </span></a> 
<a name="l643"><span class="ln">643  </span></a>***What are $E(y\!\mid\!x_0)$ and the unavoidable error $\operatorname{Var}(y\!\mid\!x_0)$ for a fixed $x_0$ in the setting given above?*** 
<a name="l644"><span class="ln">644  </span></a> 
<a name="l645"><span class="ln">645  </span></a>a3_)   $E(y\!\mid\!x_0) = 0.5\,\sigma^4 + 2\,\sigma^3 - 8\,\sigma^2 \,\text{  and  } \operatorname{Var}(y\!\mid\!x_0) = x_0^2$. &lt;br&gt; 
<a name="l646"><span class="ln">646  </span></a>b3_)   $E(y\!\mid\!x_0) = 0.5\,\sigma^4 + 2\,\sigma^3 - 8\,\sigma^2 \,\text{  and  }  \operatorname{Var}(y\!\mid\!x_0) = \sigma^2$. &lt;br&gt; 
<a name="l647"><span class="ln">647  </span></a>c3_)   $E(y\!\mid\!x_0) = 0.5\,\sigma^4 + 2\,\sigma^3 - 8\,\sigma^2 \,\text{  and  }  \operatorname{Var}(y\!\mid\!x_0) = 2\sigma^2$. &lt;br&gt; 
<a name="l648"><span class="ln">648  </span></a>d3_)   $E(y\!\mid\!x_0) = 0.5\,x_0^4 + 2\,x_0^3 - 8\,x_0^2 \,\text{  and  }\operatorname{Var}(y\!\mid\!x_0) = 2\sigma^2$. &lt;br&gt; 
<a name="l649"><span class="ln">649  </span></a>e3_)   $E(y\!\mid\!x_0) = 0.5\,x_0^4 + 2\,x_0^3 - 8\,x_0^2 \,\text{  and  }\operatorname{Var}(y\!\mid\!x_0) = \sigma^2$. &lt;br&gt; 
<a name="l650"><span class="ln">650  </span></a>f3_)   $E(y\!\mid\!x_0) = 0.5\,x_0^4 + 2\,x_0^3 - 8\,x_0^2 \,\text{  and  } \operatorname{Var}(y\!\mid\!x_0) = 0.5\,x_0^4 + 2\,x_0^3 - 8\,x_0^2+\sigma^2$.&lt;br&gt; 
<a name="l651"><span class="ln">651  </span></a> 
<a name="l652"><span class="ln">652  </span></a>To answer the question, assign &quot;True&quot; or &quot;False&quot; boolean values to variables in the next cell. For example, if you think that **a3_)** is correct, define a variable `a3_` and set it to `True`, the same applies to **b3_)** and the other options. A non-correctly answered question as well as no answer (i.e. answer “None”) yields 0 points for a specific question.&lt;br&gt; 
<a name="l653"><span class="ln">653  </span></a>&lt;b&gt;Note:&lt;/b&gt; Do not reuse these variable names. They are used for testing. 
<a name="l654"><span class="ln">654  </span></a></span><span class="s0">#%% 
<a name="l655"><span class="ln">655  </span></a># YOUR CODE HERE</span>
<a name="l656"><span class="ln">656  </span></a><span class="s1">a3_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l657"><span class="ln">657  </span></a><span class="s1">b3_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l658"><span class="ln">658  </span></a><span class="s1">c3_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l659"><span class="ln">659  </span></a><span class="s1">d3_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l660"><span class="ln">660  </span></a><span class="s1">e3_ </span><span class="s3">= </span><span class="s2">True</span>
<a name="l661"><span class="ln">661  </span></a><span class="s1">f3_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l662"><span class="ln">662  </span></a><span class="s0">#%% 
<a name="l663"><span class="ln">663  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l664"><span class="ln">664  </span></a><span class="s2">assert </span><span class="s1">a3_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l665"><span class="ln">665  </span></a><span class="s2">assert </span><span class="s1">a3_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l666"><span class="ln">666  </span></a><span class="s0">#%% 
<a name="l667"><span class="ln">667  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l668"><span class="ln">668  </span></a><span class="s2">assert </span><span class="s1">b3_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l669"><span class="ln">669  </span></a><span class="s2">assert </span><span class="s1">b3_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l670"><span class="ln">670  </span></a><span class="s0">#%% 
<a name="l671"><span class="ln">671  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l672"><span class="ln">672  </span></a><span class="s2">assert </span><span class="s1">c3_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l673"><span class="ln">673  </span></a><span class="s2">assert </span><span class="s1">c3_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l674"><span class="ln">674  </span></a><span class="s0">#%% 
<a name="l675"><span class="ln">675  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l676"><span class="ln">676  </span></a><span class="s2">assert </span><span class="s1">d3_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l677"><span class="ln">677  </span></a><span class="s2">assert </span><span class="s1">d3_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l678"><span class="ln">678  </span></a><span class="s0">#%% 
<a name="l679"><span class="ln">679  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l680"><span class="ln">680  </span></a><span class="s2">assert </span><span class="s1">e3_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l681"><span class="ln">681  </span></a><span class="s2">assert </span><span class="s1">e3_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l682"><span class="ln">682  </span></a><span class="s0">#%% 
<a name="l683"><span class="ln">683  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l684"><span class="ln">684  </span></a><span class="s2">assert </span><span class="s1">f3_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l685"><span class="ln">685  </span></a><span class="s2">assert </span><span class="s1">f3_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l686"><span class="ln">686  </span></a><span class="s0">#%% md 
<a name="l687"><span class="ln">687  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;4.2 Code (15 points):&lt;/h3&gt; 
<a name="l688"><span class="ln">688  </span></a></span><span class="s0">#%% 
<a name="l689"><span class="ln">689  </span></a># Nothing to do here, just run the cell.</span>
<a name="l690"><span class="ln">690  </span></a><span class="s2">def </span><span class="s1">pol_reg_pred</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">x_test</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">m</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">: </span><span class="s1">int</span><span class="s3">):</span>
<a name="l691"><span class="ln">691  </span></a>    <span class="s6">&quot;&quot;&quot;Train a polynomial regression model of specified degree and return predictions for test data. 
<a name="l692"><span class="ln">692  </span></a> 
<a name="l693"><span class="ln">693  </span></a>    This function fits a polynomial regression model to the provided training data `(X_train, y_train)` 
<a name="l694"><span class="ln">694  </span></a>    with degree `m`, then uses this model to predict outputs for the test samples in `X_test`. 
<a name="l695"><span class="ln">695  </span></a> 
<a name="l696"><span class="ln">696  </span></a>    Parameters 
<a name="l697"><span class="ln">697  </span></a>    ---------- 
<a name="l698"><span class="ln">698  </span></a>    X_train : (N,) np.ndarray 
<a name="l699"><span class="ln">699  </span></a>        Vector of training samples. 
<a name="l700"><span class="ln">700  </span></a>    y_train : (N,) np.ndarray 
<a name="l701"><span class="ln">701  </span></a>        Vector of training labels. 
<a name="l702"><span class="ln">702  </span></a>    x_test : np.ndarray 
<a name="l703"><span class="ln">703  </span></a>        Vector of test samples for which predictions will be made. 
<a name="l704"><span class="ln">704  </span></a>    m : int 
<a name="l705"><span class="ln">705  </span></a>        Degree of the polynomial for regression. 
<a name="l706"><span class="ln">706  </span></a>    seed : int 
<a name="l707"><span class="ln">707  </span></a>        Seed for reproducibility. 
<a name="l708"><span class="ln">708  </span></a> 
<a name="l709"><span class="ln">709  </span></a>    Returns 
<a name="l710"><span class="ln">710  </span></a>    ------- 
<a name="l711"><span class="ln">711  </span></a>    prediction : np.ndarray 
<a name="l712"><span class="ln">712  </span></a>        Predictions for the `x_test` samples. 
<a name="l713"><span class="ln">713  </span></a>    &quot;&quot;&quot;</span>
<a name="l714"><span class="ln">714  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">seed</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">)</span>
<a name="l715"><span class="ln">715  </span></a>    <span class="s1">poly_reg </span><span class="s3">= </span><span class="s1">PolynomialFeatures</span><span class="s3">(</span><span class="s1">m</span><span class="s3">)</span>
<a name="l716"><span class="ln">716  </span></a>    <span class="s1">X_poly_train </span><span class="s3">= </span><span class="s1">poly_reg</span><span class="s3">.</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">))</span>
<a name="l717"><span class="ln">717  </span></a>    <span class="s1">X_poly_test</span><span class="s3">= </span><span class="s1">poly_reg</span><span class="s3">.</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">x_test</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">))</span>
<a name="l718"><span class="ln">718  </span></a>    
<a name="l719"><span class="ln">719  </span></a>    <span class="s1">lin_reg </span><span class="s3">= </span><span class="s1">LinearRegression</span><span class="s3">()</span>
<a name="l720"><span class="ln">720  </span></a>    <span class="s1">lin_reg</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_poly_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
<a name="l721"><span class="ln">721  </span></a>    <span class="s1">y_pred </span><span class="s3">= </span><span class="s1">lin_reg</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_poly_test</span><span class="s3">)</span>
<a name="l722"><span class="ln">722  </span></a>    
<a name="l723"><span class="ln">723  </span></a>    <span class="s2">return </span><span class="s1">y_pred</span>
<a name="l724"><span class="ln">724  </span></a><span class="s0">#%% 
<a name="l725"><span class="ln">725  </span></a></span><span class="s2">def </span><span class="s1">f</span><span class="s3">(</span><span class="s1">x</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">) </span><span class="s1">-&gt; np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">:</span>
<a name="l726"><span class="ln">726  </span></a>    <span class="s6">&quot;&quot;&quot;Implementation of the polynomial from Question 4.1. 
<a name="l727"><span class="ln">727  </span></a>     
<a name="l728"><span class="ln">728  </span></a>    Parameters 
<a name="l729"><span class="ln">729  </span></a>    ---------- 
<a name="l730"><span class="ln">730  </span></a>    x : (N,) np.ndarray 
<a name="l731"><span class="ln">731  </span></a>        The input of the function. 
<a name="l732"><span class="ln">732  </span></a> 
<a name="l733"><span class="ln">733  </span></a>    Returns 
<a name="l734"><span class="ln">734  </span></a>    ------- 
<a name="l735"><span class="ln">735  </span></a>    output : (N,) np.ndarray 
<a name="l736"><span class="ln">736  </span></a>        The output of the function. 
<a name="l737"><span class="ln">737  </span></a>    &quot;&quot;&quot;</span>
<a name="l738"><span class="ln">738  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l739"><span class="ln">739  </span></a>    <span class="s2">return </span><span class="s5">0.5 </span><span class="s3">* </span><span class="s1">x</span><span class="s3">**</span><span class="s5">4 </span><span class="s3">+ </span><span class="s5">2 </span><span class="s3">* </span><span class="s1">x</span><span class="s3">**</span><span class="s5">3 </span><span class="s3">- </span><span class="s5">8 </span><span class="s3">* </span><span class="s1">x</span><span class="s3">**</span><span class="s5">2</span>
<a name="l740"><span class="ln">740  </span></a><span class="s0">#%% 
<a name="l741"><span class="ln">741  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l742"><span class="ln">742  </span></a><span class="s1">x </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">0.5</span><span class="s3">, </span><span class="s5">2</span><span class="s3">, </span><span class="s5">3</span><span class="s3">, -</span><span class="s5">4</span><span class="s3">])</span>
<a name="l743"><span class="ln">743  </span></a><span class="s1">out </span><span class="s3">= </span><span class="s1">f</span><span class="s3">(</span><span class="s1">x</span><span class="s3">)</span>
<a name="l744"><span class="ln">744  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">out</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;Output of function f is not a np.ndarray!&quot;</span>
<a name="l745"><span class="ln">745  </span></a><span class="s2">assert </span><span class="s1">out</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">x</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s4">&quot;Output of funcfion f has a wrong shape!&quot;</span>
<a name="l746"><span class="ln">746  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">out</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s5">1.71875</span><span class="s3">, -</span><span class="s5">8.</span><span class="s3">, </span><span class="s5">22.5</span><span class="s3">, -</span><span class="s5">128.</span><span class="s3">]), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l747"><span class="ln">747  </span></a><span class="s0">#%% 
<a name="l748"><span class="ln">748  </span></a></span><span class="s2">def </span><span class="s1">create_X_train</span><span class="s3">(</span><span class="s1">S</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">N</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">x_min</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">x_max</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">: </span><span class="s1">int</span><span class="s3">) </span><span class="s1">-&gt; np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">:</span>
<a name="l749"><span class="ln">749  </span></a>    <span class="s6">&quot;&quot;&quot;Generate `S` training sets, each containing `M` samples, within a specified interval. 
<a name="l750"><span class="ln">750  </span></a>    The function creates an array of shape (S, N) where each element is a sample drawn uniformly from the interval [`x_min`, `x_max`]. 
<a name="l751"><span class="ln">751  </span></a>     
<a name="l752"><span class="ln">752  </span></a>    Important: Use the function `np.random.uniform` to generate the data and `np.random.seed` to set the seed before generating the data! 
<a name="l753"><span class="ln">753  </span></a> 
<a name="l754"><span class="ln">754  </span></a>    Parameters 
<a name="l755"><span class="ln">755  </span></a>    ---------- 
<a name="l756"><span class="ln">756  </span></a>    S : int 
<a name="l757"><span class="ln">757  </span></a>        Number of training sets to create. 
<a name="l758"><span class="ln">758  </span></a>    N : int 
<a name="l759"><span class="ln">759  </span></a>        Number of samples per training set. 
<a name="l760"><span class="ln">760  </span></a>    x_min : float 
<a name="l761"><span class="ln">761  </span></a>        Lower bound of the sampling interval. 
<a name="l762"><span class="ln">762  </span></a>    x_max : float 
<a name="l763"><span class="ln">763  </span></a>        Upper bound of the sampling interval. 
<a name="l764"><span class="ln">764  </span></a>    seed : int 
<a name="l765"><span class="ln">765  </span></a>        Seed for reproducibility. 
<a name="l766"><span class="ln">766  </span></a> 
<a name="l767"><span class="ln">767  </span></a>    Returns 
<a name="l768"><span class="ln">768  </span></a>    ------- 
<a name="l769"><span class="ln">769  </span></a>    X_train : (S, N) np.ndarray 
<a name="l770"><span class="ln">770  </span></a>        A np.ndarray containing the generated sets of samples. 
<a name="l771"><span class="ln">771  </span></a>    &quot;&quot;&quot;</span>
<a name="l772"><span class="ln">772  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l773"><span class="ln">773  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">seed</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">)</span>
<a name="l774"><span class="ln">774  </span></a>    <span class="s1">X_train </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">uniform</span><span class="s3">(</span><span class="s1">x_min</span><span class="s3">, </span><span class="s1">x_max</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=(</span><span class="s1">S</span><span class="s3">, </span><span class="s1">N</span><span class="s3">))</span>
<a name="l775"><span class="ln">775  </span></a>    <span class="s2">return </span><span class="s1">X_train</span>
<a name="l776"><span class="ln">776  </span></a><span class="s0">#%% 
<a name="l777"><span class="ln">777  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l778"><span class="ln">778  </span></a><span class="s1">S </span><span class="s3">= </span><span class="s5">300</span>
<a name="l779"><span class="ln">779  </span></a><span class="s1">N </span><span class="s3">= </span><span class="s5">25</span>
<a name="l780"><span class="ln">780  </span></a><span class="s1">x_min </span><span class="s3">= -</span><span class="s5">1</span>
<a name="l781"><span class="ln">781  </span></a><span class="s1">x_max </span><span class="s3">= </span><span class="s5">3</span>
<a name="l782"><span class="ln">782  </span></a><span class="s1">seed </span><span class="s3">= </span><span class="s5">66</span>
<a name="l783"><span class="ln">783  </span></a>
<a name="l784"><span class="ln">784  </span></a><span class="s1">X_train </span><span class="s3">= </span><span class="s1">create_X_train</span><span class="s3">(</span><span class="s1">S</span><span class="s3">, </span><span class="s1">N</span><span class="s3">, </span><span class="s1">x_min</span><span class="s3">, </span><span class="s1">x_max</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">)</span>
<a name="l785"><span class="ln">785  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;X_train is not a np.ndarray!&quot;</span>
<a name="l786"><span class="ln">786  </span></a><span class="s2">assert </span><span class="s1">X_train</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">S</span><span class="s3">, </span><span class="s1">N</span><span class="s3">), </span><span class="s4">&quot;The output shape of X_train is incorrect!&quot;</span>
<a name="l787"><span class="ln">787  </span></a><span class="s0">#%% 
<a name="l788"><span class="ln">788  </span></a></span><span class="s2">def </span><span class="s1">create_y_train</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">mu</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">std</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">f</span><span class="s3">: </span><span class="s1">callable</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">: </span><span class="s1">int</span><span class="s3">) </span><span class="s1">-&gt; np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">:</span>
<a name="l789"><span class="ln">789  </span></a>    <span class="s6">&quot;&quot;&quot;Generate labels from training data using a function `f` with added Gaussian noise. 
<a name="l790"><span class="ln">790  </span></a> 
<a name="l791"><span class="ln">791  </span></a>    This function applies `f` to the training set `X_train` to generate labels, then adds  
<a name="l792"><span class="ln">792  </span></a>    Gaussian noise with specified mean `mu` and standard deviation `std` to each label.  
<a name="l793"><span class="ln">793  </span></a>    A seed is used for reproducibility. 
<a name="l794"><span class="ln">794  </span></a> 
<a name="l795"><span class="ln">795  </span></a>    Important: Use `np.random.seed` to set the seed and np.random.normal for the Gaussian noise! 
<a name="l796"><span class="ln">796  </span></a> 
<a name="l797"><span class="ln">797  </span></a>    Parameters 
<a name="l798"><span class="ln">798  </span></a>    ---------- 
<a name="l799"><span class="ln">799  </span></a>    X_train : (S, N) np.ndarray 
<a name="l800"><span class="ln">800  </span></a>        The training data set to which the function `f` will be applied. 
<a name="l801"><span class="ln">801  </span></a>    mu : float 
<a name="l802"><span class="ln">802  </span></a>        Mean of the Gaussian noise. 
<a name="l803"><span class="ln">803  </span></a>    std : float 
<a name="l804"><span class="ln">804  </span></a>        Standard deviation of the Gaussian noise. 
<a name="l805"><span class="ln">805  </span></a>    f : callable 
<a name="l806"><span class="ln">806  </span></a>        A function to apply to `X_train` to generate labels. 
<a name="l807"><span class="ln">807  </span></a>    seed : int 
<a name="l808"><span class="ln">808  </span></a>        Random seed for reproducibility. 
<a name="l809"><span class="ln">809  </span></a> 
<a name="l810"><span class="ln">810  </span></a>    Returns 
<a name="l811"><span class="ln">811  </span></a>    ------- 
<a name="l812"><span class="ln">812  </span></a>    y_train : (S, N) np.ndarray 
<a name="l813"><span class="ln">813  </span></a>        An array containing the generated labels with added noise. 
<a name="l814"><span class="ln">814  </span></a>    &quot;&quot;&quot;</span>
<a name="l815"><span class="ln">815  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l816"><span class="ln">816  </span></a>    <span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">seed</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">)</span>
<a name="l817"><span class="ln">817  </span></a>    <span class="s1">noise </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">mu</span><span class="s3">, </span><span class="s1">std</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">X_train</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>
<a name="l818"><span class="ln">818  </span></a>    <span class="s1">y_train </span><span class="s3">= </span><span class="s1">f</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">) + </span><span class="s1">noise</span>
<a name="l819"><span class="ln">819  </span></a>    <span class="s2">return </span><span class="s1">y_train</span>
<a name="l820"><span class="ln">820  </span></a><span class="s0">#%% 
<a name="l821"><span class="ln">821  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l822"><span class="ln">822  </span></a><span class="s1">seed </span><span class="s3">= </span><span class="s5">66</span>
<a name="l823"><span class="ln">823  </span></a><span class="s1">mu </span><span class="s3">= </span><span class="s5">0</span>
<a name="l824"><span class="ln">824  </span></a><span class="s1">std </span><span class="s3">= </span><span class="s5">2</span>
<a name="l825"><span class="ln">825  </span></a><span class="s1">ref_X_train </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">10</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">2</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">)</span>
<a name="l826"><span class="ln">826  </span></a>
<a name="l827"><span class="ln">827  </span></a><span class="s1">ref_y_train </span><span class="s3">= </span><span class="s1">create_y_train</span><span class="s3">(</span><span class="s1">ref_X_train</span><span class="s3">, </span><span class="s1">mu</span><span class="s3">, </span><span class="s1">std</span><span class="s3">, </span><span class="s2">lambda </span><span class="s1">x</span><span class="s3">: </span><span class="s1">x</span><span class="s3">**</span><span class="s5">2</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">)</span>
<a name="l828"><span class="ln">828  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">ref_y_train</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;y_train is not a np.ndarray!&quot;</span>
<a name="l829"><span class="ln">829  </span></a><span class="s2">assert </span><span class="s1">ref_y_train</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">ref_X_train</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s4">&quot;y_train has a wrong shape!&quot;</span>
<a name="l830"><span class="ln">830  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">ref_y_train</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s5">2.83122873</span><span class="s3">, -</span><span class="s5">1.1705728</span><span class="s3">, </span><span class="s5">2.76738393</span><span class="s3">, </span><span class="s5">7.48616765</span><span class="s3">, </span><span class="s5">16.69409546</span><span class="s3">], [</span><span class="s5">28.11298221</span><span class="s3">, </span><span class="s5">30.08730288</span><span class="s3">, </span><span class="s5">51.71816136</span><span class="s3">, </span><span class="s5">65.29669358</span><span class="s3">, </span><span class="s5">81.57205749</span><span class="s3">]]), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l831"><span class="ln">831  </span></a><span class="s0">#%% 
<a name="l832"><span class="ln">832  </span></a></span><span class="s2">def </span><span class="s1">bias_var</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">x_test</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">M</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">f</span><span class="s3">: </span><span class="s1">callable</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">: </span><span class="s1">int</span><span class="s3">) </span><span class="s1">-&gt; tuple</span><span class="s3">[</span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">]: </span>
<a name="l833"><span class="ln">833  </span></a>    <span class="s6">&quot;&quot;&quot;Compute model bias and variance for polynomial regression models of varying degrees. 
<a name="l834"><span class="ln">834  </span></a> 
<a name="l835"><span class="ln">835  </span></a>    This function estimates the squared bias and variance of polynomial regression models 
<a name="l836"><span class="ln">836  </span></a>    of degrees ranging from 1 to `M` by sampling training sets, fitting each model,  
<a name="l837"><span class="ln">837  </span></a>    and evaluating each at a specified test set `x_test`. 
<a name="l838"><span class="ln">838  </span></a> 
<a name="l839"><span class="ln">839  </span></a>    Important: Pass the seed to `pol_reg_pred` and use this function  
<a name="l840"><span class="ln">840  </span></a>    for computing the predictions of the polynomial regression models! 
<a name="l841"><span class="ln">841  </span></a> 
<a name="l842"><span class="ln">842  </span></a>    Parameters 
<a name="l843"><span class="ln">843  </span></a>    ---------- 
<a name="l844"><span class="ln">844  </span></a>    X_train : (S, N) np.ndarray 
<a name="l845"><span class="ln">845  </span></a>        Array of training data sets, where each element is an array of samples. 
<a name="l846"><span class="ln">846  </span></a>    y_train : (S, N) np.ndarray 
<a name="l847"><span class="ln">847  </span></a>        Array of training label sets, where each element is an array of labels. 
<a name="l848"><span class="ln">848  </span></a>    x_test : np.ndarray 
<a name="l849"><span class="ln">849  </span></a>        A 1D test data set. 
<a name="l850"><span class="ln">850  </span></a>    M : int 
<a name="l851"><span class="ln">851  </span></a>        The maximum polynomial degree to evaluate. 
<a name="l852"><span class="ln">852  </span></a>    f : callable 
<a name="l853"><span class="ln">853  </span></a>        The true function to compare the predictions against. 
<a name="l854"><span class="ln">854  </span></a>    seed : int 
<a name="l855"><span class="ln">855  </span></a>        Random seed for reproducibility. 
<a name="l856"><span class="ln">856  </span></a> 
<a name="l857"><span class="ln">857  </span></a>    Returns 
<a name="l858"><span class="ln">858  </span></a>    ------- 
<a name="l859"><span class="ln">859  </span></a>    tuple of np.ndarray 
<a name="l860"><span class="ln">860  </span></a>        - sqbias : (M,) np.ndarray 
<a name="l861"><span class="ln">861  </span></a>            Array of squared bias values for polynomial degrees from 1 to `M`. 
<a name="l862"><span class="ln">862  </span></a>        - variance : (M,) np.ndarray 
<a name="l863"><span class="ln">863  </span></a>            Array of variance values for polynomial degrees from 1 to `M`. 
<a name="l864"><span class="ln">864  </span></a>    &quot;&quot;&quot;</span>
<a name="l865"><span class="ln">865  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l866"><span class="ln">866  </span></a>    <span class="s1">S </span><span class="s3">= </span><span class="s1">X_train</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">]</span>
<a name="l867"><span class="ln">867  </span></a>    <span class="s1">x_test </span><span class="s3">= </span><span class="s1">x_test</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s5">1</span><span class="s3">)</span>
<a name="l868"><span class="ln">868  </span></a>    <span class="s1">num_test </span><span class="s3">= </span><span class="s1">x_test</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">]</span>
<a name="l869"><span class="ln">869  </span></a>    <span class="s1">sqbias </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">M</span><span class="s3">)</span>
<a name="l870"><span class="ln">870  </span></a>    <span class="s1">variance </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">M</span><span class="s3">)</span>
<a name="l871"><span class="ln">871  </span></a>    
<a name="l872"><span class="ln">872  </span></a>    <span class="s1">f_x_test </span><span class="s3">= </span><span class="s1">f</span><span class="s3">(</span><span class="s1">x_test</span><span class="s3">)</span>
<a name="l873"><span class="ln">873  </span></a>    
<a name="l874"><span class="ln">874  </span></a>    <span class="s2">for </span><span class="s1">m </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s5">1</span><span class="s3">, </span><span class="s1">M</span><span class="s3">+</span><span class="s5">1</span><span class="s3">):</span>
<a name="l875"><span class="ln">875  </span></a>        <span class="s1">predictions </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">((</span><span class="s1">S</span><span class="s3">, </span><span class="s1">num_test</span><span class="s3">))</span>
<a name="l876"><span class="ln">876  </span></a>        <span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">S</span><span class="s3">):</span>
<a name="l877"><span class="ln">877  </span></a>            <span class="s1">y_pred </span><span class="s3">= </span><span class="s1">pol_reg_pred</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">[</span><span class="s1">s</span><span class="s3">], </span><span class="s1">y_train</span><span class="s3">[</span><span class="s1">s</span><span class="s3">], </span><span class="s1">x_test</span><span class="s3">, </span><span class="s1">m</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">)</span>
<a name="l878"><span class="ln">878  </span></a>            <span class="s1">predictions</span><span class="s3">[</span><span class="s1">s</span><span class="s3">] = </span><span class="s1">y_pred</span>
<a name="l879"><span class="ln">879  </span></a>        <span class="s1">mean_pred </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">predictions</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
<a name="l880"><span class="ln">880  </span></a>        <span class="s0"># Compute squared bias</span>
<a name="l881"><span class="ln">881  </span></a>        <span class="s1">sqbias</span><span class="s3">[</span><span class="s1">m</span><span class="s3">-</span><span class="s5">1</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">( (</span><span class="s1">mean_pred </span><span class="s3">- </span><span class="s1">f_x_test</span><span class="s3">)**</span><span class="s5">2 </span><span class="s3">)</span>
<a name="l882"><span class="ln">882  </span></a>        <span class="s0"># Compute variance</span>
<a name="l883"><span class="ln">883  </span></a>        <span class="s1">variance</span><span class="s3">[</span><span class="s1">m</span><span class="s3">-</span><span class="s5">1</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">( </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">( (</span><span class="s1">predictions </span><span class="s3">- </span><span class="s1">mean_pred</span><span class="s3">)**</span><span class="s5">2</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1 </span><span class="s3">) )</span>
<a name="l884"><span class="ln">884  </span></a>    
<a name="l885"><span class="ln">885  </span></a>    <span class="s2">return </span><span class="s1">sqbias</span><span class="s3">, </span><span class="s1">variance</span>
<a name="l886"><span class="ln">886  </span></a><span class="s0">#%% 
<a name="l887"><span class="ln">887  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l888"><span class="ln">888  </span></a><span class="s1">seed </span><span class="s3">= </span><span class="s5">66</span>
<a name="l889"><span class="ln">889  </span></a><span class="s1">M </span><span class="s3">= </span><span class="s5">11</span>
<a name="l890"><span class="ln">890  </span></a><span class="s1">ref_X_train </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">10</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">2</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">)</span>
<a name="l891"><span class="ln">891  </span></a><span class="s1">ref_y_train </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">10</span><span class="s3">, </span><span class="s5">20</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">2</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">)</span>
<a name="l892"><span class="ln">892  </span></a><span class="s1">ref_x_test </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">5</span><span class="s3">)</span>
<a name="l893"><span class="ln">893  </span></a>
<a name="l894"><span class="ln">894  </span></a><span class="s1">ref_sqbias</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">bias_var</span><span class="s3">(</span><span class="s1">ref_X_train</span><span class="s3">, </span><span class="s1">ref_y_train</span><span class="s3">, </span><span class="s1">ref_x_test</span><span class="s3">, </span><span class="s1">M</span><span class="s3">, </span><span class="s2">lambda </span><span class="s1">x</span><span class="s3">: </span><span class="s1">x</span><span class="s3">**</span><span class="s5">2</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">)</span>
<a name="l895"><span class="ln">895  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">ref_sqbias</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The returned squared bias is not a np.ndarray!&quot;</span>
<a name="l896"><span class="ln">896  </span></a><span class="s2">assert </span><span class="s1">ref_sqbias</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">M</span><span class="s3">,), </span><span class="s4">&quot;The returned squared bias has a wrong shape!&quot;</span>
<a name="l897"><span class="ln">897  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">ref_sqbias</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">56.8</span><span class="s3">, </span><span class="s5">56.8</span><span class="s3">, </span><span class="s5">56.8</span><span class="s3">, </span><span class="s5">56.8</span><span class="s3">, </span><span class="s5">60.8229</span><span class="s3">, </span><span class="s5">64.8283</span><span class="s3">, </span><span class="s5">68.2727</span><span class="s3">, </span><span class="s5">71.0926</span><span class="s3">, </span><span class="s5">73.3658</span><span class="s3">, </span><span class="s5">75.1944</span><span class="s3">, </span><span class="s5">76.6702</span><span class="s3">]), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l898"><span class="ln">898  </span></a><span class="s0">#%% 
<a name="l899"><span class="ln">899  </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l900"><span class="ln">900  </span></a><span class="s1">seed </span><span class="s3">= </span><span class="s5">66</span>
<a name="l901"><span class="ln">901  </span></a><span class="s1">M </span><span class="s3">= </span><span class="s5">11</span>
<a name="l902"><span class="ln">902  </span></a><span class="s1">ref_X_train </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">10</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">2</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">)</span>
<a name="l903"><span class="ln">903  </span></a><span class="s1">ref_y_train </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">10</span><span class="s3">, </span><span class="s5">20</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(</span><span class="s5">2</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">)</span>
<a name="l904"><span class="ln">904  </span></a><span class="s1">ref_x_test </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">5</span><span class="s3">)</span>
<a name="l905"><span class="ln">905  </span></a>
<a name="l906"><span class="ln">906  </span></a><span class="s1">_</span><span class="s3">, </span><span class="s1">ref_var </span><span class="s3">= </span><span class="s1">bias_var</span><span class="s3">(</span><span class="s1">ref_X_train</span><span class="s3">, </span><span class="s1">ref_y_train</span><span class="s3">, </span><span class="s1">ref_x_test</span><span class="s3">, </span><span class="s1">M</span><span class="s3">, </span><span class="s2">lambda </span><span class="s1">x</span><span class="s3">: </span><span class="s1">x</span><span class="s3">**</span><span class="s5">2</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">)</span>
<a name="l907"><span class="ln">907  </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">ref_var</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">), </span><span class="s4">&quot;The returned variance is not a np.ndarray!&quot;</span>
<a name="l908"><span class="ln">908  </span></a><span class="s2">assert </span><span class="s1">ref_var</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">M</span><span class="s3">,), </span><span class="s4">&quot;The returned variance has a wrong shape!&quot;</span>
<a name="l909"><span class="ln">909  </span></a><span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">ref_var</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">0.0000e+00</span><span class="s3">, </span><span class="s5">2.5244e-30</span><span class="s3">, </span><span class="s5">6.2031e-25</span><span class="s3">, </span><span class="s5">4.5267e-22</span><span class="s3">, </span><span class="s5">9.3123e-02</span><span class="s3">, </span><span class="s5">3.1799e-01</span><span class="s3">, </span><span class="s5">5.9439e-01</span><span class="s3">, </span><span class="s5">8.7445e-01</span><span class="s3">, </span><span class="s5">1.1357e+00</span><span class="s3">, </span><span class="s5">1.3697e+00</span><span class="s3">, </span><span class="s5">1.5748e+00</span><span class="s3">]), </span><span class="s5">4</span><span class="s3">)</span>
<a name="l910"><span class="ln">910  </span></a><span class="s0">#%% 
<a name="l911"><span class="ln">911  </span></a># Nothing to do here, just run the cell.</span>
<a name="l912"><span class="ln">912  </span></a><span class="s1">seed </span><span class="s3">= </span><span class="s5">12</span>
<a name="l913"><span class="ln">913  </span></a><span class="s1">S </span><span class="s3">= </span><span class="s5">300</span>
<a name="l914"><span class="ln">914  </span></a><span class="s1">N </span><span class="s3">= </span><span class="s5">25</span>
<a name="l915"><span class="ln">915  </span></a><span class="s1">M </span><span class="s3">= </span><span class="s5">11</span>
<a name="l916"><span class="ln">916  </span></a><span class="s1">x_min </span><span class="s3">= -</span><span class="s5">1</span>
<a name="l917"><span class="ln">917  </span></a><span class="s1">x_max </span><span class="s3">= </span><span class="s5">3</span>
<a name="l918"><span class="ln">918  </span></a><span class="s1">mu </span><span class="s3">= </span><span class="s5">0</span>
<a name="l919"><span class="ln">919  </span></a><span class="s1">sigma_squared </span><span class="s3">= </span><span class="s5">4</span>
<a name="l920"><span class="ln">920  </span></a><span class="s1">std </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sqrt</span><span class="s3">(</span><span class="s1">sigma_squared</span><span class="s3">)</span>
<a name="l921"><span class="ln">921  </span></a><span class="s1">x_test </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">1.7</span><span class="s3">])</span>
<a name="l922"><span class="ln">922  </span></a>
<a name="l923"><span class="ln">923  </span></a><span class="s1">X_train </span><span class="s3">= </span><span class="s1">create_X_train</span><span class="s3">(</span><span class="s1">S</span><span class="s3">,</span><span class="s1">N</span><span class="s3">,</span><span class="s1">x_min</span><span class="s3">,</span><span class="s1">x_max</span><span class="s3">,</span><span class="s1">seed</span><span class="s3">)</span>
<a name="l924"><span class="ln">924  </span></a><span class="s1">y_train </span><span class="s3">= </span><span class="s1">create_y_train</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">,</span><span class="s1">mu</span><span class="s3">,</span><span class="s1">std</span><span class="s3">,</span><span class="s1">f</span><span class="s3">,</span><span class="s1">seed</span><span class="s3">)</span>
<a name="l925"><span class="ln">925  </span></a><span class="s1">sqbias</span><span class="s3">, </span><span class="s1">variance </span><span class="s3">= </span><span class="s1">bias_var</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">,</span><span class="s1">y_train</span><span class="s3">,</span><span class="s1">x_test</span><span class="s3">,</span><span class="s1">M</span><span class="s3">,</span><span class="s1">f</span><span class="s3">,</span><span class="s1">seed</span><span class="s3">)</span>
<a name="l926"><span class="ln">926  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;Shapes of X and y: </span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">,</span><span class="s1">X_train</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">,</span><span class="s1">y_train</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>
<a name="l927"><span class="ln">927  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">Squared Bias over m: </span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">, </span><span class="s1">sqbias</span><span class="s3">)</span>
<a name="l928"><span class="ln">928  </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">Variance over m: </span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s3">, </span><span class="s1">variance</span><span class="s3">)</span>
<a name="l929"><span class="ln">929  </span></a><span class="s0">#%% md 
<a name="l930"><span class="ln">930  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Plot 4.3 (5 Points):&lt;/h3&gt; 
<a name="l931"><span class="ln">931  </span></a></span><span class="s0">#%% 
<a name="l932"><span class="ln">932  </span></a># Nothing to do here, just run the cell.</span>
<a name="l933"><span class="ln">933  </span></a><span class="s1">x_test </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s1">x_min</span><span class="s3">, </span><span class="s1">x_max</span><span class="s3">, </span><span class="s5">0.01</span><span class="s3">)</span>
<a name="l934"><span class="ln">934  </span></a><span class="s0">#%% 
<a name="l935"><span class="ln">935  </span></a></span><span class="s2">def </span><span class="s1">plot_regression</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">x_test</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">: </span><span class="s1">int</span><span class="s3">):</span>
<a name="l936"><span class="ln">936  </span></a>    <span class="s6">&quot;&quot;&quot;Creates a plot for the first set of training data and the corresponding regression models with m = {1, 4, 11}. 
<a name="l937"><span class="ln">937  </span></a> 
<a name="l938"><span class="ln">938  </span></a>    Important: Pass the seed to `pol_reg_pred` and use this function  
<a name="l939"><span class="ln">939  </span></a>    for computing the predictions of the polynomial regression models! 
<a name="l940"><span class="ln">940  </span></a> 
<a name="l941"><span class="ln">941  </span></a>    Parameters 
<a name="l942"><span class="ln">942  </span></a>    ---------- 
<a name="l943"><span class="ln">943  </span></a>    X_train : (S, N) np.ndarray 
<a name="l944"><span class="ln">944  </span></a>        Sets of training data. 
<a name="l945"><span class="ln">945  </span></a>    y_train : (S, N) np.ndarray 
<a name="l946"><span class="ln">946  </span></a>        Sets of training labels. 
<a name="l947"><span class="ln">947  </span></a>    x_test : np.ndarray 
<a name="l948"><span class="ln">948  </span></a>        Vector of test data. 
<a name="l949"><span class="ln">949  </span></a>    &quot;&quot;&quot;</span>
<a name="l950"><span class="ln">950  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l951"><span class="ln">951  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">figure</span><span class="s3">(</span><span class="s1">figsize</span><span class="s3">=(</span><span class="s5">10</span><span class="s3">, </span><span class="s5">6</span><span class="s3">))</span>
<a name="l952"><span class="ln">952  </span></a>    
<a name="l953"><span class="ln">953  </span></a>    <span class="s0"># Plot the first training set</span>
<a name="l954"><span class="ln">954  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">scatter</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">y_train</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">color</span><span class="s3">=</span><span class="s4">'blue'</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Training Data'</span><span class="s3">)</span>
<a name="l955"><span class="ln">955  </span></a>    
<a name="l956"><span class="ln">956  </span></a>    <span class="s0"># Generate true function values for plotting</span>
<a name="l957"><span class="ln">957  </span></a>    <span class="s1">f_x_test </span><span class="s3">= </span><span class="s1">f</span><span class="s3">(</span><span class="s1">x_test</span><span class="s3">)</span>
<a name="l958"><span class="ln">958  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">x_test</span><span class="s3">, </span><span class="s1">f_x_test</span><span class="s3">, </span><span class="s1">color</span><span class="s3">=</span><span class="s4">'black'</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'True Function'</span><span class="s3">)</span>
<a name="l959"><span class="ln">959  </span></a>    
<a name="l960"><span class="ln">960  </span></a>    <span class="s0"># For m = 1, 4, 11</span>
<a name="l961"><span class="ln">961  </span></a>    <span class="s1">degrees </span><span class="s3">= [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">4</span><span class="s3">, </span><span class="s5">11</span><span class="s3">]</span>
<a name="l962"><span class="ln">962  </span></a>    <span class="s1">colors </span><span class="s3">= [</span><span class="s4">'red'</span><span class="s3">, </span><span class="s4">'green'</span><span class="s3">, </span><span class="s4">'orange'</span><span class="s3">]</span>
<a name="l963"><span class="ln">963  </span></a>    <span class="s2">for </span><span class="s1">m</span><span class="s3">, </span><span class="s1">color </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span><span class="s1">degrees</span><span class="s3">, </span><span class="s1">colors</span><span class="s3">):</span>
<a name="l964"><span class="ln">964  </span></a>        <span class="s1">y_pred </span><span class="s3">= </span><span class="s1">pol_reg_pred</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">y_train</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">x_test</span><span class="s3">, </span><span class="s1">m</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">)</span>
<a name="l965"><span class="ln">965  </span></a>        <span class="s1">plt</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">x_test</span><span class="s3">, </span><span class="s1">y_pred</span><span class="s3">, </span><span class="s1">color</span><span class="s3">=</span><span class="s1">color</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">f'Polynomial Degree </span><span class="s2">{</span><span class="s1">m</span><span class="s2">}</span><span class="s4">'</span><span class="s3">)</span>
<a name="l966"><span class="ln">966  </span></a>    
<a name="l967"><span class="ln">967  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">xlabel</span><span class="s3">(</span><span class="s4">'x'</span><span class="s3">)</span>
<a name="l968"><span class="ln">968  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">ylabel</span><span class="s3">(</span><span class="s4">'y'</span><span class="s3">)</span>
<a name="l969"><span class="ln">969  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">title</span><span class="s3">(</span><span class="s4">'Polynomial Regression Models'</span><span class="s3">)</span>
<a name="l970"><span class="ln">970  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">legend</span><span class="s3">()</span>
<a name="l971"><span class="ln">971  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">show</span><span class="s3">()</span>
<a name="l972"><span class="ln">972  </span></a><span class="s0">#%% 
<a name="l973"><span class="ln">973  </span></a># Nothing to do here, just run the cell.</span>
<a name="l974"><span class="ln">974  </span></a><span class="s1">plot_regression</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">x_test</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">)</span>
<a name="l975"><span class="ln">975  </span></a><span class="s0">#%% md 
<a name="l976"><span class="ln">976  </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Plot 4.4 (5 Points):&lt;/h3&gt; 
<a name="l977"><span class="ln">977  </span></a></span><span class="s0">#%% 
<a name="l978"><span class="ln">978  </span></a></span><span class="s2">def </span><span class="s1">plot_combination</span><span class="s3">(</span><span class="s1">M</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">sigma</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">bias</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">, </span><span class="s1">var</span><span class="s3">: </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ndarray</span><span class="s3">):</span>
<a name="l979"><span class="ln">979  </span></a>    <span class="s6">&quot;&quot;&quot;Creates a plot for the unavoidable error, bias, variance, and Expected Prediction Error (EPE) versus polynomial degree `m` in the range [1, M]. 
<a name="l980"><span class="ln">980  </span></a> 
<a name="l981"><span class="ln">981  </span></a>    Parameters 
<a name="l982"><span class="ln">982  </span></a>    ---------- 
<a name="l983"><span class="ln">983  </span></a>    M : int 
<a name="l984"><span class="ln">984  </span></a>        The maximum polynomial degree for which to plot the error components, with `m` ranging from 1 to `M`. 
<a name="l985"><span class="ln">985  </span></a>    sigma : float 
<a name="l986"><span class="ln">986  </span></a>        The unavoidable error level, representing noise in the data. 
<a name="l987"><span class="ln">987  </span></a>    bias : np.ndarray 
<a name="l988"><span class="ln">988  </span></a>        Array of squared bias values for polynomial degrees in [1, M]. 
<a name="l989"><span class="ln">989  </span></a>    var : np.ndarray 
<a name="l990"><span class="ln">990  </span></a>        Array of variance values for polynomial degrees in [1, M]. 
<a name="l991"><span class="ln">991  </span></a>    &quot;&quot;&quot;</span>
<a name="l992"><span class="ln">992  </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l993"><span class="ln">993  </span></a>    <span class="s1">m_values </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s5">1</span><span class="s3">, </span><span class="s1">M</span><span class="s3">+</span><span class="s5">1</span><span class="s3">)</span>
<a name="l994"><span class="ln">994  </span></a>    <span class="s1">unavoidable_error </span><span class="s3">= </span><span class="s1">sigma  </span><span class="s0"># Since variance of noise is sigma_squared</span>
<a name="l995"><span class="ln">995  </span></a>    
<a name="l996"><span class="ln">996  </span></a>    <span class="s1">total_EPE </span><span class="s3">= </span><span class="s1">unavoidable_error </span><span class="s3">+ </span><span class="s1">bias </span><span class="s3">+ </span><span class="s1">var</span>
<a name="l997"><span class="ln">997  </span></a>    
<a name="l998"><span class="ln">998  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">figure</span><span class="s3">(</span><span class="s1">figsize</span><span class="s3">=(</span><span class="s5">10</span><span class="s3">,</span><span class="s5">6</span><span class="s3">))</span>
<a name="l999"><span class="ln">999  </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">m_values</span><span class="s3">, [</span><span class="s1">unavoidable_error</span><span class="s3">]*</span><span class="s1">M</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Unavoidable Error'</span><span class="s3">, </span><span class="s1">marker</span><span class="s3">=</span><span class="s4">'o'</span><span class="s3">)</span>
<a name="l1000"><span class="ln">1000 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">m_values</span><span class="s3">, </span><span class="s1">bias</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Squared Bias'</span><span class="s3">, </span><span class="s1">marker</span><span class="s3">=</span><span class="s4">'o'</span><span class="s3">)</span>
<a name="l1001"><span class="ln">1001 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">m_values</span><span class="s3">, </span><span class="s1">var</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Variance'</span><span class="s3">, </span><span class="s1">marker</span><span class="s3">=</span><span class="s4">'o'</span><span class="s3">)</span>
<a name="l1002"><span class="ln">1002 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">m_values</span><span class="s3">, </span><span class="s1">total_EPE</span><span class="s3">, </span><span class="s1">label</span><span class="s3">=</span><span class="s4">'Total EPE'</span><span class="s3">, </span><span class="s1">marker</span><span class="s3">=</span><span class="s4">'o'</span><span class="s3">)</span>
<a name="l1003"><span class="ln">1003 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">xlabel</span><span class="s3">(</span><span class="s4">'Polynomial Degree m'</span><span class="s3">)</span>
<a name="l1004"><span class="ln">1004 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">ylabel</span><span class="s3">(</span><span class="s4">'Error'</span><span class="s3">)</span>
<a name="l1005"><span class="ln">1005 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">title</span><span class="s3">(</span><span class="s4">'Bias-Variance Decomposition over Polynomial Degree'</span><span class="s3">)</span>
<a name="l1006"><span class="ln">1006 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">legend</span><span class="s3">()</span>
<a name="l1007"><span class="ln">1007 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">xticks</span><span class="s3">(</span><span class="s1">m_values</span><span class="s3">)</span>
<a name="l1008"><span class="ln">1008 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">grid</span><span class="s3">(</span><span class="s2">True</span><span class="s3">)</span>
<a name="l1009"><span class="ln">1009 </span></a>    <span class="s1">plt</span><span class="s3">.</span><span class="s1">show</span><span class="s3">()</span>
<a name="l1010"><span class="ln">1010 </span></a><span class="s0">#%% 
<a name="l1011"><span class="ln">1011 </span></a># Nothing to do here, just run the cell.</span>
<a name="l1012"><span class="ln">1012 </span></a><span class="s1">plot_combination</span><span class="s3">(</span><span class="s1">M</span><span class="s3">, </span><span class="s1">sigma_squared</span><span class="s3">, </span><span class="s1">sqbias</span><span class="s3">, </span><span class="s1">variance</span><span class="s3">)</span>
<a name="l1013"><span class="ln">1013 </span></a><span class="s0">#%% md 
<a name="l1014"><span class="ln">1014 </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Question 4.4 (5 Points):&lt;/h3&gt; 
<a name="l1015"><span class="ln">1015 </span></a> 
<a name="l1016"><span class="ln">1016 </span></a>If you did the previous task correctly, the resulting plot should have many similarities or should be identical to the following plot: 
<a name="l1017"><span class="ln">1017 </span></a> 
<a name="l1018"><span class="ln">1018 </span></a>![combined.png](attachment:9de352ae-f814-439f-880b-6f51a3830d56.png) 
<a name="l1019"><span class="ln">1019 </span></a> 
<a name="l1020"><span class="ln">1020 </span></a>***What observations can you make from this plot? Answer which of the following statements are correct (several may be correct):*** 
<a name="l1021"><span class="ln">1021 </span></a> 
<a name="l1022"><span class="ln">1022 </span></a>a4_) The variance is low for models which are too complex, i.e. $m \leq 2$. &lt;br&gt; 
<a name="l1023"><span class="ln">1023 </span></a>b4_) For appropriate complexity, i.e. $3 \leq m \leq 6$, both model variance and bias are low, which can indicate good generalization abilities.&lt;br&gt; 
<a name="l1024"><span class="ln">1024 </span></a>c4_) As the model becomes too complex, i.e. $m \geq 9$, the variance increases again while the bias stays low. This is an indication for overfitting.&lt;br&gt; 
<a name="l1025"><span class="ln">1025 </span></a>d4_) For models with $m \geq 9$, the variance is high (i.e. significantly larger than $0$) because the independent noise has zero mean and high individual biases cancel in expectation. &lt;br&gt; 
<a name="l1026"><span class="ln">1026 </span></a>e4_) For models with $m \geq 9$, the bias is still low (i.e. close to $0$) because the independent noise has zero mean and high individual biases cancel in expectation. &lt;br&gt; 
<a name="l1027"><span class="ln">1027 </span></a> 
<a name="l1028"><span class="ln">1028 </span></a>To answer the question, assign &quot;True&quot; or &quot;False&quot; boolean values to variables in the next cell. For example, if you think that **a4_)** is correct, define a variable `a4_` and set it to `True`, the same applies to **b4_)** and the other statements. A non-correctly answered statement as well as no answer (i.e. answer “None”) yields 0 points for a specific statement.&lt;br&gt; 
<a name="l1029"><span class="ln">1029 </span></a>&lt;b&gt;Note:&lt;/b&gt; Do not reuse these variable names. They are used for testing. 
<a name="l1030"><span class="ln">1030 </span></a></span><span class="s0">#%% 
<a name="l1031"><span class="ln">1031 </span></a># YOUR CODE HERE</span>
<a name="l1032"><span class="ln">1032 </span></a><span class="s1">a4_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l1033"><span class="ln">1033 </span></a><span class="s1">b4_ </span><span class="s3">= </span><span class="s2">True</span>
<a name="l1034"><span class="ln">1034 </span></a><span class="s1">c4_ </span><span class="s3">= </span><span class="s2">True</span>
<a name="l1035"><span class="ln">1035 </span></a><span class="s1">d4_ </span><span class="s3">= </span><span class="s2">False</span>
<a name="l1036"><span class="ln">1036 </span></a><span class="s1">e4_ </span><span class="s3">= </span><span class="s2">True</span>
<a name="l1037"><span class="ln">1037 </span></a><span class="s0">#%% 
<a name="l1038"><span class="ln">1038 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1039"><span class="ln">1039 </span></a><span class="s2">assert </span><span class="s1">a4_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l1040"><span class="ln">1040 </span></a><span class="s2">assert </span><span class="s1">a4_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l1041"><span class="ln">1041 </span></a><span class="s0">#%% 
<a name="l1042"><span class="ln">1042 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1043"><span class="ln">1043 </span></a><span class="s2">assert </span><span class="s1">b4_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l1044"><span class="ln">1044 </span></a><span class="s2">assert </span><span class="s1">b4_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l1045"><span class="ln">1045 </span></a><span class="s0">#%% 
<a name="l1046"><span class="ln">1046 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1047"><span class="ln">1047 </span></a><span class="s2">assert </span><span class="s1">c4_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l1048"><span class="ln">1048 </span></a><span class="s2">assert </span><span class="s1">c4_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l1049"><span class="ln">1049 </span></a><span class="s0">#%% 
<a name="l1050"><span class="ln">1050 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1051"><span class="ln">1051 </span></a><span class="s2">assert </span><span class="s1">d4_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l1052"><span class="ln">1052 </span></a><span class="s2">assert </span><span class="s1">d4_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l1053"><span class="ln">1053 </span></a><span class="s0">#%% 
<a name="l1054"><span class="ln">1054 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1055"><span class="ln">1055 </span></a><span class="s2">assert </span><span class="s1">e4_ </span><span class="s2">is not None</span><span class="s3">, </span><span class="s4">&quot;Store True/False!&quot;</span>
<a name="l1056"><span class="ln">1056 </span></a><span class="s2">assert </span><span class="s1">e4_ </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], </span><span class="s4">&quot;Invalid Answer!&quot;</span>
<a name="l1057"><span class="ln">1057 </span></a><span class="s0">#%% md 
<a name="l1058"><span class="ln">1058 </span></a></span><span class="s1">&lt;h2 style=&quot;color:rgb(0,120,170)&quot;&gt;Task 5: Evaluation metrics for imbalanced data sets&lt;/h2&gt; 
<a name="l1059"><span class="ln">1059 </span></a></span><span class="s0">#%% md 
<a name="l1060"><span class="ln">1060 </span></a></span><span class="s1">Consider a classifier with discriminant function $\bar g$. 
<a name="l1061"><span class="ln">1061 </span></a>For a given labeled data set, the following results are obtained: 
<a name="l1062"><span class="ln">1062 </span></a>$$\begin{array}{|r|r|} 
<a name="l1063"><span class="ln">1063 </span></a>\hline 
<a name="l1064"><span class="ln">1064 </span></a>y &amp; \bar g(x)\\ 
<a name="l1065"><span class="ln">1065 </span></a>\hline \hline 
<a name="l1066"><span class="ln">1066 </span></a> +1 &amp; 0.93 \\ 
<a name="l1067"><span class="ln">1067 </span></a> +1 &amp; 0.51 \\ 
<a name="l1068"><span class="ln">1068 </span></a> -1 &amp; 0.48 \\ 
<a name="l1069"><span class="ln">1069 </span></a> -1 &amp; 0.13 \\ 
<a name="l1070"><span class="ln">1070 </span></a> +1 &amp; 0.02 \\ 
<a name="l1071"><span class="ln">1071 </span></a> -1 &amp; -0.11 \\ 
<a name="l1072"><span class="ln">1072 </span></a> -1 &amp; -0.25 \\ 
<a name="l1073"><span class="ln">1073 </span></a> -1 &amp; -0.37 \\ 
<a name="l1074"><span class="ln">1074 </span></a> +1 &amp; -0.41 \\ 
<a name="l1075"><span class="ln">1075 </span></a> -1 &amp; -1.68 \\ 
<a name="l1076"><span class="ln">1076 </span></a> +1 &amp; -2.23 \\ 
<a name="l1077"><span class="ln">1077 </span></a> +1 &amp; -3.41 \\ 
<a name="l1078"><span class="ln">1078 </span></a>\hline 
<a name="l1079"><span class="ln">1079 </span></a>\end{array}$$ 
<a name="l1080"><span class="ln">1080 </span></a> 
<a name="l1081"><span class="ln">1081 </span></a>* **Code 5.1**: 
<a name="l1082"><span class="ln">1082 </span></a>  * Compute the confusion matrix using the usual $\theta = 0$ threshold. 
<a name="l1083"><span class="ln">1083 </span></a>  * Complete the function `evaluation_metrics` to calculate the following evaluation measures: TPR, TNR, FPR, FNR, ACC, BACC, PREC, and $F_1$. 
<a name="l1084"><span class="ln">1084 </span></a> 
<a name="l1085"><span class="ln">1085 </span></a>Let's say we have a population of 1000 people and we know that 50 are infected with the corona virus. 
<a name="l1086"><span class="ln">1086 </span></a>* **Code 5.2**: Assume that the population is tested with an assay that has a certain specificity and sensitivity. 
<a name="l1087"><span class="ln">1087 </span></a> 
<a name="l1088"><span class="ln">1088 </span></a>  * (1) What is the probability $p_1$ that a person is *not* infected if they are diagnosed as ill by the test? &lt;br&gt; 
<a name="l1089"><span class="ln">1089 </span></a>  * (2) What is the probability $p_2$ that a person is infected if they are diagnosed as healthy by the test? 
<a name="l1090"><span class="ln">1090 </span></a> 
<a name="l1091"><span class="ln">1091 </span></a>Write a function that returns both values. Then check your calculation using specificity of $90 \%$ and sensitivity of $95 \%$. 
<a name="l1092"><span class="ln">1092 </span></a> 
<a name="l1093"><span class="ln">1093 </span></a>**Important**: Round your result to 4 decimal points, i.e. 0.9871 if it is 98.71%. 
<a name="l1094"><span class="ln">1094 </span></a></span><span class="s0">#%% md 
<a name="l1095"><span class="ln">1095 </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Code 5.1 (8 Points):&lt;/h3&gt; 
<a name="l1096"><span class="ln">1096 </span></a></span><span class="s0">#%% md 
<a name="l1097"><span class="ln">1097 </span></a></span><span class="s1">* &lt;b&gt;Reminder:&lt;/b&gt; Confusion Matrix structure: 
<a name="l1098"><span class="ln">1098 </span></a> 
<a name="l1099"><span class="ln">1099 </span></a>$$ 
<a name="l1100"><span class="ln">1100 </span></a>\begin{array}{|c|c|c|} 
<a name="l1101"><span class="ln">1101 </span></a>\hline 
<a name="l1102"><span class="ln">1102 </span></a> &amp; g(x)=+1  &amp; g(x)=-1\\ 
<a name="l1103"><span class="ln">1103 </span></a> \hline 
<a name="l1104"><span class="ln">1104 </span></a> y=+1 &amp; \text{TP}  &amp; \text{FN} \\ 
<a name="l1105"><span class="ln">1105 </span></a> \hline 
<a name="l1106"><span class="ln">1106 </span></a> y=-1 &amp; \text{FP} &amp; \text{TN} \\ 
<a name="l1107"><span class="ln">1107 </span></a>\hline 
<a name="l1108"><span class="ln">1108 </span></a>\end{array} 
<a name="l1109"><span class="ln">1109 </span></a>$$ 
<a name="l1110"><span class="ln">1110 </span></a> 
<a name="l1111"><span class="ln">1111 </span></a>Define 4 variables `TP_`, `FN_`, `FP_` and `TN_` and assign the correct number assuming the usual $\theta = 0$ threshold. 
<a name="l1112"><span class="ln">1112 </span></a></span><span class="s0">#%% 
<a name="l1113"><span class="ln">1113 </span></a># YOUR CODE HERE</span>
<a name="l1114"><span class="ln">1114 </span></a><span class="s1">data </span><span class="s3">= [</span>
<a name="l1115"><span class="ln">1115 </span></a>    <span class="s3">(+</span><span class="s5">1</span><span class="s3">, </span><span class="s5">0.93</span><span class="s3">),</span>
<a name="l1116"><span class="ln">1116 </span></a>    <span class="s3">(+</span><span class="s5">1</span><span class="s3">, </span><span class="s5">0.51</span><span class="s3">),</span>
<a name="l1117"><span class="ln">1117 </span></a>    <span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">0.48</span><span class="s3">),</span>
<a name="l1118"><span class="ln">1118 </span></a>    <span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">0.13</span><span class="s3">),</span>
<a name="l1119"><span class="ln">1119 </span></a>    <span class="s3">(+</span><span class="s5">1</span><span class="s3">, </span><span class="s5">0.02</span><span class="s3">),</span>
<a name="l1120"><span class="ln">1120 </span></a>    <span class="s3">(-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">0.11</span><span class="s3">),</span>
<a name="l1121"><span class="ln">1121 </span></a>    <span class="s3">(-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">0.25</span><span class="s3">),</span>
<a name="l1122"><span class="ln">1122 </span></a>    <span class="s3">(-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">0.37</span><span class="s3">),</span>
<a name="l1123"><span class="ln">1123 </span></a>    <span class="s3">(+</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">0.41</span><span class="s3">),</span>
<a name="l1124"><span class="ln">1124 </span></a>    <span class="s3">(-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1.68</span><span class="s3">),</span>
<a name="l1125"><span class="ln">1125 </span></a>    <span class="s3">(+</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">2.23</span><span class="s3">),</span>
<a name="l1126"><span class="ln">1126 </span></a>    <span class="s3">(+</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">3.41</span><span class="s3">)</span>
<a name="l1127"><span class="ln">1127 </span></a><span class="s3">]</span>
<a name="l1128"><span class="ln">1128 </span></a>
<a name="l1129"><span class="ln">1129 </span></a><span class="s1">TP_ </span><span class="s3">= </span><span class="s5">0</span>
<a name="l1130"><span class="ln">1130 </span></a><span class="s1">FN_ </span><span class="s3">= </span><span class="s5">0</span>
<a name="l1131"><span class="ln">1131 </span></a><span class="s1">FP_ </span><span class="s3">= </span><span class="s5">0</span>
<a name="l1132"><span class="ln">1132 </span></a><span class="s1">TN_ </span><span class="s3">= </span><span class="s5">0</span>
<a name="l1133"><span class="ln">1133 </span></a>
<a name="l1134"><span class="ln">1134 </span></a><span class="s2">for </span><span class="s1">y</span><span class="s3">, </span><span class="s1">gx </span><span class="s2">in </span><span class="s1">data</span><span class="s3">:</span>
<a name="l1135"><span class="ln">1135 </span></a>    <span class="s0"># Prediction based on threshold theta = 0</span>
<a name="l1136"><span class="ln">1136 </span></a>    <span class="s1">prediction </span><span class="s3">= +</span><span class="s5">1 </span><span class="s2">if </span><span class="s1">gx </span><span class="s3">&gt;= </span><span class="s5">0 </span><span class="s2">else </span><span class="s3">-</span><span class="s5">1</span>
<a name="l1137"><span class="ln">1137 </span></a>    
<a name="l1138"><span class="ln">1138 </span></a>    <span class="s2">if </span><span class="s1">y </span><span class="s3">== +</span><span class="s5">1 </span><span class="s2">and </span><span class="s1">prediction </span><span class="s3">== +</span><span class="s5">1</span><span class="s3">:</span>
<a name="l1139"><span class="ln">1139 </span></a>        <span class="s1">TP_ </span><span class="s3">+= </span><span class="s5">1</span>
<a name="l1140"><span class="ln">1140 </span></a>    <span class="s2">elif </span><span class="s1">y </span><span class="s3">== +</span><span class="s5">1 </span><span class="s2">and </span><span class="s1">prediction </span><span class="s3">== -</span><span class="s5">1</span><span class="s3">:</span>
<a name="l1141"><span class="ln">1141 </span></a>        <span class="s1">FN_ </span><span class="s3">+= </span><span class="s5">1</span>
<a name="l1142"><span class="ln">1142 </span></a>    <span class="s2">elif </span><span class="s1">y </span><span class="s3">== -</span><span class="s5">1 </span><span class="s2">and </span><span class="s1">prediction </span><span class="s3">== +</span><span class="s5">1</span><span class="s3">:</span>
<a name="l1143"><span class="ln">1143 </span></a>        <span class="s1">FP_ </span><span class="s3">+= </span><span class="s5">1</span>
<a name="l1144"><span class="ln">1144 </span></a>    <span class="s2">elif </span><span class="s1">y </span><span class="s3">== -</span><span class="s5">1 </span><span class="s2">and </span><span class="s1">prediction </span><span class="s3">== -</span><span class="s5">1</span><span class="s3">:</span>
<a name="l1145"><span class="ln">1145 </span></a>        <span class="s1">TN_ </span><span class="s3">+= </span><span class="s5">1</span>
<a name="l1146"><span class="ln">1146 </span></a>        
<a name="l1147"><span class="ln">1147 </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">f&quot;TP = </span><span class="s2">{</span><span class="s1">TP_</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l1148"><span class="ln">1148 </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">f&quot;FN = </span><span class="s2">{</span><span class="s1">FN_</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l1149"><span class="ln">1149 </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">f&quot;FP = </span><span class="s2">{</span><span class="s1">FP_</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l1150"><span class="ln">1150 </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">f&quot;TN = </span><span class="s2">{</span><span class="s1">TN_</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s3">)</span>
<a name="l1151"><span class="ln">1151 </span></a><span class="s0">#%% 
<a name="l1152"><span class="ln">1152 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1153"><span class="ln">1153 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">TP_</span><span class="s3">, </span><span class="s1">int</span><span class="s3">), </span><span class="s4">&quot;The number of TP is not an integer!&quot;</span>
<a name="l1154"><span class="ln">1154 </span></a><span class="s0">#%% 
<a name="l1155"><span class="ln">1155 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1156"><span class="ln">1156 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">FN_</span><span class="s3">, </span><span class="s1">int</span><span class="s3">), </span><span class="s4">&quot;The number of FN is not an integer!&quot;</span>
<a name="l1157"><span class="ln">1157 </span></a><span class="s0">#%% 
<a name="l1158"><span class="ln">1158 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1159"><span class="ln">1159 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">FP_</span><span class="s3">, </span><span class="s1">int</span><span class="s3">), </span><span class="s4">&quot;The number of FP is not an integer!&quot;</span>
<a name="l1160"><span class="ln">1160 </span></a><span class="s0">#%% 
<a name="l1161"><span class="ln">1161 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1162"><span class="ln">1162 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">TN_</span><span class="s3">, </span><span class="s1">int</span><span class="s3">), </span><span class="s4">&quot;The number of TN is not an integer!&quot;</span>
<a name="l1163"><span class="ln">1163 </span></a><span class="s0">#%% 
<a name="l1164"><span class="ln">1164 </span></a></span><span class="s2">def </span><span class="s1">evaluation_meatrics</span><span class="s3">(</span><span class="s1">TP</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">TN</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">FP</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">FN</span><span class="s3">: </span><span class="s1">int</span><span class="s3">) </span><span class="s1">-&gt; tuple</span><span class="s3">[</span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">]:</span>
<a name="l1165"><span class="ln">1165 </span></a>    <span class="s6">&quot;&quot;&quot;Calculate evaluation metrics for a binary classification model. 
<a name="l1166"><span class="ln">1166 </span></a> 
<a name="l1167"><span class="ln">1167 </span></a>    This function computes common evaluation metrics, including True Positive Rate (TPR), 
<a name="l1168"><span class="ln">1168 </span></a>    True Negative Rate (TNR), False Positive Rate (FPR), False Negative Rate (FNR),  
<a name="l1169"><span class="ln">1169 </span></a>    Accuracy (ACC), Balanced Accuracy (BACC), Precision (PREC), and F1 Score (F1),  
<a name="l1170"><span class="ln">1170 </span></a>    based on the counts of true positives, true negatives, false positives, and false negatives. 
<a name="l1171"><span class="ln">1171 </span></a> 
<a name="l1172"><span class="ln">1172 </span></a>    Parameters 
<a name="l1173"><span class="ln">1173 </span></a>    ---------- 
<a name="l1174"><span class="ln">1174 </span></a>    TP : int 
<a name="l1175"><span class="ln">1175 </span></a>        Number of true positive cases. 
<a name="l1176"><span class="ln">1176 </span></a>    TN : int 
<a name="l1177"><span class="ln">1177 </span></a>        Number of true negative cases. 
<a name="l1178"><span class="ln">1178 </span></a>    FP : int 
<a name="l1179"><span class="ln">1179 </span></a>        Number of false positive cases. 
<a name="l1180"><span class="ln">1180 </span></a>    FN : int 
<a name="l1181"><span class="ln">1181 </span></a>        Number of false negative cases. 
<a name="l1182"><span class="ln">1182 </span></a> 
<a name="l1183"><span class="ln">1183 </span></a>    Returns 
<a name="l1184"><span class="ln">1184 </span></a>    ------- 
<a name="l1185"><span class="ln">1185 </span></a>    tuple of float 
<a name="l1186"><span class="ln">1186 </span></a>        - TPR : float 
<a name="l1187"><span class="ln">1187 </span></a>            True Positive Rate, or Recall. 
<a name="l1188"><span class="ln">1188 </span></a>        - TNR : float 
<a name="l1189"><span class="ln">1189 </span></a>            True Negative Rate, or Specificity. 
<a name="l1190"><span class="ln">1190 </span></a>        - FPR : float 
<a name="l1191"><span class="ln">1191 </span></a>            False Positive Rate. 
<a name="l1192"><span class="ln">1192 </span></a>        - FNR : float 
<a name="l1193"><span class="ln">1193 </span></a>            False Negative Rate. 
<a name="l1194"><span class="ln">1194 </span></a>        - ACC : float 
<a name="l1195"><span class="ln">1195 </span></a>            Accuracy of the model. 
<a name="l1196"><span class="ln">1196 </span></a>        - BACC : float 
<a name="l1197"><span class="ln">1197 </span></a>            Balanced Accuracy, the average of TPR and TNR. 
<a name="l1198"><span class="ln">1198 </span></a>        - PREC : float 
<a name="l1199"><span class="ln">1199 </span></a>            Precision of the model. 
<a name="l1200"><span class="ln">1200 </span></a>        - F1 : float 
<a name="l1201"><span class="ln">1201 </span></a>            F1 Score, the harmonic mean of Precision and Recall 
<a name="l1202"><span class="ln">1202 </span></a>    &quot;&quot;&quot;    </span>
<a name="l1203"><span class="ln">1203 </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l1204"><span class="ln">1204 </span></a>    <span class="s1">TPR </span><span class="s3">= </span><span class="s1">TP </span><span class="s3">/ (</span><span class="s1">TP </span><span class="s3">+ </span><span class="s1">FN</span><span class="s3">) </span><span class="s2">if </span><span class="s3">(</span><span class="s1">TP </span><span class="s3">+ </span><span class="s1">FN</span><span class="s3">) != </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
<a name="l1205"><span class="ln">1205 </span></a>    <span class="s1">TNR </span><span class="s3">= </span><span class="s1">TN </span><span class="s3">/ (</span><span class="s1">TN </span><span class="s3">+ </span><span class="s1">FP</span><span class="s3">) </span><span class="s2">if </span><span class="s3">(</span><span class="s1">TN </span><span class="s3">+ </span><span class="s1">FP</span><span class="s3">) != </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
<a name="l1206"><span class="ln">1206 </span></a>    <span class="s1">FPR </span><span class="s3">= </span><span class="s1">FP </span><span class="s3">/ (</span><span class="s1">FP </span><span class="s3">+ </span><span class="s1">TN</span><span class="s3">) </span><span class="s2">if </span><span class="s3">(</span><span class="s1">FP </span><span class="s3">+ </span><span class="s1">TN</span><span class="s3">) != </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
<a name="l1207"><span class="ln">1207 </span></a>    <span class="s1">FNR </span><span class="s3">= </span><span class="s1">FN </span><span class="s3">/ (</span><span class="s1">FN </span><span class="s3">+ </span><span class="s1">TP</span><span class="s3">) </span><span class="s2">if </span><span class="s3">(</span><span class="s1">FN </span><span class="s3">+ </span><span class="s1">TP</span><span class="s3">) != </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
<a name="l1208"><span class="ln">1208 </span></a>    <span class="s1">ACC </span><span class="s3">= (</span><span class="s1">TP </span><span class="s3">+ </span><span class="s1">TN</span><span class="s3">) / (</span><span class="s1">TP </span><span class="s3">+ </span><span class="s1">TN </span><span class="s3">+ </span><span class="s1">FP </span><span class="s3">+ </span><span class="s1">FN</span><span class="s3">) </span><span class="s2">if </span><span class="s3">(</span><span class="s1">TP </span><span class="s3">+ </span><span class="s1">TN </span><span class="s3">+ </span><span class="s1">FP </span><span class="s3">+ </span><span class="s1">FN</span><span class="s3">) != </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
<a name="l1209"><span class="ln">1209 </span></a>    <span class="s1">BACC </span><span class="s3">= (</span><span class="s1">TPR </span><span class="s3">+ </span><span class="s1">TNR</span><span class="s3">) / </span><span class="s5">2</span>
<a name="l1210"><span class="ln">1210 </span></a>    <span class="s1">PREC </span><span class="s3">= </span><span class="s1">TP </span><span class="s3">/ (</span><span class="s1">TP </span><span class="s3">+ </span><span class="s1">FP</span><span class="s3">) </span><span class="s2">if </span><span class="s3">(</span><span class="s1">TP </span><span class="s3">+ </span><span class="s1">FP</span><span class="s3">) != </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
<a name="l1211"><span class="ln">1211 </span></a>    <span class="s1">F1 </span><span class="s3">= (</span><span class="s5">2 </span><span class="s3">* </span><span class="s1">PREC </span><span class="s3">* </span><span class="s1">TPR</span><span class="s3">) / (</span><span class="s1">PREC </span><span class="s3">+ </span><span class="s1">TPR</span><span class="s3">) </span><span class="s2">if </span><span class="s3">(</span><span class="s1">PREC </span><span class="s3">+ </span><span class="s1">TPR</span><span class="s3">) != </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
<a name="l1212"><span class="ln">1212 </span></a>    <span class="s2">return </span><span class="s1">TPR</span><span class="s3">, </span><span class="s1">TNR</span><span class="s3">, </span><span class="s1">FPR</span><span class="s3">, </span><span class="s1">FNR</span><span class="s3">, </span><span class="s1">ACC</span><span class="s3">, </span><span class="s1">BACC</span><span class="s3">, </span><span class="s1">PREC</span><span class="s3">, </span><span class="s1">F1</span>
<a name="l1213"><span class="ln">1213 </span></a><span class="s0">#%% 
<a name="l1214"><span class="ln">1214 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1215"><span class="ln">1215 </span></a><span class="s1">TPR_</span><span class="s3">, </span><span class="s1">TNR_</span><span class="s3">, </span><span class="s1">FPR_</span><span class="s3">, </span><span class="s1">FNR_</span><span class="s3">, </span><span class="s1">ACC_</span><span class="s3">, </span><span class="s1">BACC_</span><span class="s3">, </span><span class="s1">PREC_</span><span class="s3">, </span><span class="s1">F1_ </span><span class="s3">= </span><span class="s1">evaluation_meatrics</span><span class="s3">(</span><span class="s1">TP_</span><span class="s3">, </span><span class="s1">TN_</span><span class="s3">, </span><span class="s1">FP_</span><span class="s3">, </span><span class="s1">FN_</span><span class="s3">)</span>
<a name="l1216"><span class="ln">1216 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">TPR_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The TPR is not a float!&quot;</span>
<a name="l1217"><span class="ln">1217 </span></a><span class="s2">assert </span><span class="s1">TPR_ </span><span class="s3">== </span><span class="s5">0.5</span><span class="s3">, </span><span class="s4">&quot;The TPR is wrong!&quot;</span>
<a name="l1218"><span class="ln">1218 </span></a><span class="s0">#%% 
<a name="l1219"><span class="ln">1219 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1220"><span class="ln">1220 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">TNR_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The TNR is not a float!&quot;</span>
<a name="l1221"><span class="ln">1221 </span></a><span class="s2">assert </span><span class="s1">TNR_ </span><span class="s3">== </span><span class="s5">2</span><span class="s3">/</span><span class="s5">3</span><span class="s3">, </span><span class="s4">&quot;The TNR is wrong!&quot;</span>
<a name="l1222"><span class="ln">1222 </span></a><span class="s0">#%% 
<a name="l1223"><span class="ln">1223 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1224"><span class="ln">1224 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">FPR_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The FPR is not a float!&quot;</span>
<a name="l1225"><span class="ln">1225 </span></a><span class="s2">assert </span><span class="s1">FPR_ </span><span class="s3">== </span><span class="s5">1</span><span class="s3">/</span><span class="s5">3</span><span class="s3">, </span><span class="s4">&quot;The FPR is wrong!&quot;</span>
<a name="l1226"><span class="ln">1226 </span></a><span class="s0">#%% 
<a name="l1227"><span class="ln">1227 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1228"><span class="ln">1228 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">FNR_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The FNR is not a float!&quot;</span>
<a name="l1229"><span class="ln">1229 </span></a><span class="s2">assert </span><span class="s1">FNR_ </span><span class="s3">== </span><span class="s5">0.5</span><span class="s3">, </span><span class="s4">&quot;The FNR is wrong!&quot;</span>
<a name="l1230"><span class="ln">1230 </span></a><span class="s0">#%% 
<a name="l1231"><span class="ln">1231 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1232"><span class="ln">1232 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">ACC_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The ACC is not a float!&quot;</span>
<a name="l1233"><span class="ln">1233 </span></a><span class="s2">assert </span><span class="s1">round</span><span class="s3">(</span><span class="s1">ACC_</span><span class="s3">, </span><span class="s5">3</span><span class="s3">) == </span><span class="s5">0.583</span><span class="s3">, </span><span class="s4">&quot;The ACC is wrong!&quot;</span>
<a name="l1234"><span class="ln">1234 </span></a><span class="s0">#%% 
<a name="l1235"><span class="ln">1235 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1236"><span class="ln">1236 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">BACC_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The BACC is not a float!&quot;</span>
<a name="l1237"><span class="ln">1237 </span></a><span class="s2">assert </span><span class="s1">round</span><span class="s3">(</span><span class="s1">BACC_</span><span class="s3">, </span><span class="s5">3</span><span class="s3">) == </span><span class="s5">0.583</span><span class="s3">, </span><span class="s4">&quot;The BACC is wrong!&quot;</span>
<a name="l1238"><span class="ln">1238 </span></a><span class="s0">#%% 
<a name="l1239"><span class="ln">1239 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1240"><span class="ln">1240 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">PREC_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The PREC is not a float!&quot;</span>
<a name="l1241"><span class="ln">1241 </span></a><span class="s2">assert </span><span class="s1">PREC_ </span><span class="s3">== </span><span class="s5">0.6</span><span class="s3">, </span><span class="s4">&quot;The PREC is wrong!&quot;</span>
<a name="l1242"><span class="ln">1242 </span></a><span class="s0">#%% 
<a name="l1243"><span class="ln">1243 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1244"><span class="ln">1244 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">F1_</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The F1 is not a float!&quot;</span>
<a name="l1245"><span class="ln">1245 </span></a><span class="s2">assert </span><span class="s1">F1_ </span><span class="s3">== </span><span class="s5">6</span><span class="s3">/</span><span class="s5">11</span><span class="s3">, </span><span class="s4">&quot;The F1 is wrong!&quot;</span>
<a name="l1246"><span class="ln">1246 </span></a><span class="s0">#%% 
<a name="l1247"><span class="ln">1247 </span></a># Nothing to do here, just run the cell.</span>
<a name="l1248"><span class="ln">1248 </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot; TPR = {:.3f}</span><span class="s2">\n </span><span class="s4">TNR = {:.3f}</span><span class="s2">\n </span><span class="s4">FPR = {:.3f}</span><span class="s2">\n </span><span class="s4">FNR = {:.3f}</span><span class="s2">\n </span><span class="s4">ACC = {:.3f}</span><span class="s2">\n</span><span class="s4">BACC = {:.3f}</span><span class="s2">\n</span><span class="s4">PREC = {:.3f}</span><span class="s2">\n  </span><span class="s4">F1 = {:.3f}&quot;</span><span class="s3">.</span><span class="s1">format</span><span class="s3">(</span><span class="s1">TPR_</span><span class="s3">, </span><span class="s1">TNR_</span><span class="s3">, </span><span class="s1">FPR_</span><span class="s3">, </span><span class="s1">FNR_</span><span class="s3">, </span><span class="s1">ACC_</span><span class="s3">, </span><span class="s1">BACC_</span><span class="s3">, </span><span class="s1">PREC_</span><span class="s3">, </span><span class="s1">F1_</span><span class="s3">))</span>
<a name="l1249"><span class="ln">1249 </span></a><span class="s0">#%% md 
<a name="l1250"><span class="ln">1250 </span></a></span><span class="s1">&lt;h3 style=&quot;color:rgb(210,90,80)&quot;&gt;Calculation 5.2 (7 Points):&lt;/h3&gt; 
<a name="l1251"><span class="ln">1251 </span></a></span><span class="s0">#%% 
<a name="l1252"><span class="ln">1252 </span></a></span><span class="s2">def </span><span class="s1">calc_prob</span><span class="s3">(</span><span class="s1">spec</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">sens</span><span class="s3">: </span><span class="s1">float</span><span class="s3">, </span><span class="s1">pop</span><span class="s3">: </span><span class="s1">int</span><span class="s3">, </span><span class="s1">inf</span><span class="s3">: </span><span class="s1">int</span><span class="s3">) </span><span class="s1">-&gt; tuple</span><span class="s3">[</span><span class="s1">float</span><span class="s3">, </span><span class="s1">float</span><span class="s3">]:</span>
<a name="l1253"><span class="ln">1253 </span></a>    <span class="s6">&quot;&quot;&quot;Calculate the rounded probabilities of false positives and false negatives. 
<a name="l1254"><span class="ln">1254 </span></a> 
<a name="l1255"><span class="ln">1255 </span></a>    This function computes two probabilities:  
<a name="l1256"><span class="ln">1256 </span></a>    - `p1`: the probability of a false positive given a positive test result. 
<a name="l1257"><span class="ln">1257 </span></a>    - `p2`: the probability of a false negative given a negative test result. 
<a name="l1258"><span class="ln">1258 </span></a> 
<a name="l1259"><span class="ln">1259 </span></a>    Parameters 
<a name="l1260"><span class="ln">1260 </span></a>    ---------- 
<a name="l1261"><span class="ln">1261 </span></a>    spec : float 
<a name="l1262"><span class="ln">1262 </span></a>        Specificity of the test (True Negative Rate). 
<a name="l1263"><span class="ln">1263 </span></a>    sens : float 
<a name="l1264"><span class="ln">1264 </span></a>        Sensitivity of the test (True Positive Rate). 
<a name="l1265"><span class="ln">1265 </span></a>    pop : int 
<a name="l1266"><span class="ln">1266 </span></a>        Total population size. 
<a name="l1267"><span class="ln">1267 </span></a>    inf : int 
<a name="l1268"><span class="ln">1268 </span></a>        Number of infected individuals in the population. 
<a name="l1269"><span class="ln">1269 </span></a> 
<a name="l1270"><span class="ln">1270 </span></a>    Returns 
<a name="l1271"><span class="ln">1271 </span></a>    ------- 
<a name="l1272"><span class="ln">1272 </span></a>    tuple of float 
<a name="l1273"><span class="ln">1273 </span></a>        - p1 : float 
<a name="l1274"><span class="ln">1274 </span></a>            Probability of a false positive given a positive test result, rounded to 4 decimal places. 
<a name="l1275"><span class="ln">1275 </span></a>        - p2 : float 
<a name="l1276"><span class="ln">1276 </span></a>            Probability of a false negative given a negative test result, rounded to 4 decimal places. 
<a name="l1277"><span class="ln">1277 </span></a>    &quot;&quot;&quot;</span>
<a name="l1278"><span class="ln">1278 </span></a>    <span class="s0"># YOUR CODE HERE</span>
<a name="l1279"><span class="ln">1279 </span></a>     <span class="s0"># Prevalence</span>
<a name="l1280"><span class="ln">1280 </span></a>    <span class="s1">P_infected </span><span class="s3">= </span><span class="s1">inf </span><span class="s3">/ </span><span class="s1">pop</span>
<a name="l1281"><span class="ln">1281 </span></a>    <span class="s1">P_not_infected </span><span class="s3">= </span><span class="s5">1 </span><span class="s3">- </span><span class="s1">P_infected</span>
<a name="l1282"><span class="ln">1282 </span></a>
<a name="l1283"><span class="ln">1283 </span></a>    <span class="s0"># Probabilities</span>
<a name="l1284"><span class="ln">1284 </span></a>    <span class="s1">P_TP </span><span class="s3">= </span><span class="s1">sens </span><span class="s3">* </span><span class="s1">P_infected</span>
<a name="l1285"><span class="ln">1285 </span></a>    <span class="s1">P_FP </span><span class="s3">= (</span><span class="s5">1 </span><span class="s3">- </span><span class="s1">spec</span><span class="s3">) * </span><span class="s1">P_not_infected</span>
<a name="l1286"><span class="ln">1286 </span></a>    <span class="s1">P_TN </span><span class="s3">= </span><span class="s1">spec </span><span class="s3">* </span><span class="s1">P_not_infected</span>
<a name="l1287"><span class="ln">1287 </span></a>    <span class="s1">P_FN </span><span class="s3">= (</span><span class="s5">1 </span><span class="s3">- </span><span class="s1">sens</span><span class="s3">) * </span><span class="s1">P_infected</span>
<a name="l1288"><span class="ln">1288 </span></a>
<a name="l1289"><span class="ln">1289 </span></a>    <span class="s0"># Total probabilities</span>
<a name="l1290"><span class="ln">1290 </span></a>    <span class="s1">P_test_positive </span><span class="s3">= </span><span class="s1">P_TP </span><span class="s3">+ </span><span class="s1">P_FP</span>
<a name="l1291"><span class="ln">1291 </span></a>    <span class="s1">P_test_negative </span><span class="s3">= </span><span class="s1">P_TN </span><span class="s3">+ </span><span class="s1">P_FN</span>
<a name="l1292"><span class="ln">1292 </span></a>
<a name="l1293"><span class="ln">1293 </span></a>    <span class="s0"># p1: Probability of not infected given test positive</span>
<a name="l1294"><span class="ln">1294 </span></a>    <span class="s1">P_not_infected_given_positive </span><span class="s3">= </span><span class="s1">P_FP </span><span class="s3">/ </span><span class="s1">P_test_positive</span>
<a name="l1295"><span class="ln">1295 </span></a>
<a name="l1296"><span class="ln">1296 </span></a>    <span class="s0"># p2: Probability of infected given test negative</span>
<a name="l1297"><span class="ln">1297 </span></a>    <span class="s1">P_infected_given_negative </span><span class="s3">= </span><span class="s1">P_FN </span><span class="s3">/ </span><span class="s1">P_test_negative</span>
<a name="l1298"><span class="ln">1298 </span></a>
<a name="l1299"><span class="ln">1299 </span></a>    <span class="s0"># Round to 4 decimal places</span>
<a name="l1300"><span class="ln">1300 </span></a>    <span class="s1">p1 </span><span class="s3">= </span><span class="s1">round</span><span class="s3">(</span><span class="s1">P_not_infected_given_positive</span><span class="s3">, </span><span class="s5">4</span><span class="s3">)</span>
<a name="l1301"><span class="ln">1301 </span></a>    <span class="s1">p2 </span><span class="s3">= </span><span class="s1">round</span><span class="s3">(</span><span class="s1">P_infected_given_negative</span><span class="s3">, </span><span class="s5">4</span><span class="s3">)</span>
<a name="l1302"><span class="ln">1302 </span></a>
<a name="l1303"><span class="ln">1303 </span></a>    <span class="s2">return </span><span class="s1">p1</span><span class="s3">, </span><span class="s1">p2</span>
<a name="l1304"><span class="ln">1304 </span></a><span class="s0">#%% 
<a name="l1305"><span class="ln">1305 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1306"><span class="ln">1306 </span></a><span class="s1">p1</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">calc_prob</span><span class="s3">(</span><span class="s5">0.90</span><span class="s3">, </span><span class="s5">0.95</span><span class="s3">, </span><span class="s5">1000</span><span class="s3">, </span><span class="s5">50</span><span class="s3">)</span>
<a name="l1307"><span class="ln">1307 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">p1</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The probability of a false positive is not a float!&quot;</span>
<a name="l1308"><span class="ln">1308 </span></a><span class="s2">assert </span><span class="s1">p1 </span><span class="s3">== </span><span class="s5">0.6667</span><span class="s3">, </span><span class="s4">&quot;The probability of a false positive is not correct!&quot;</span>
<a name="l1309"><span class="ln">1309 </span></a><span class="s0">#%% 
<a name="l1310"><span class="ln">1310 </span></a># DO NOT DELETE THIS CELL!</span>
<a name="l1311"><span class="ln">1311 </span></a><span class="s1">_</span><span class="s3">, </span><span class="s1">p2 </span><span class="s3">= </span><span class="s1">calc_prob</span><span class="s3">(</span><span class="s5">0.90</span><span class="s3">, </span><span class="s5">0.95</span><span class="s3">, </span><span class="s5">1000</span><span class="s3">, </span><span class="s5">50</span><span class="s3">)</span>
<a name="l1312"><span class="ln">1312 </span></a><span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">p2</span><span class="s3">, </span><span class="s1">float</span><span class="s3">), </span><span class="s4">&quot;The probability of a false negative is not a float!&quot;</span>
<a name="l1313"><span class="ln">1313 </span></a><span class="s2">assert </span><span class="s1">p2 </span><span class="s3">== </span><span class="s5">0.0029</span><span class="s3">, </span><span class="s4">&quot;The probability of a false negative is not correct!&quot;</span>
<a name="l1314"><span class="ln">1314 </span></a><span class="s0">#%% 
<a name="l1315"><span class="ln">1315 </span></a></span><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;The probability that a person who is tested positive is in fact not infected is {}&quot;</span><span class="s3">.</span><span class="s1">format</span><span class="s3">(</span><span class="s1">p1</span><span class="s3">))</span>
<a name="l1316"><span class="ln">1316 </span></a><span class="s1">print</span><span class="s3">(</span><span class="s4">&quot;The probability that a person who is tested negative is in fact infected is {}&quot;</span><span class="s3">.</span><span class="s1">format</span><span class="s3">(</span><span class="s1">p2</span><span class="s3">))</span>
<a name="l1317"><span class="ln">1317 </span></a><span class="s0">#%% 
<a name="l1318"><span class="ln">1318 </span></a></span></pre>
</body>
</html>